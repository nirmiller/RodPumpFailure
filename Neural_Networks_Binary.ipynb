{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g58pj8bWpoVg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "import plotly.express as px\n",
        "%matplotlib inline\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1NeGzQZlBQt",
        "outputId": "4ca33490-da33-4f30-a19a-389450844a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb3NyptRkSd9"
      },
      "outputs": [],
      "source": [
        "filters = ['FAILURETYPE',\n",
        "       'H2S_CONCENTRATION',\n",
        "       'StrokeLength', 'GrossStrokeLength', 'Fillage', 'YesterdaysAverageSPM',\n",
        "       'max_unguided_dls', 'dls_high_in_hole', 'gas_anchor_length',\n",
        "       'MAX_INCLINATION',\n",
        "       'AVG_PRESS_FLOWLINE', 'AVG_PRESSURE_TUBING', 'AVG_PRESSURE_CASING',\n",
        "       'AVG_DIFFERENTIAL_PRESSURE', 'AVG_OIL_VOLUME', 'AVG_WATER_VOLUME',\n",
        "       'AVG_LIQUID_VOLUME', 'AVG_WATERSG',\n",
        "        'overall_max_sideload',\n",
        "       'shallow_max_sideload', 'max_unguided_sideload',\n",
        "       'CHROME_LENGTH', 'ENDURALLOY_LENGTH', 'POLY_LENGTH', 'NIPPLE_SET_DEPTH',\n",
        "       'pump_bore']\n",
        "tags = ['Not Failure', 'Failure']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W032QqVVj1GH"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Group 3 Inventors Program Project/Data Sets/rodpump_failure.csv')\n",
        "data['FAILURETYPE'] = data['FAILURETYPE'].replace(np.nan, 'Not Failure')\n",
        "data['FAILURETYPE'] = data['FAILURETYPE'].replace('Tubing', 'Failure')\n",
        "data['FAILURETYPE'] = data['FAILURETYPE'].replace('Sucker Rod Pump', 'Failure')\n",
        "data['FAILURETYPE'] = data['FAILURETYPE'].replace('Rods', 'Failure')\n",
        "data = data.replace('Other', 0)\n",
        "min_length = min(list(data['FAILURETYPE'].value_counts(dropna=False)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw1-_IIgeGlt"
      },
      "outputs": [],
      "source": [
        "data = data.replace(np.nan, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yBtvc3czyrE"
      },
      "outputs": [],
      "source": [
        "filtered_data = data[filters]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "zezWW9gCzJQu",
        "outputId": "577def98-d935-49ef-c8aa-4d22682ed4e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      FAILURETYPE  H2S_CONCENTRATION  StrokeLength  GrossStrokeLength  \\\n",
              "0         Failure                0.0    144.000000         108.135619   \n",
              "1         Failure                0.0    168.000000         173.462417   \n",
              "2         Failure                0.0    144.000000           0.000000   \n",
              "3         Failure                0.0    144.199997           0.000000   \n",
              "4     Not Failure                0.0    168.000000         127.228453   \n",
              "...           ...                ...           ...                ...   \n",
              "2591  Not Failure                0.0    144.000000           0.000000   \n",
              "2592  Not Failure                0.0    144.000000           0.000000   \n",
              "2593      Failure                0.0    168.039993         129.730177   \n",
              "2594      Failure                0.0    144.000000           0.000000   \n",
              "2595      Failure                0.0    144.000000           0.000000   \n",
              "\n",
              "        Fillage  YesterdaysAverageSPM  max_unguided_dls  dls_high_in_hole  \\\n",
              "0     91.410156              6.000000          1.710783          1.396486   \n",
              "1      2.500000              0.000000          1.830000          1.650000   \n",
              "2      0.000000              0.000000          5.470000          5.470000   \n",
              "3     86.327774              5.800000          1.928766          0.487946   \n",
              "4     61.000000              4.272727          1.871999          3.876364   \n",
              "...         ...                   ...               ...               ...   \n",
              "2591   0.000000              0.000000          1.259511          1.210066   \n",
              "2592   0.000000              0.000000          1.150000          1.140000   \n",
              "2593  96.699997              6.600000          1.560000          1.700000   \n",
              "2594   0.000000              0.000000          1.287232          0.715211   \n",
              "2595   0.000000              0.000000          4.093197          4.093197   \n",
              "\n",
              "      gas_anchor_length  MAX_INCLINATION  ...  AVG_LIQUID_VOLUME  AVG_WATERSG  \\\n",
              "0                 19.27             2.43  ...         109.325929         1.04   \n",
              "1                 17.21             2.30  ...         108.557848         0.00   \n",
              "2                 20.75             2.10  ...          56.506804         0.00   \n",
              "3                 17.25             1.47  ...         112.883333         1.04   \n",
              "4                 17.12             4.23  ...          93.008849         1.04   \n",
              "...                 ...              ...  ...                ...          ...   \n",
              "2591              20.73             1.93  ...          98.737291         0.00   \n",
              "2592              20.75             1.75  ...         137.847413         0.00   \n",
              "2593              19.80             6.07  ...          42.813953         0.00   \n",
              "2594              19.25             1.83  ...          41.669091         0.00   \n",
              "2595              19.26             2.19  ...         110.016000         0.00   \n",
              "\n",
              "      overall_max_sideload  shallow_max_sideload  max_unguided_sideload  \\\n",
              "0                     0.00                  0.00                   0.00   \n",
              "1                   179.44                179.44                 179.44   \n",
              "2                   105.76                105.76                 105.76   \n",
              "3                    98.18                 47.96                  98.18   \n",
              "4                   266.68                266.68                 170.99   \n",
              "...                    ...                   ...                    ...   \n",
              "2591                 96.58                 96.58                  96.58   \n",
              "2592                 61.66                 61.66                  61.66   \n",
              "2593                164.65                164.65                 121.77   \n",
              "2594                  0.00                  0.00                   0.00   \n",
              "2595                  0.00                  0.00                   0.00   \n",
              "\n",
              "      CHROME_LENGTH  ENDURALLOY_LENGTH  POLY_LENGTH  NIPPLE_SET_DEPTH  \\\n",
              "0               0.0               0.00          0.0           10024.8   \n",
              "1               0.0               0.00          0.0           10235.6   \n",
              "2               0.0               0.00          0.0           10401.9   \n",
              "3               0.0               0.00          0.0            9557.7   \n",
              "4               0.0             129.39          0.0            9681.7   \n",
              "...             ...                ...          ...               ...   \n",
              "2591            0.0               0.00          0.0            9708.4   \n",
              "2592            0.0               0.00          0.0            9904.4   \n",
              "2593            0.0              65.35          0.0            9014.5   \n",
              "2594            0.0               0.00          0.0            9532.2   \n",
              "2595            0.0               0.00          0.0           10165.0   \n",
              "\n",
              "      pump_bore  \n",
              "0           1.5  \n",
              "1           1.5  \n",
              "2           1.5  \n",
              "3          1.75  \n",
              "4          1.75  \n",
              "...         ...  \n",
              "2591        1.5  \n",
              "2592        1.5  \n",
              "2593       1.75  \n",
              "2594        1.5  \n",
              "2595        1.5  \n",
              "\n",
              "[2596 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1c62efd-dfea-4448-8d85-e410d41ec182\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FAILURETYPE</th>\n",
              "      <th>H2S_CONCENTRATION</th>\n",
              "      <th>StrokeLength</th>\n",
              "      <th>GrossStrokeLength</th>\n",
              "      <th>Fillage</th>\n",
              "      <th>YesterdaysAverageSPM</th>\n",
              "      <th>max_unguided_dls</th>\n",
              "      <th>dls_high_in_hole</th>\n",
              "      <th>gas_anchor_length</th>\n",
              "      <th>MAX_INCLINATION</th>\n",
              "      <th>...</th>\n",
              "      <th>AVG_LIQUID_VOLUME</th>\n",
              "      <th>AVG_WATERSG</th>\n",
              "      <th>overall_max_sideload</th>\n",
              "      <th>shallow_max_sideload</th>\n",
              "      <th>max_unguided_sideload</th>\n",
              "      <th>CHROME_LENGTH</th>\n",
              "      <th>ENDURALLOY_LENGTH</th>\n",
              "      <th>POLY_LENGTH</th>\n",
              "      <th>NIPPLE_SET_DEPTH</th>\n",
              "      <th>pump_bore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>108.135619</td>\n",
              "      <td>91.410156</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.710783</td>\n",
              "      <td>1.396486</td>\n",
              "      <td>19.27</td>\n",
              "      <td>2.43</td>\n",
              "      <td>...</td>\n",
              "      <td>109.325929</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10024.8</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>173.462417</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.830000</td>\n",
              "      <td>1.650000</td>\n",
              "      <td>17.21</td>\n",
              "      <td>2.30</td>\n",
              "      <td>...</td>\n",
              "      <td>108.557848</td>\n",
              "      <td>0.00</td>\n",
              "      <td>179.44</td>\n",
              "      <td>179.44</td>\n",
              "      <td>179.44</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10235.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.470000</td>\n",
              "      <td>5.470000</td>\n",
              "      <td>20.75</td>\n",
              "      <td>2.10</td>\n",
              "      <td>...</td>\n",
              "      <td>56.506804</td>\n",
              "      <td>0.00</td>\n",
              "      <td>105.76</td>\n",
              "      <td>105.76</td>\n",
              "      <td>105.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10401.9</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144.199997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.327774</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>1.928766</td>\n",
              "      <td>0.487946</td>\n",
              "      <td>17.25</td>\n",
              "      <td>1.47</td>\n",
              "      <td>...</td>\n",
              "      <td>112.883333</td>\n",
              "      <td>1.04</td>\n",
              "      <td>98.18</td>\n",
              "      <td>47.96</td>\n",
              "      <td>98.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9557.7</td>\n",
              "      <td>1.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Not Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>127.228453</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>4.272727</td>\n",
              "      <td>1.871999</td>\n",
              "      <td>3.876364</td>\n",
              "      <td>17.12</td>\n",
              "      <td>4.23</td>\n",
              "      <td>...</td>\n",
              "      <td>93.008849</td>\n",
              "      <td>1.04</td>\n",
              "      <td>266.68</td>\n",
              "      <td>266.68</td>\n",
              "      <td>170.99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9681.7</td>\n",
              "      <td>1.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2591</th>\n",
              "      <td>Not Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.259511</td>\n",
              "      <td>1.210066</td>\n",
              "      <td>20.73</td>\n",
              "      <td>1.93</td>\n",
              "      <td>...</td>\n",
              "      <td>98.737291</td>\n",
              "      <td>0.00</td>\n",
              "      <td>96.58</td>\n",
              "      <td>96.58</td>\n",
              "      <td>96.58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9708.4</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2592</th>\n",
              "      <td>Not Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.150000</td>\n",
              "      <td>1.140000</td>\n",
              "      <td>20.75</td>\n",
              "      <td>1.75</td>\n",
              "      <td>...</td>\n",
              "      <td>137.847413</td>\n",
              "      <td>0.00</td>\n",
              "      <td>61.66</td>\n",
              "      <td>61.66</td>\n",
              "      <td>61.66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9904.4</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2593</th>\n",
              "      <td>Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>168.039993</td>\n",
              "      <td>129.730177</td>\n",
              "      <td>96.699997</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>1.560000</td>\n",
              "      <td>1.700000</td>\n",
              "      <td>19.80</td>\n",
              "      <td>6.07</td>\n",
              "      <td>...</td>\n",
              "      <td>42.813953</td>\n",
              "      <td>0.00</td>\n",
              "      <td>164.65</td>\n",
              "      <td>164.65</td>\n",
              "      <td>121.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9014.5</td>\n",
              "      <td>1.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2594</th>\n",
              "      <td>Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.287232</td>\n",
              "      <td>0.715211</td>\n",
              "      <td>19.25</td>\n",
              "      <td>1.83</td>\n",
              "      <td>...</td>\n",
              "      <td>41.669091</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9532.2</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2595</th>\n",
              "      <td>Failure</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.093197</td>\n",
              "      <td>4.093197</td>\n",
              "      <td>19.26</td>\n",
              "      <td>2.19</td>\n",
              "      <td>...</td>\n",
              "      <td>110.016000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10165.0</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2596 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1c62efd-dfea-4448-8d85-e410d41ec182')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1c62efd-dfea-4448-8d85-e410d41ec182 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1c62efd-dfea-4448-8d85-e410d41ec182');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psBCE_7CkT4x",
        "outputId": "44b2b944-8073-4d25-c421-57ca9e16316b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "labels = []\n",
        "for i in range(len(filtered_data)):\n",
        "  labels.append(filtered_data.values[i][0])\n",
        "labels = np.reshape(np.array(labels), (-1, 1))\n",
        "oneHotEncoder = OneHotEncoder(sparse=False )\n",
        "encoded_labels = oneHotEncoder.fit_transform(labels)\n",
        "encoded_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZFepnfURYDm",
        "outputId": "cacf8127-b2b3-484d-deff-dae2e59de158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n"
          ]
        }
      ],
      "source": [
        "for el in encoded_labels:\n",
        "  print(el)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3LIe6XddE3q",
        "outputId": "892bf1c6-9fbe-4a7d-ef2c-b80575cb318a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2596, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "np.array(filtered_data).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbdt_3y5e39f"
      },
      "outputs": [],
      "source": [
        "input_data = []\n",
        "for i in range(len(filtered_data)):\n",
        "  input_data.append(filtered_data.values[i][1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6qp5QYDkVQ-",
        "outputId": "9071a94c-b888-4039-c3ca-759399ede311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2076, 25) (520, 25) (2076, 2) (520, 2)\n"
          ]
        }
      ],
      "source": [
        "input_data = np.array(input_data)\n",
        "scaler = MinMaxScaler((-1, 1))\n",
        "input_data = scaler.fit_transform(input_data)\n",
        "\n",
        "encoded_labels = np.array(encoded_labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_data, encoded_labels, test_size=0.2)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqK0L5ZWSDpo"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(len(filters) -1)))\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Dropout(.5))\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Dropout(.5))\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(len(tags), activation=tf.nn.softmax))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=.001),metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFgHwRXbSc69",
        "outputId": "d5772e5b-d685-43d2-e27f-6aa7d9940d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96hUluPgoXG5",
        "outputId": "f2c0fdf8-d017-4268-95c0-bb49fb6be553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 7s 7ms/step - loss: 0.6337 - accuracy: 0.6627 - val_loss: 0.6107 - val_accuracy: 0.6538\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6193 - accuracy: 0.6689 - val_loss: 0.6085 - val_accuracy: 0.7276\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5973 - accuracy: 0.6735 - val_loss: 0.5698 - val_accuracy: 0.7244\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5925 - accuracy: 0.6899 - val_loss: 0.5635 - val_accuracy: 0.7372\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5817 - accuracy: 0.7029 - val_loss: 0.5944 - val_accuracy: 0.7244\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5772 - accuracy: 0.7046 - val_loss: 0.5652 - val_accuracy: 0.7404\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5682 - accuracy: 0.7063 - val_loss: 0.5893 - val_accuracy: 0.6923\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7069 - val_loss: 0.5489 - val_accuracy: 0.7372\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5589 - accuracy: 0.7262 - val_loss: 0.5718 - val_accuracy: 0.7500\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5645 - accuracy: 0.7177 - val_loss: 0.5393 - val_accuracy: 0.7532\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5542 - accuracy: 0.7273 - val_loss: 0.5496 - val_accuracy: 0.7436\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7200 - val_loss: 0.5661 - val_accuracy: 0.6987\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5555 - accuracy: 0.7256 - val_loss: 0.5449 - val_accuracy: 0.7468\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5474 - accuracy: 0.7273 - val_loss: 0.5383 - val_accuracy: 0.7468\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5518 - accuracy: 0.7307 - val_loss: 0.5696 - val_accuracy: 0.6859\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5502 - accuracy: 0.7217 - val_loss: 0.5351 - val_accuracy: 0.7564\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5478 - accuracy: 0.7245 - val_loss: 0.5440 - val_accuracy: 0.7436\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5527 - accuracy: 0.7205 - val_loss: 0.5458 - val_accuracy: 0.7436\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5420 - accuracy: 0.7302 - val_loss: 0.5485 - val_accuracy: 0.7436\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5400 - accuracy: 0.7313 - val_loss: 0.5356 - val_accuracy: 0.7532\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5564 - accuracy: 0.7217 - val_loss: 0.5334 - val_accuracy: 0.7468\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7353 - val_loss: 0.5544 - val_accuracy: 0.7115\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5315 - accuracy: 0.7455 - val_loss: 0.5367 - val_accuracy: 0.7468\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.7370 - val_loss: 0.5352 - val_accuracy: 0.7468\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5465 - accuracy: 0.7234 - val_loss: 0.5459 - val_accuracy: 0.7404\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5376 - accuracy: 0.7370 - val_loss: 0.5357 - val_accuracy: 0.7564\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5483 - accuracy: 0.7290 - val_loss: 0.5344 - val_accuracy: 0.7404\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5330 - accuracy: 0.7341 - val_loss: 0.5351 - val_accuracy: 0.7436\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5347 - accuracy: 0.7421 - val_loss: 0.5462 - val_accuracy: 0.7244\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5292 - accuracy: 0.7415 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7466 - val_loss: 0.5554 - val_accuracy: 0.7436\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.7415 - val_loss: 0.5388 - val_accuracy: 0.7436\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7398 - val_loss: 0.5432 - val_accuracy: 0.7436\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7528 - val_loss: 0.5599 - val_accuracy: 0.7115\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7358 - val_loss: 0.5255 - val_accuracy: 0.7468\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5268 - accuracy: 0.7409 - val_loss: 0.5280 - val_accuracy: 0.7660\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.7517 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7449 - val_loss: 0.5482 - val_accuracy: 0.7340\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5222 - accuracy: 0.7466 - val_loss: 0.5312 - val_accuracy: 0.7532\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5090 - accuracy: 0.7630 - val_loss: 0.5533 - val_accuracy: 0.7276\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.7432 - val_loss: 0.5319 - val_accuracy: 0.7404\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5097 - accuracy: 0.7528 - val_loss: 0.5915 - val_accuracy: 0.6795\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5235 - accuracy: 0.7409 - val_loss: 0.5296 - val_accuracy: 0.7532\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5217 - accuracy: 0.7506 - val_loss: 0.5431 - val_accuracy: 0.7468\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.7494 - val_loss: 0.5379 - val_accuracy: 0.7372\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5171 - accuracy: 0.7540 - val_loss: 0.5309 - val_accuracy: 0.7436\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5081 - accuracy: 0.7534 - val_loss: 0.5554 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5256 - accuracy: 0.7506 - val_loss: 0.5389 - val_accuracy: 0.7468\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5164 - accuracy: 0.7630 - val_loss: 0.5440 - val_accuracy: 0.7468\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5159 - accuracy: 0.7585 - val_loss: 0.5361 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "kBD79C3SqpYo",
        "outputId": "c5e7e25b-187e-473f-ac20-c2fc249ea4cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACkB0lEQVR4nOzdd3xb5fX48c+VvHe87cSJsycZhExGGIFAKJtCCxRKCy00KSOFL1B+ZbU0FFqgZUMboIWWsAkrQAIEQhKyyN7LWR6xHe8t3d8fj66GLdmSLFuSfd6vl19SpCvp2kmso3POcx5N13UdIYQQQohexBTsExBCCCGE6G4SAAkhhBCi15EASAghhBC9jgRAQgghhOh1JAASQgghRK8jAZAQQggheh0JgIQQQgjR60gAJIQQQoheRwIgIYQQQvQ6EgAJIcKWpmk88MADPj/uwIEDaJrGK6+8EvBzEkKEBwmAhBCd8sorr6BpGpqmsXz58jb367pOXl4emqbxox/9KAhn6L+vv/4aTdN4++23g30qQogAkwBICBEQMTEx/Pe//21z+7Jlyzh8+DDR0dFBOCshhHBPAiAhREDMnj2bt956i5aWFpfb//vf/zJx4kSys7ODdGZCCNGWBEBCiID46U9/SllZGV988YX9tqamJt5++22uuuoqt4+pra3ld7/7HXl5eURHRzN8+HD++te/ouu6y3GNjY3cfvvtZGRkkJiYyIUXXsjhw4fdPueRI0f4xS9+QVZWFtHR0YwePZoFCxYE7ht1Y9++ffz4xz8mNTWVuLg4pk6dyscff9zmuKeeeorRo0cTFxdHnz59OOmkk1yyZtXV1dx2223k5+cTHR1NZmYmZ599NuvXr+/S8xeiN5IASAgREPn5+UybNo3//e9/9ts+/fRTKisr+clPftLmeF3XufDCC3niiSc499xzefzxxxk+fDh33nkn8+bNczn2hhtu4Mknn+Scc87hkUceITIykvPPP7/NcxYXFzN16lSWLFnC3Llz+fvf/86QIUP45S9/yZNPPhnw79l4zenTp/PZZ5/xm9/8hocffpiGhgYuvPBC3nvvPftxL730ErfccgujRo3iySef5MEHH2T8+PF8//339mNuuukmnnvuOS677DKeffZZ7rjjDmJjY9m+fXuXnLsQvZouhBCd8PLLL+uAvmbNGv3pp5/WExMT9bq6Ol3Xdf3HP/6xfsYZZ+i6rusDBgzQzz//fPvj3n//fR3Q//SnP7k83+WXX65rmqbv2bNH13Vd37Bhgw7ov/nNb1yOu+qqq3RAv//+++23/fKXv9RzcnL00tJSl2N/8pOf6MnJyfbz2r9/vw7oL7/8crvf21dffaUD+ltvveXxmNtuu00H9G+//dZ+W3V1tT5w4EA9Pz9ft1gsuq7r+kUXXaSPHj263ddLTk7W58yZ0+4xQojAkAyQECJgrrjiCurr6/noo4+orq7mo48+8lj++uSTTzCbzdxyyy0ut//ud79D13U+/fRT+3FAm+Nuu+02lz/rus4777zDBRdcgK7rlJaW2r9mzZpFZWVll5SSPvnkEyZPnswpp5xivy0hIYFf/epXHDhwgG3btgGQkpLC4cOHWbNmjcfnSklJ4fvvv+fo0aMBP08hhCsJgIQQAZORkcHMmTP573//y7vvvovFYuHyyy93e2xBQQG5ubkkJia63D5y5Ej7/calyWRi8ODBLscNHz7c5c/Hjh2joqKCF198kYyMDJev66+/HoCSkpKAfJ+tv4/W5+Lu+7jrrrtISEhg8uTJDB06lDlz5vDdd9+5PObRRx9ly5Yt5OXlMXnyZB544AH27dsX8HMWQkBEsE9ACNGzXHXVVdx4440UFRVx3nnnkZKS0i2va7VaAbjmmmu47rrr3B4zduzYbjkXd0aOHMnOnTv56KOPWLx4Me+88w7PPvss9913Hw8++CCgMminnnoq7733Hp9//jmPPfYYf/nLX3j33Xc577zzgnbuQvREkgESQgTUJZdcgslkYtWqVR7LXwADBgzg6NGjVFdXu9y+Y8cO+/3GpdVqZe/evS7H7dy50+XPxgoxi8XCzJkz3X5lZmYG4lts8320Phd33wdAfHw8V155JS+//DIHDx7k/PPPtzdNG3JycvjNb37D+++/z/79+0lLS+Phhx8O+HkL0dtJACSECKiEhASee+45HnjgAS644AKPx82ePRuLxcLTTz/tcvsTTzyBpmn2jIdx+Y9//MPluNarusxmM5dddhnvvPMOW7ZsafN6x44d8+fb6dDs2bNZvXo1K1eutN9WW1vLiy++SH5+PqNGjQKgrKzM5XFRUVGMGjUKXddpbm7GYrFQWVnpckxmZia5ubk0NjZ2ybkL0ZtJCUwIEXCeSlDOLrjgAs444wzuvfdeDhw4wLhx4/j888/54IMPuO222+w9P+PHj+enP/0pzz77LJWVlUyfPp2lS5eyZ8+eNs/5yCOP8NVXXzFlyhRuvPFGRo0aRXl5OevXr2fJkiWUl5f79f2888479oxO6+/z7rvv5n//+x/nnXcet9xyC6mpqbz66qvs37+fd955B5NJfc4855xzyM7O5uSTTyYrK4vt27fz9NNPc/7555OYmEhFRQX9+vXj8ssvZ9y4cSQkJLBkyRLWrFnD3/72N7/OWwjRjuAuQhNChDvnZfDtab0MXtfVcvHbb79dz83N1SMjI/WhQ4fqjz32mG61Wl2Oq6+v12+55RY9LS1Nj4+P1y+44AL90KFDbZbB67quFxcX63PmzNHz8vL0yMhIPTs7Wz/rrLP0F1980X6Mr8vgPX0ZS9/37t2rX3755XpKSooeExOjT548Wf/oo49cnuuFF17QTzvtND0tLU2Pjo7WBw8erN955516ZWWlruu63tjYqN955536uHHj9MTERD0+Pl4fN26c/uyzz7Z7jkII/2i63mrkqhBCCCFEDyc9QEIIIYTodSQAEkIIIUSvIwGQEEIIIXodCYCEEEII0etIACSEEEKIXkcCICGEEEL0OjII0Q2r1crRo0dJTExE07Rgn44QQgghvKDrOtXV1eTm5tqHkHoiAZAbR48eJS8vL9inIYQQQgg/HDp0iH79+rV7jARAbiQmJgLqB5iUlBTksxFCCCGEN6qqqsjLy7O/j7dHAiA3jLJXUlKSBEBCCCFEmPGmfUWaoIUQQgjR60gAJIQQQoheRwIgIYQQQvQ60gMkhBBCdBOr1UpTU1OwTyNsRUZGYjabA/JcEgAJIYQQ3aCpqYn9+/djtVqDfSphLSUlhezs7E7P6ZMASAghhOhiuq5TWFiI2WwmLy+vwyF9oi1d16mrq6OkpASAnJycTj2fBEBCCCFEF2tpaaGuro7c3Fzi4uKCfTphKzY2FoCSkhIyMzM7VQ6TEFQIIYToYhaLBYCoqKggn0n4MwLI5ubmTj2PBEBCCCFEN5H9JTsvUD9DCYCEEEII0etIACSEEEKIbpOfn8+TTz4Z7NOQAEgIIYQQbWma1u7XAw884Nfzrlmzhl/96leBPVk/yCqwbqTrOofK64kwa+SmxAb7dIQQQgiPCgsL7dcXLlzIfffdx86dO+23JSQk2K/ruo7FYiEiouOwIiMjI7An6ifJAHWjhz/ezmmPfcUrKw4E+1SEEEKIdmVnZ9u/kpOT0TTN/ucdO3aQmJjIp59+ysSJE4mOjmb58uXs3buXiy66iKysLBISEpg0aRJLlixxed7WJTBN0/jnP//JJZdcQlxcHEOHDmXRokVd/v1JANSNRuUmAbB6f3mQz0QIIUQw6bpOXVNLUL50XQ/Y93H33XfzyCOPsH37dsaOHUtNTQ2zZ89m6dKl/PDDD5x77rlccMEFHDx4sN3nefDBB7niiivYtGkTs2fP5uqrr6a8vGvfK6UE1o0m5acCsOVIJXVNLcRFyY9fCCF6o/pmC6Pu+ywor73toVkBe/956KGHOPvss+1/Tk1NZdy4cfY///GPf+S9995j0aJFzJ071+Pz/PznP+enP/0pAH/+85/5xz/+werVqzn33HMDcp7uSAaoG/XrE0tOcgwtVp0NByuCfTpCCCFEp5x00kkuf66pqeGOO+5g5MiRpKSkkJCQwPbt2zvMAI0dO9Z+PT4+nqSkJPuWF11FUhDdSNM0JuWnsmjjUVYfKGf6kPRgn5IQQoggiI00s+2hWUF77UCJj493+fMdd9zBF198wV//+leGDBlCbGwsl19+OU1NTe0+T2RkpMufNU3r8k1jJQDqZpMG2gIg6QMSQoheS9O0HtkG8d133/Hzn/+cSy65BFAZoQMHDgT3pDyQElg3m2zrA/rhYAXNlq6NboUQQojuNHToUN599102bNjAxo0bueqqq7o8k+MvCYC62dDMBFLiIqlvtrDlSGWwT0cIIYQImMcff5w+ffowffp0LrjgAmbNmsWJJ54Y7NNyS9MDuR6uh6iqqiI5OZnKykqSkpIC/vw3vLqWJduL+f3sEfzqtMEBf34hhBChpaGhgf379zNw4EBiYmKCfTphrb2fpS/v35IBCoLJA/sAsHr/8SCfiRBCCNE7SQAUBMY8oLUF5VitkoATQgghupsEQEEwpm8ysZFmKuqa2XOsJtinI4QQQvQ6EgAFQaTZxIT+KQB8L8vhhRBCiG4nAVCQTB6oymBrJAASQgghup0EQEFizANac6A8oBvTCSGEEKJjEgAFyYT+fYgwaRRWNnD4eH2wT0cIIYToVSQACpLYKDNj+iYDKgskhBBCiO4jAVAQ2fuAJAASQgghupUEQEFk9AHJSjAhhBCie0kAFEQn5auJ0PuO1VJa0xjksxFCCCEcNE1r9+uBBx7o1HO///77ATtXf0QE9dV7uZS4KIZnJbKzuJq1B8o5d0xOsE9JCCGEAKCwsNB+feHChdx3333s3LnTfltCQkIwTitgJAMUZJNkXzAhhBAhKDs72/6VnJyMpmkut73xxhuMHDmSmJgYRowYwbPPPmt/bFNTE3PnziUnJ4eYmBgGDBjA/PnzAcjPzwfgkksuQdM0+5+7m2SAgmxSfiqvrToojdBCCNGb6Do01wXntSPjQNM69RSvv/469913H08//TQTJkzghx9+4MYbbyQ+Pp7rrruOf/zjHyxatIg333yT/v37c+jQIQ4dOgTAmjVryMzM5OWXX+bcc8/FbDYH4rvymQRAQWasBNt6tJKaxhYSouWvRAgherzmOvhzbnBe+/dHISq+U09x//3387e//Y1LL70UgIEDB7Jt2zZeeOEFrrvuOg4ePMjQoUM55ZRT0DSNAQMG2B+bkZEBQEpKCtnZ2Z06j86QEliQ5STHkpcai1WH9QVSBhNCCBHaamtr2bt3L7/85S9JSEiwf/3pT39i7969APz85z9nw4YNDB8+nFtuuYXPP/88yGfdlqQbQsCk/FQOlR9h9f5yThuWEezTEUII0dUi41QmJliv3Qk1NTUAvPTSS0yZMsXlPqOcdeKJJ7J//34+/fRTlixZwhVXXMHMmTN5++23O/XagSQBUAiYnJ/Ku+uPsFr6gIQQonfQtE6XoYIlKyuL3Nxc9u3bx9VXX+3xuKSkJK688kquvPJKLr/8cs4991zKy8tJTU0lMjISi8XSjWfdlgRAIWCSrQ9ow6EKGlssREcEpyFMCCGE8MaDDz7ILbfcQnJyMueeey6NjY2sXbuW48ePM2/ePB5//HFycnKYMGECJpOJt956i+zsbFJSUgC1Emzp0qWcfPLJREdH06dPn27/HqQHKAQMSo8nPSGKphYrmw9XBvt0hBBCiHbdcMMN/POf/+Tll1/mhBNOYMaMGbzyyisMHDgQgMTERB599FFOOukkJk2axIEDB/jkk08wmVTY8be//Y0vvviCvLw8JkyYEJTvQdN1XQ/KK4ewqqoqkpOTqaysJCkpqVte86b/rGPx1iL+79zh/Ob0Id3ymkIIIbpHQ0MD+/fvZ+DAgcTExAT7dMJaez9LX96/JQMUIuwbo8q+YEIIIUSXkwAoRBgB0NqC41iskpQTQgghupIEQCFiZE4SCdERVDe0sKOoKtinI4QQQvRoQQ+AnnnmGfLz84mJiWHKlCmsXr263eMrKiqYM2cOOTk5REdHM2zYMD755BP7/fPnz2fSpEkkJiaSmZnJxRdf7LJ5W6gymzROHKC64KUMJoQQQnStoAZACxcuZN68edx///2sX7+ecePGMWvWLEpKStwe39TUxNlnn82BAwd4++232blzJy+99BJ9+/a1H7Ns2TLmzJnDqlWr+OKLL2hubuacc86htra2u74tv03OtwVAB2QitBBC9ESy7qjzAvUzDOocoMcff5wbb7yR66+/HoDnn3+ejz/+mAULFnD33Xe3OX7BggWUl5ezYsUKIiMjAdrsIrt48WKXP7/yyitkZmaybt06TjvttK75RgJk8sA0AFYfKEfXdbROblYnhBAiNBgTkpuamoiNjQ3y2YS3ujq1iawRB/graAFQU1MT69at45577rHfZjKZmDlzJitXrnT7mEWLFjFt2jTmzJnDBx98QEZGBldddRV33XWXx91kKyvVXJ3U1FSP59LY2EhjY6P9z1VVwenBGdsvmSiziWPVjRSU1ZGfHp5TQoUQQriKiIggLi6OY8eOERkZaZ+HI7yn6zp1dXWUlJSQkpLS6V3kgxYAlZaWYrFYyMrKcrk9KyuLHTt2uH3Mvn37+PLLL7n66qv55JNP2LNnD7/5zW9obm7m/vvvb3O81Wrltttu4+STT2bMmDEez2X+/Pk8+OCDnfuGAiAm0sy4vGTWHDjO6gPlEgAJIUQPoWkaOTk57N+/n4KCgmCfTlgL1C7yYbUVhtVqJTMzkxdffBGz2czEiRM5cuQIjz32mNsAaM6cOWzZsoXly5e3+7z33HMP8+bNs/+5qqqKvLy8gJ+/Nyblp6oAaH85V5wUnHMQQggReFFRUQwdOpSmpqZgn0rYioyM7HTmxxC0ACg9PR2z2UxxcbHL7cXFxR4ju5ycnDbf/MiRIykqKqKpqYmoqCj77XPnzuWjjz7im2++oV+/fu2eS3R0NNHR0Z34bgJnUn4qsJcNhyqCfSpCCCECzGQyySToEBG0ImRUVBQTJ05k6dKl9tusVitLly5l2rRpbh9z8skns2fPHqxWq/22Xbt2kZOTYw9+dF1n7ty5vPfee3z55Zf2fUnCxfDsRAAKympptlg7OFoIIYQQ/ghqF9a8efN46aWXePXVV9m+fTs333wztbW19lVh1157rUuT9M0330x5eTm33noru3bt4uOPP+bPf/4zc+bMsR8zZ84cXnvtNf773/+SmJhIUVERRUVF1NfXd/v354/spBjiosw0W3QOldcF+3SEEEKIHimoPUBXXnklx44d47777qOoqIjx48ezePFie2P0wYMHXTrl8/Ly+Oyzz7j99tsZO3Ysffv25dZbb+Wuu+6yH/Pcc88BcPrpp7u81ssvv8zPf/7zLv+eOstk0hiUEc+WI1XsPVbLoIyEYJ+SEEII0ePIbvBuBGM3eGe3vvEDH2w4yt3njeCmGYO7/fWFEEKIcCS7wYe5wbasz96SmiCfiRBCCNEzSQAUguwB0DEJgIQQQoiuIAFQCBqcqQYg7j1WK/vGCCGEEF1AAqAQlJ8Wj6ZBZX0zZbUyMEsIIYQINAmAQlBMpJm8PnGA9AEJIYQQXUECoBA1OMNRBhNCCCFEYEkAFKKkEVoIIYToOhIAhajBmRIACSGEEF1FAqAQJRkgIYQQoutIABSijB6gw8fraWi2BPlshBBCiJ5FAqAQlRofRUpcJLoO+0ulEVoIIYQIJAmAQpSmaVIGE0IIIbqIBEAhzL4UvkQyQEIIIUQgSQAUwiQDJIQQQnQNCYBCmARAQgghRNeQACiEGbOA9h2rxWqVTVGFEEKIQJEAqLu1NHp9aF6fWCLNGvXNFgqrGrrwpIQQQojeRQKg7lS0GZ48ATa/DXrHGZ0Is4n8NKMRWspgQgghRKBIANSdVj4DNcXwzi/hjauhuqjDh0gfkBBCCBF4EgB1pwufgjP+H5giYefH8MwU2PC/drNBgzONXeElABJCCCECRQKg7mSOhBl3wq+XQc54aKiA92+C/14BVUfdPsSeAZJZQEIIIUTASAAUDFmj4YalcNb9YI6C3Z/DM1Nh/X/aZIOkBCaEEEIEngRAwWKOgFPnwa+/hb4TobESFs2F1y6DikP2wwbZpkGXVDdS1dAcrLMVQgghehQJgIItcwT84nM4+yEwR8PepfDsNNj1OQCJMZFkJUUDah6QEEIIITpPAqBQYI6Ak2+Fm7+DfpOhqRqWPmS/29EHJGUwIYQQIhAkAAol6UPhgifV9aoj9pulD0gIIYQILAmAQk18prqsLwdLC+C0K7wEQEIIIURASAAUauJSQbP9tdSVAo49wfZKD5AQQggREBIAhRqTGeLS1fWaEsBRAisoq6XZYg3WmQkhhBA9hgRAoSg+Q13WqgAoOymGuCgzzRadQ+V1QTwxIYQQomeQACgUJRgBkCqBmUyafR6QlMGEEEKIzpMAKBQZjdC2Ehg4ymB7ZCm8EEII0WkSAIWiBFsAVNs2AJKVYEIIIUTnSQAUiuKNJuhj9pskABJCCCECRwKgUGSUwGqdAqBMWw9QSQ16qw1ThRBCCOEbCYBCkZsSWH5aPJoGVQ0tlNY0BenEhBBCiJ5BAqBQZCyDdyqBxUSayesTB0gZTAghhOgsCYBCUYJTCczqGHwoW2IIIYQQgSEBUCgyJkHrFqg/br/ZsSu8zAISQgghOkMCoFAUEQUxKeq6SyO0rAQTQgghAkECoFAls4CEEEKILiMBUKhyOw1a9QAdqainvskSjLMSQgghegQJgEKVMQzRqQSWGh9FSlwkug77S6UPSAghhPBX0AOgZ555hvz8fGJiYpgyZQqrV69u9/iKigrmzJlDTk4O0dHRDBs2jE8++aRTzxmSEtoOQ9Q0TcpgQgghRAAENQBauHAh8+bN4/7772f9+vWMGzeOWbNmUVJS4vb4pqYmzj77bA4cOMDbb7/Nzp07eemll+jbt6/fzxmy3JTAQJbCCyGEEIEQ1ADo8ccf58Ybb+T6669n1KhRPP/888TFxbFgwQK3xy9YsIDy8nLef/99Tj75ZPLz85kxYwbjxo3z+zlDVoJtGKJTBgicG6GlBCaEEEL4K2gBUFNTE+vWrWPmzJmOkzGZmDlzJitXrnT7mEWLFjFt2jTmzJlDVlYWY8aM4c9//jMWi8Xv5wRobGykqqrK5Svo7NOgW2eAjFlAkgESQggh/BW0AKi0tBSLxUJWVpbL7VlZWRQVFbl9zL59+3j77bexWCx88skn/OEPf+Bvf/sbf/rTn/x+ToD58+eTnJxs/8rLy+vkdxcA9g1RS11uNmYB7SutwWqVTVGFEEIIfwS9CdoXVquVzMxMXnzxRSZOnMiVV17Jvffey/PPP9+p573nnnuorKy0fx06dChAZ9wJ9hJYCTjt/p7XJ5ZIs0ZDs5WjlfVBOjkhhBAivEUE64XT09Mxm80UFxe73F5cXEx2drbbx+Tk5BAZGYnZbLbfNnLkSIqKimhqavLrOQGio6OJjo7uxHfTBYwSWEsDNFZDTBIAEWYT+Wnx7C6pYe+xWvrZNkgVQgghhPeClgGKiopi4sSJLF261H6b1Wpl6dKlTJs2ze1jTj75ZPbs2YPVaYPQXbt2kZOTQ1RUlF/PGbKi4iFSrfjy2AgtfUBCCCGEX4JaAps3bx4vvfQSr776Ktu3b+fmm2+mtraW66+/HoBrr72We+65x378zTffTHl5Obfeeiu7du3i448/5s9//jNz5szx+jnDiqeVYJmyFF4IIYTojKCVwACuvPJKjh07xn333UdRURHjx49n8eLF9ibmgwcPYjI5YrS8vDw+++wzbr/9dsaOHUvfvn259dZbueuuu7x+zrASnwnHD3heCSYBkBBCCOEXTdd1WUrUSlVVFcnJyVRWVpKUlBS8E3njatjxEZz/N5h0g/3mjYcquOiZ70hPiGbNvWehaVrwzlEIIYQIEb68f4fVKrBexz4LyLUENiQzgagIE6U1jSxcEwIr1oQQQogwIwFQKIt3WgrvfHN0BPPOHgbAgx9uY480QwshhBA+kQAolLnZENXwq1MHccqQdOqbLdzyvx9obLF088kJIYQQ4UsCoFDmoQQGYDJpPH7FOFLjo9hWWMVfPt3ZzScnhBBChC8JgEKZPQPkfif7zKQYHrt8LAALvtvPVzvDbMd7IYQQIkgkAApl7WSADGeNzOLn0/MBuOPNjZRUN3TDiQkhhBDhTQKgUGYEQE3V0Ox536+7zxvBiOxEymqb+N2bG2WTVCGEEKIDEgCFsphkMEep624aoe2HRZp56qcTiIk08e3uUv61fL/3r7HxDXhyLBRt7uTJCiGEEOFDAqBQpmlqGjS0WwYDGJqVyB9+NAqARz/bwebDld69xua3oKIAdi3uzJkKIYQQYUUCoFAXn64uPTRCO7tqcn/OHZ1Ns0Xnljd+oLaxpePnrzxiuzzciZMUQgghwosEQKGunVlArWmaxiOXnUBOcgz7S2t5YNHWjp+/6qi6lABICCFELyIBUKizl8C8W+KeEhfFE1eOR9PgrXWH+XDjUc8HN1ZDo61UViFbagghhOg9JAAKdQnGdhgdZ4AMUwelMfeMIQD8/r3NlNY0uj+wyik4qjwMsi+uEEKIXkICoFDnYwbIcOtZQxmRnUh1Qwufbilyf5Bz2au5FuqP+3mSQgghRHiRACjUxfueAQKIMJu4ZEJfAD7zFABVHXH9s/QBCSFE55Ts8PkDqwgOCYBCnR8lMMOs0dkArNpXRmVdc9sDqlr1B0kAJIQQ/qsuguemw2uXBftMhBckAAp1fpbAAPLT4xmelUiLVWfpjuK2B7QOeCQAEkII/x0vAN0C5fuCfSbCCxIAhTpjGXx9OVjcZHE6MGt0FgCfbXVTBjMyQDEp6rLyoB8nKIQQAoDGKnXZVANWS3DPRXRIAqBQF9sHNNtfU12Zzw+fNUaVwZbtOkZ9U6v/kEYPUN5kdSkZICGE8F+D0wT+xurgnYfwigRAoc5khjjbNGg/ymCjcpLo1yeWhmYry3a16iMyMkB5U9SlBEBCCOE/56BHAqCQJwFQOLBPg/Y9ANI0zd4M/blzGayhypGu7T9VXXY2ACrZ7voJSAghehPjdypIABQGJAAKB8ZS+A42RPXECICWbC+m2WJVNxrlr5gUSB+urlcXQUuTf+dYsgOenQpvXuff44UQItw1OAdAVZ6PEyFBAqBwYJ8F5N9siYkD+pAWH0VVQwvf7ytXNxoBUFJfteGqORrQobqdrTPac2Stujy2w7/HCyFEuJMMUFiRACgc+LAhqjtmk8Y5ttVgi7cWqhuNXeCT+4KmQXI/9Wd/9wQzln3WHpMtNYQQvZNkgMKKBEDhoJMlMIBz7H1AxVituqMBOilXXRoBkL99QGV71aW1BRoq/D5PIYQIW9IEHVYkAAoHnWiCNkwfnEZCdAQl1Y1sOFwBVbZAJ8kW+CTnqUt/AyDnwV+1vi/XF0KIsCclsLAiAVA4CEAGKDrCzBkjVCD12daithmgFCMA8qMEpuutAiD/z1MIIcKW8yrYBimBhToJgMKBnxuitmafCr2lCN25Bwg6VwKrKVGTTw0SAAkheiPJAIUVCYDCgXMTtNXq99OcPjyTqAgTB8pq0Stbl8A6EQC13vdGAiAhRG8kPUBhRQKgcGBkgHQL1B/3+2kSoiM4dUg6idRjaq5VN9qboJ1KYL6u4irf6/rn2lK/z1EIIcKSrssqsDAjAVA4MEeqPcGgU43QoIYi5mi2JuXYPhAVp64n2UphzXW+B1mSARJC9HYtDWB12rBaMkAhTwKgcBGgPqCzRmaSq6lhiE3xOY47ImMg3lZq87UR2lgCn9JfXdZJBkgI0cu0bnqWDFDIkwAoXBjBiR8bojpLS4hmWkYDAEWkud7pbx+QkQEyNlWVEpgQordpnfGRDFDIkwAoXCQEJgMEMDmtHoCdtYmud/gTADkvgbcHQFICE0L0Mo2tNoKWACjkSQAULgKUAQIYFqNSsxurEyitaXTckezHLCBjCbxmgr4T1W0SAAkhehujBBYRqy4lAAp5EgCFiwD1AAHENxQBcNSaypJtxY47/NkPzMj+JPdzPL6uHKyWTp+nEEKEDaPnx5it1lQjvwdDnARA4SKAJTBjCnQhaWoqtMGfEpixBD51EMSmAhqgqyBICCF6CyPjY6yodb5NhCQJgMJFoEpgum7fCb5QT+W7PWVUN9iWbqb4sR+YkQFKHQzmCIhLVX+WMpgQojcxSmDx6WCOUtclAAppEgCFC+dp0J3RUAm2IYixaXk0Wax8tdP2nEYPUE0RtDR6eIJWjCXwaYPVZVx6YM5TCCHCiVECi06CaNsCEwmAQpoEQOEi3hZY1JT4PqnZWZVtD7DYVE4fMwDAUQaLS4OIGNtxR717PnsGaJDtPANYqhNCiHBhZIBiJAAKFxIAhQujBGZp7Nx/Kvsu8H2ZNTobgK93lNDQbAFNc+oD8qIR2nkJfKotA2QEajILSAjRm7hkgJJcbxMhSQKgcBEVB1EJ6npnsitGf09yX8b2TSY7KYbaJgtLt9t6i3xphHZeAt9HZZMkAySE6JUkAAo7QQ+AnnnmGfLz84mJiWHKlCmsXr3a47GvvPIKmqa5fMXExLgcU1NTw9y5c+nXrx+xsbGMGjWK559/vqu/je5hBBedaYQ2SmBJuZhMGpecqFYs/OGDLRRW1vsWADkvgY+Idj1H2Q5DCNGbSAks7AQ1AFq4cCHz5s3j/vvvZ/369YwbN45Zs2ZRUuL5DT4pKYnCwkL7V0FBgcv98+bNY/Hixbz22mts376d2267jblz57Jo0aKu/na6nr0RujMBkKMEBnDrWUMZnZtEeW0Tc//7A5YkH4YhOi+BN8TbtteQEpgQojeRJuiwE9QA6PHHH+fGG2/k+uuvt2dq4uLiWLBggcfHaJpGdna2/SsrK8vl/hUrVnDddddx+umnk5+fz69+9SvGjRvXbmYpbASivGQvgalMT0ykmWevPpHEmAjWFRzn4wKz63Htad3/E6hzFEKIcCMZoLATtACoqamJdevWMXPmTMfJmEzMnDmTlStXenxcTU0NAwYMIC8vj4suuoitW7e63D99+nQWLVrEkSNH0HWdr776il27dnHOOed02ffSbewlsE4EF/YMUK79pgFp8fztx+MA+N8u2wozbwKg1kvgnc9RAiAhRG9iBDvRiSoIgrY7xIuQErQAqLS0FIvF0iaDk5WVRVFRkdvHDB8+nAULFvDBBx/w2muvYbVamT59OocPO96sn3rqKUaNGkW/fv2Iiori3HPP5ZlnnuG0007zeC6NjY1UVVW5fIWkzpbAdN2pB6ivy13njM7m16cN4qiuSljWioMdL7dvvQQenAIgKYEJIXoRKYGFnaA3Qfti2rRpXHvttYwfP54ZM2bw7rvvkpGRwQsvvGA/5qmnnmLVqlUsWrSIdevW8be//Y05c+awZMkSj887f/58kpOT7V95eXnd8e34rrNN0A0V0FynrjtlgAx3zBpOv/5DADC1NNBQ1U4Wx90SeHAsg2+s8n6YohBChDNLs+N3a0yyrAILE0ELgNLT0zGbzRQXF7vcXlxcTHZ2tlfPERkZyYQJE9izZw8A9fX1/P73v+fxxx/nggsuYOzYscydO5crr7ySv/71rx6f55577qGystL+deiQD5uBdqfOZldsW2AQlwaRsW3ujjSbePzqKZSSAsALi772/FzulsADxKSAKaJz5ymEEOHEOdMTnSgZoDARtAAoKiqKiRMnsnTpUvttVquVpUuXMm3aNK+ew2KxsHnzZnJycgBobm6mubkZk8n12zKbzVitVo/PEx0dTVJSkstXSOpsCcxpCbwnWUkxRKepgGbr9m28ucZDMOhuCTyoYYqyHYYQojcxMj2RcWCOlAxQmIgI5ovPmzeP6667jpNOOonJkyfz5JNPUltby/XXXw/AtddeS9++fZk/fz4ADz30EFOnTmXIkCFUVFTw2GOPUVBQwA033ACoJfIzZszgzjvvJDY2lgEDBrBs2TL+/e9/8/jjjwft+wwY+4aofgYW9gCoX7uHJWblQ9lGcrUy/vDBFsb0TWZUbqug0N0SePt5Zqj9xCQDJIToDYxmZyPzIxmgsBDUAOjKK6/k2LFj3HfffRQVFTF+/HgWL15sb4w+ePCgSzbn+PHj3HjjjRQVFdGnTx8mTpzIihUrGDVqlP2YN954g3vuuYerr76a8vJyBgwYwMMPP8xNN93U7d9fwCXYSmBN1dBc77aM1S6jBJbct/3jbJuiTk2r45USK795fR2LfnsKSTGRjmPc9f8Y4iUDJIToRZwboEECoDAR1AAIYO7cucydO9ftfV9//bXLn5944gmeeOKJdp8vOzubl19+OVCnF1qik8AcBZYmFVyk9Pft8W6WwLtlmxF0Zk4jfZtiOVBWx/+9tYnnrjkRTdPUMWUdZIBAAiAhRO/gPAMIJAAKE2G1CqzX07TOlcGqbOMCOiiBGQFQVM1Rnr36RKLMJhZvLeL17w86jjEyQGnuMkCyHYYQohexzwBKcr1sqgGrJTjnJDokAVC4Mcpg/jRCe50BMrbDOMy4vBT+79zhAPzz233ouu55CbxBdoQXQvQmja16gGKceiYlCxSyJAAKN/YMkI8BkK773ANETTG0NHLVlP7ER5k5UFbH6v3lnpfA289ReoCEEL1IQ6W6NAKfiGjVrgASAIUwCYDCjb/9NfXHoaVeXU/sIAMUlwoRtgbrqiPERUVwwTj1mIVrD3leAt/ZcxRCiHBkzwAlO26TPqCQJwFQuEnwM7gwlsDHpUNkTPvHapq9D8jYE+yKSSor9MnmQuqLd6n73DVAg2yHIYToXYwgx7n0JQFQyJMAKNz4WwLztvxlMAKgCjUIcUJeCkMzE2hotrJ352Z1n7v+H3AtgXW0n5gQQoS71nOAwGkYogRAocqvAOjQoUMuG5CuXr2a2267jRdffDFgJyY8sE+D9jMDlORlAJTiaIQG0DSNK07Ks920Xd3XUQaopQGaan07TyGECDet5wA5X2+s7P7zEV7xKwC66qqr+OqrrwAoKiri7LPPZvXq1dx777089NBDAT1B0Yq/G6L6GgDZV4I5tsK45MS+RJg0kuttwa+7JfAAUfFqJDxIH5AQoudrPQcIpAQWBvwKgLZs2cLkyZMBePPNNxkzZgwrVqzg9ddf55VXXgnk+YnW/G0w9nYJvKFVDxBAekI0Z43IIF8rUjd4KoGB035g0gckhOjh3GaAJAAKdX4FQM3NzURHq9U/S5Ys4cILLwRgxIgRFBYWBu7sRFtGCay+HCzN3j/OCGSSOxiCaHATAAH87IRYErQGLJhoSszz/HhZCi+E6C1aD0IECYDCgF8B0OjRo3n++ef59ttv+eKLLzj33HMBOHr0KGlpaQE9QdFKbCpoZnXdl+xKZzJATo3MU1NUPfuoNY2luys8P16Wwgshegt3JTDjeoPsCB+q/AqA/vKXv/DCCy9w+umn89Of/pRx48YBsGjRIntpTHQRk8kpu+JlH5Cu+94DZBzXUg91ZfabIyr2A3BAz1IzgTyRAEgI0RtYrVICC1N+bYZ6+umnU1paSlVVFX369LHf/qtf/Yq4uLiAnZzwID5DTWn2NrioK1crssD7DFBENCRkQ02RaoQ2gi7bEMQDejbf7DpGYWU9OcludqU3jncKnoQQosdpqgFsWfIYd6vAJAMUqvzKANXX19PY2GgPfgoKCnjyySfZuXMnmZmZAT1B4YZ9JZiXAZCR/YnPcD+52RN3fUC2XeD1PgOx6vDOusNuHoj0AAkhegcjw2OKgAinIbOSAQp5fgVAF110Ef/+978BqKioYMqUKfztb3/j4osv5rnnngvoCQo37LOAvCyB+Vr+MrgLgGwZoCEjVNnzzbWHsVrdDDvsTAls/zfw7eMyRFEIEfqcy1+a5rhdAqCQ51cAtH79ek499VQA3n77bbKysigoKODf//43//jHPwJ6gsINX2cBBSoActoF/sQJE0mIjuBgeR3f7y93c46dWAa/6BZY+iAcWu37Y4UQoju5a4AGKYGFAb8CoLq6OhITVXT7+eefc+mll2IymZg6dSoFBQUBPUHhhq97bfm6DYah9TBEp13gYzIH2zdIfdNdM7S/GaDmejh+QF2vOOjbY4UQoru5a4AGyQCFAb8CoCFDhvD+++9z6NAhPvvsM8455xwASkpKSEpK6uDRotN8LoH5uATeYGyHYdsPrPUu8Fc6bZBaWd9qJpERANWVqVUS3irfh72hsPqob+crhBDdTQKgsOVXAHTfffdxxx13kJ+fz+TJk5k2bRqgskETJkwI6AkKN+wbovrYBJ3k5RBEQ+sSWLlqgDb2ABvXL5nhWYk0tlj5cGOrYMWYBG1tgYYK71+zdLfTectQTSFEiOuoBNZUA1ZL956T8IpfAdDll1/OwYMHWbt2LZ999pn99rPOOosnnngiYCcnPEgwykteZoCMAMbXDJBRAqstgeYGRwbItgWGpmn8+CQVJLUpg0VEQXSy7fE+9AGV7XFclwyQECLUecoAOQdETTXddz7Ca34FQADZ2dlMmDCBo0eP2neGnzx5MiNGjAjYyQkPjAxQbWnHU0Z13VEC87UHKLaPY1PTqiP2JfDOu8BfMqEvkWaNTYcr2V7Y6lyclsI3tlj4YMMRrvnn99z9ziZ0Tyu8nAOgnpgBOrIe3ru5Z35vQvRGnjJAEdFgjnI9RoQUvwIgq9XKQw89RHJyMgMGDGDAgAGkpKTwxz/+Easv/R7CPwlZkDYEdAus6GDVXV0ZWBrV9UQfM0Ca5loGMzJATrvApyVEM3NkFuAmC2TrA3r/uw1Mn/8lt76xgeV7SnljzSG2tQ6WDC4ZoB4YJKz4B2z8L2xaGOwzEUIEgn0fsMS290kfUEjzKwC69957efrpp3nkkUf44Ycf+OGHH/jzn//MU089xR/+8IdAn6NozWSCmQ+o6yuedmR43LEPQcxUZSlf2QOgQ04lsEEuh1xha4Z+74cjNLZYsFp1lu06xvoyNWh87bbdlNU2kZUUzaCMeAA+21LU9rV03bUHqLrQtwbqcGCUI9v7OxNChA9PJTCQACjE+bUVxquvvso///lP+y7wAGPHjqVv37785je/4eGHHw7YCQoPRvwI8qbCoVXw5cNw8TPuj/N3CbzB6AM6st6+BJ4++S6HnDY0g+ykGIqqGrjnnc2sO3icgrI6Ho6I5sQImJDWwinnnMjMkVks2niUeW9u5LOtxcw7Z7jra9WVOzVMa6qBuq7UseqtJzACnxo3AaAQIvx4KoGBBEAhzq8MUHl5udtenxEjRlBe7mYongg8TYNZtkBzw+tQtMX9cf4OQTQYAdD+ZbY/92uznYbZpHH5RJUpeveHIxSU1ZEYE0G/vP4AXDY8mnPH5BBhNnHWiCwiTBo7i6vZX1rr+lpG+SupnyPo6UmZEksLVNsCn+ri4J6LECIw2s0A2RaCNFZ23/kIr/kVAI0bN46nn366ze1PP/00Y8eO7fRJCS/1OwlGXwLo8IWH0mOnAyBbCcwITlqVvwxXT+1P/9Q4xvRN4pFLT+D735/FjPEj1Z1OwxCT4yKZNjgNgM+2tsqClNnKX+lDIDFHXe9JfUC1JapvC3rW9yVEb9ZgC25iktveJxmgkOZXCezRRx/l/PPPZ8mSJfYZQCtXruTQoUN88sknAT1B0YGz7oftH8HeL2HPUhhyluv9RgnM1yXwhuRWs4NSB7s9LCc5lm/+7wzXGz1sh3HO6Gy+3V3KZ1uLuGmG0/MZQVbaEJX5KdzQszJAxt8FQE2x6nly3jtICBF+pAk6bPmVAZoxYwa7du3ikksuoaKigoqKCi699FK2bt3Kf/7zn0Cfo2hP6kCY/Ct1/Yv72g7csi+B93EIoqFNAOQ+A+SWh+0wZo3KQtPgh4MVFFU2OO4wGqDThvbMDFCVUwDU0uDbgEghRGiSJuiw5fccoNzcXB5++GHeeecd3nnnHf70pz9x/Phx/vWvfwXy/IQ3TrtDpV+Lt8DGN1zvqzKGIPpZAkvqCzhlKdLcZ4Dc8hAAZSbFMCEvBYAvtjmVwYw5Q2lDIMkWAPWkeTmts1nSByREeNP19pugjdskAApJfgdAIoTEpcKpd6jrX/4RmurUdechiP6WwCKiIDHb8Wd/MkD1x1UDsJNZo9VzLjb6gKwWxzL79CGOmUXOWZOuUlUITbUdH9fp12n1vfSk7JYQvVFLA1ht+yC2lwGSQYghSQKgnmLyryClv3pTXWVbEl9bCpYmQHOUlPxhlMHcLIFvV2wf7NmjujKXu4wAaNW+cirqmtScIUsjmKPVyjMjYOvqIKFsL/xjPLz9y659HWibAaqRDJAQYc2e2dEgKqHt/UZQ1CgBUCiSAKiniIxRDdEAy5+EmhJHxiHBzyGIBiMAcrMEvl0mM8SpFV+ty2D56fGMyE7EYtVZsr0ESp1WmZnMjgCoq0tge79Un+L2fd31QxeNAChSDYOUDJAQYc7I7EQnqgG1rUkPUEjzaRXYpZde2u79FRUVnTkX0VmjL4WVT8PRH+DrRxwrwvzt/zEYAZAv5S9DfIYaZljbduf6WaOz2VFUzWdbi7h8mLECzNZjZGSsGitVeSoq3o8T98KR9eqypV5lofoM6JrXAUcAlDseCr6THiAhwp0x38dd+QskAApxPmWAkpOT2/0aMGAA1157bVedq+iIyQTn/EldX/eKymqA//0/hryp6nLAKb4/1sNSeHCUwb7ZdYzmkp3qxrQh6jImyZFSdpMF0nWdkqqGNrf77Oh6x/VjOzv/fJ5YLY7d7fueqC4lAyREeGuvARqcSmASAIUinzJAL7/8cledhwiU/FNg+GzY+Qmsfknd5u8SeMPIH8HvdqpNWH1lNELXtQ2ARuYk0j81joPldVQe3kE6QPpQxwGJOWo4YvVR1Rjt5P5FW/n3ygJeuvYkzh7lx3mB+qXkHPQc2wHDzvHvuTpSe0xt7aGZIGe8uk16gIQIb+3NAHK+XXqAQpL0APVEMx8EzQzo6s+dLYGBWgnmz9A+D0vhATRNY9ZoFbyYyp2WwBs8LIVfV1DOv1cWAPDf7wt8PyfD0Q3Yf0YApV2YAbL3Y2U7/j4kAyREeGtvBhBICSzESQDUE2UMg4k/d/y5syWwzrCXwNoGQKDKYDE0ktpiy4akOWeAjJVgjtVTLRYrf3h/q/3Py/eUUlnf7N+5GeWvyDh12ZUlMOdxBIm2jFW1bRq0ECI8eVsCa6ppO6RWBJ0EQD3V6Xc7emhSBwbvPNrpAQI4sX8fJiSoDXSbo5LVTCODmwzQa6sK2FZYRVJMBAPS4mi26Hyxzc9SktEAPfICdXlsV9cFJM4BUIJtrlJLvWMfISFE+OkoA+QcGDXVdP35CJ9IANRTJWTC1W/B7L9C7onBO492SmAAJpPGBX3VEMLCiH6uZbZWGaBj1Y387fNdANx57ggumaBKSZ9s9rOUZARAJ1yhSoaNlY7d2gPNKIEl94OoOMcu0dIHJET46qgHKCIazLYRJDIMMeRIANSTDZgOk28M7oabHQRAANOSKwDYVJ+BxeqUgWmVAZr/yXaqG1sY2y+Zqyb35/wT1P3f7j7mexmsthQqD6rreZMcWbKu6gNqPZHbmK4tfUBChC/7TvAeMkAgfUAhTAIg0bXsAVCZx0P66yo7sq0pkx8OHnfckeiYBv39vjLe/eEImgZ/vGgMZpPG0KxEhmYm0GzRWeJrGczI/qQPU/uoZYxQf+6qPiBjJ3h7AOTUBySECE/2Eliy52MkAApZEgCJrmX0ADVVQ3O920PMthVg+/UcFm9xKkHZMkB6dREPvL8JgJ9M6s8420aqALNtWSCfy2BH1qlLozyYPkxddlUAZJTAjBVgPXG3eyF6m46aoEECoBAmAZDoWtFJYIpU1901Quu6mvUD7NNz+GxbEbrRiByfCZoJTbdQWnKEPnGR/N+s4S4PP3+sUQYrparBhzKYsQLMGErYlRkgq9UR6BgZIGOmkvQACRG+OuoBAkd2SGYBhZygB0DPPPMM+fn5xMTEMGXKFFavXu3x2FdeeQVN01y+YmJi2hy3fft2LrzwQpKTk4mPj2fSpEkcPHiwK78N4Ymmtd8HVFdmr6MXReRyqLyebYW2XxTmCCxxmQBka8e569wR9Il33dNsWFYiQzITaLJYvS+D6bqjBNZ3orrMMDJAO7z+1rxWV+bYlNZYASYZICHCX0erwECGIYawoAZACxcuZN68edx///2sX7+ecePGMWvWLEpKSjw+JikpicLCQvtXQYHrILy9e/dyyimnMGLECL7++ms2bdrEH/7wB7eBkugm7S2FL1XZH5LzmDJUlYc+2+oIZA5bUgCYntnIFSfluX16n8tgFQfVZGpTBGSNUbcZJbC60nb7lfziblNa6QESIvxJCSysBTUAevzxx7nxxhu5/vrrGTVqFM8//zxxcXEsWLDA42M0TSM7O9v+lZXlug3Cvffey+zZs3n00UeZMGECgwcP5sILLyQzM7Orvx3hSXsZoDJjE9Qh9r3BPrP1Aa3YU8qOWjXL6Lox0ZhM7lezGavBvtnlZRnMKH9ljYZIW2AcFQ8p/dX1QK8Es68Ac5rILRkgIcKfTxkgCYBCTdACoKamJtatW8fMmTMdJ2MyMXPmTFauXOnxcTU1NQwYMIC8vDwuuugitm51TAW2Wq18/PHHDBs2jFmzZpGZmcmUKVN4//332z2XxsZGqqqqXL5EALWzH5jR/0PaEM4amUmESWNncTW7i6u5b9FWivQ+AOSajrd9rM2wrAQGZ8TTZLGydLsXGZXW5S9Duq2/KNB9QFWtVoCBaw+QTIMW4WDXZ/DRPGgOwCbEPYGlGZrr1PX2AqAY2RA1VAUtACotLcVisbTJ4GRlZVFU5H4Y3fDhw1mwYAEffPABr732GlarlenTp3P48GEASkpKqKmp4ZFHHuHcc8/l888/55JLLuHSSy9l2bJlHs9l/vz5Lrva5+W5L7UIP7W3HUaZbQ+w9KGkxEUxdVAaADe9to49JTVUR9qCp6qjbR9ro2maPQv08SYvBhkaAVDrAZEZXR0AOWeAbL1AzXXSGyDCw+J7YO2/YN/XwT6T0OAc0HhVApP/56Em6E3Qvpg2bRrXXnst48ePZ8aMGbz77rtkZGTwwgsvACoDBHDRRRdx++23M378eO6++25+9KMf8fzzz3t83nvuuYfKykr716FDh7rl++k12usBspfABgMwa4wKDPYeU9OhJ4+z9ei0EwABzLatBvtm9zGq2yuDWS1QuEFd7+shAOqyEphTBigq3vGpUfqARKirPw7GhsVGQN/bGQFNRCyYIz0fZ/w/l0nQISdoAVB6ejpms5niYtdf/sXFxWRnZ3v1HJGRkUyYMIE9e/bYnzMiIoJRo0a5HDdy5Mh2V4FFR0eTlJTk8iUCyFMPkNUC5fvUddsmqOeMcmQEJ+X3YdIJo9UfOuiVGZ6VyKCMeJparCzd7rmJntLdak+eyDhHycvQVUvh3fUAgUyDFuHj6AbH9a7aLibceNMADdIDFMKCFgBFRUUxceJEli5dar/NarWydOlSpk2b5tVzWCwWNm/eTE5Ojv05J02axM6drm9gu3btYsCAAYE7eeEbTwFQxUG1PNwcrfbIArKSYjh7VBaJ0RH88eIxaEbWpKr9IMG5DPbRpnaONQYg5owHc4TrfcZKsKojgf205q4HCGQWkAgfxsIBgBoJgACnBuh2ZgA53y8BUMiJ6PiQrjNv3jyuu+46TjrpJCZPnsyTTz5JbW0t119/PQDXXnstffv2Zf78+QA89NBDTJ06lSFDhlBRUcFjjz1GQUEBN9xwg/0577zzTq688kpOO+00zjjjDBYvXsyHH37I119/HYxvUYBTCazV8nLn8pfJbL/5+Wsm0thiIS4qAhptK7+aqtUvkHZ+2cw+IYenvtxjL4MlxrhJS7cegOgsNkXN6akpUpmifhPbHuMrXXdfAgNZCSbCxxGnAEgyQIp9CGJHGSBpgg5VQQ2ArrzySo4dO8Z9991HUVER48ePZ/HixfbG6IMHD2IyOZJUx48f58Ybb6SoqIg+ffowceJEVqxY4VLyuuSSS3j++eeZP38+t9xyC8OHD+edd97hlFNO6fbvT9g4Z4B03bE5a6v+H4PZpKngB1TAE5WoAqCqQsjwHACNyFZlsH3Halm6vYSLJ/Rte5C9AXqC+yfJGKYCoGM7AhMA1R+HFtuqmTYBkMwCEmHCpQQmATvgRwlMeoBCTVADIIC5c+cyd+5ct/e1zto88cQTPPHEEx0+5y9+8Qt+8YtfBOL0RCDE2TJAlkb1Kcj4hWEMQbT1/3iUlKsak6uPOiY2u2GUwZ76cg8fby5sGwC1NELxFnW99RJ4Q8YI2P9N4BqhjfJXfAZERLveJxkgEQ5qSqDqsOPPErAr3swAAimBhbCwWgUmwlRUHETGq+vOfUBOQxDbZdsUtaM+IHBMhV62y81qsOItqucoNhX65Lt/gkAvhW+9C7wz6QES4cDImsY5jbOwtATvfEKFbQufjjNAtvubatTCDxEyJAAS3cPdUnhvA6BEW/BQ3f5SeLCVwdLVarAvd7RaDeZc/tLcT5UO+DBEdzOADPYMUM/oqdB1nQ2HKqhvkl/yPcrRH9TlkLPU9jHoUNvOSsvewtseIOcAqamm685H+EwCINE9Wq8Ea6p1BAfpHZXAvM8AaZpmzwJ93Ho1mPGL3FP5CxxL4Y8fgOb6Dl+vQ54aoMFpGXzPCIA+3lzIxc98x6OfdcGGsiJ47AsHTnJkLaVs630JLCIazLY9AKUMFlIkABLdo/V2GMYE6Ng+EJfa/mN97JUxAqCvdx2jptEpVW8sgXe3Asx+nunqnNAdGarOaC8AMt5Mmmt7xC/GZTtVcLtyb4A3kxXBo+uumdMeFrR3irdN0ODoA5JhiCFFAiDRPVpvh2Evf3WQ/QFH8NDBNGjDyJxEBqYbQxFt/TWN1Y6yVustMJxpWpuBiM0WK798ZQ03vLoWi9XHfbvaK4FFJ6gVbtAj3lA2Hq4AYE9JDY0tUgbrcs318OXDgR/c6azykPrQYoqA7BN6XNm2U7zNAEF4NEKvXQB7lnZ8XA8iAZDoHq17gLzt/wGfM0CqDKY+qX6y2faYwo2ADkn9HMvPPTEGItreWN5ed5ilO0pYsr24bV9RRzxNgTb0kE/UNY0t7C5R/Q0tVp3dxdLr0OXWvQLfPAqf3dt1r2GUjTNHQWSMUwksvP+9BoS9B6iDQYjOx4RqAFS8DT66Hd66vlc1aksAJLpH6x4gIwBK9yIAMjJANcVerz6xl8F2HqO2scWp/OVh/o8zewZoBw3NFp5csst+16srDnj1+kD7QxANPSQA2nKk0mVT+22FkurvcodWq8sja3H54QfSkVaDQ40PIzIN2scSWLK6DNVZQMbYj8ZKx3iSXkACINE9PAVA3mSA4jNAM4Nu9Xr1yaicJPLT4mhssbJ0R4nnHeDdMWYNle7i3ysPUFzVSEZiNCYNlu8pZU+Jl5/iGipUfw90HACF+RvKxkMVLn/e7ikAqjkGjw6Gd27s+pPq6Yygvv44HN/fNa9xtNXg0ETJANnZS2DJHR8b6hkgY09GcN32pIeTAEh0D+cSmK5DqQ89QCazI1DwYiUY2IYi2naIf/Gbvej2lSxeTHe2ZYD0sj28+JX6ZHTnrOGcNVL98n91RYFX52DP/sSmQmSs+2N6SEnB6P8ZmpkAwLajHgKggu9UT8m298HS7P4Y0bHaUqhw+nd4pAvetKxWxwTo3FYZIFkF5l8TdKhmgMqdAmgjsO4FJAAS3cOeASpVX42VgAapA717vP0Xr3eN0ADXTc8nOTaSo0cOo1UcVDfmju/4gUl9ISoBzdpCcsNhhmQmcOmEvvx8ej4A76w/TFXrIYvudNT/Az2mqXTjITUU7ieT+wMqA6S7K8sYDbuWJrXdiPBP64DH6NUJpPJ96g07IgYyR6rb7CXbXj6802r1fjNU52NCNgPkHABJBkiIwDKmyNaVOurNKXmeMyOt+TALyJCZGMN9PxrFWJNact+UMhhivEhXaxrNqSozNUQ7wh3nDCPCbGL64DSGZiZQ12Th7bWHO3gSPO8C76wH9ACVVDdwpKIeTYNLJ/Ql0qxR1dDCkQo3c5Scg57Cjd13kj2NkdGMUhm3LnnTMl4j+wQw2zYWTrD9e6091rMyeDs+gSfHwoHvvDu+uRawBfjerAIzskQhGwA5lcCKt6htg3oBCYBE94hLU5e6FQ6vUde96f8x+DAN2tmlJ/bl4gz1afW7hgFeL2Pf2qQCrlNTypg1Wv3S1zSNa21ZoH+vPIC1o+fqqAEaurwHaEdRled+nADZZMv+DMlIoE98FEMy1afd7YVuftk7L9mWAMh/Rpli7JXqsnBj4FfvuOubi0tzTIOu6UHToDctVCXFre96d7xR/jJFePchLpRLYE11jt+rkXEqO2vsmdjDSQAkukdEFMSkqOsFK9WlLwGQPQPkWwCkaRrnpqpMzNfVeSxY3nGz6KHyOr44pjJF52RWojltm3HphL4kxkRwoKyOZbuPeXoK27naMkDJ7ZTAErouA7T1aCUXPvUdlz67guO1TQF/foPR/zMuLwVQc5jATR+QpQXKnFaYFG7qsnPq0XTdEQCN+4nKAjXXBn4ekH1yulMAZDI57WEXvlnLNoxFGd7+DJ1nAHnaVseZkSUKxUGIxw+oy5gU6D9NXe8lZTAJgET3MfqADq1Sl940QBsSfRuGaKfrxBSrTMMm6yD++vlO9h1rf0bNk0t2s8OiXi+zwTVgio+O4IqT8gAvlsRXtjME0WCsqmmqCWh6vKHZwu0LN9BksVLfbGHJ9q7r2dhgWwFmBECjctQv+zaZp+MH1KdLQ9HmXjVzJGAqCqCuDEyRkDMOcsar2wO5esfS4sjQtV452QPKti6sFkcAVLqr/WMNDT70/zgfF4olMKP8lTrIsUikK3rKQpAEQKL7GAGQsYty2mDvH5vk5+oT2yRb3RRBn8ETaWyxctc7mzyWr3YXV/PeD4fZo9uCltLdbd6kr502AE1TM4b2l9Z6fm03JbAFy/cz6eEl/OH9LRSU1apfjEYfRwAbSx9dvJNdTsMIF2/pmjcrXdfZdFj9fY7vlwI4AqA2s4CM3q+sEyAiVmUtjC1RhPeM7E/2CWqfKWO2VSBX7xzbAS31alJ560xtD2nct6s8BC0N6npNsRor0BEjkPFmBRiEUQBkC3Z7yUowCYBE9zGWwhs62gTVmT0DVOjb0DdbKlfLGs1Dl00kPsrMmgPH+ffKA24P/+vnO7HqMHLkGDBHq1+MxgoymwFp8ZwxPBPA4/Ooc3VdBfbVzhL++PE2jlU38p9VBZzx16+Z8/p6GmLVcwWqpPDt7mMs+E5lru4+b4TttlLXfdECpKCsjsr6ZqIiTAzPVr/kR9oCoIPldVQ7r5YzGqCzRkH2GHW9SMpgPjvSaqSDkaEJZNnCPv9nvCp7OeshoxvsWg/+O+ZFFqjR9iHOmxlA4CiBhXoAZPxbOrYzNM81wCQAEt3HOQCKiFHbUnjLyAA11/rWSGh8ksk9kX594uwBwV8W7+RgWZ3LoRsOVfDZ1mJMGvxu1ihHgOYmLX6drRn67bWH1aTp1hqqoMn2CyQxh4KyWm793w/oOsw+IZvTh2dg1dUO6huORwOwdedO90vHfVBR18Qdb6nSxTVT+/Pr0wapfdEsVr7ydRsPLxj9P6Nzk4iKUL9O+sRHkZMcA8COIqdfokZ/RcZwVboBKNwQ8HPq8exTzW0BkPGpvXhr4FbvGCWQXDeT03vaLKDW/79LvegD8mUGEIRPBigxy/Z7We8VixQkABLdxyiBAaQObvvJsj1R8Y5PWz4shXc0cqo3i6unDGDqoFTqmy1tSmGPLlYZiktP7MfQrET1Rg1u59WcOiSdQenxVDe28O56N0vijexPTDJ1Wgy//s86qhpaGJ+XwhNXjueV6yez+LZTufTEvpTofQB495t1nPvkt7y97jBNLVbvv0cbXde5970tFFc1Mig9nntnj1JN4GNUz0ZXlMHs/T+28pfBbR+Q8XPMGOEUAPX8X7IBZWlxDCc0Ap+UAWrYprUZigK0esd5B/jW7CsXe8gsIHsAZGtm9qYR2pcZQM7HheIqMGMGUOogddkVJdUQJQGQ6D7OAZAv/T8Gex+Ql43QVkubNwuTSeMvl40lNtLMyn1l/G+NKm8t313Kir1lRJlN3DbTlvlJNwKgtr8QTSaNa6cNAODVlQVtMze2FWB6Ul/ueXczO4qqSU+I4rlrTiQ6wgzAiOwkHr9iPGdOOgGAvIhKdhZXc8dbGznt0a9474fDPmWE3vvhCB9vLiTCpPHkT8YTG6Ve51zbMv6vdpbQ0BzYpmNjC4zxtgZog1EGs68Es1odpYWMEZA9Vl0v3NR1+1j1RMe2O/Xm2P6dapojGApEI3RLo8omgesKMIO9CbqnZIBsJbD+U21/9qYEZmyE6m0GyHZcU01oNf63NKoeKHAKgGyZxV6wEkwCINF9nEtgvvT/GBJ9HIZYuluVoSLjHMEMqofnzlnqz/M/2cHh43U8+pnKTlw1pT/9+sSpAzM8B0AAl03sR3yUmT0lNXy3p8z1TlsG6LClDx9sOIrZpPHMVSeSk9x2ZkhCulpVdtXoaO46dwSZidEUVTVw+8KN/PZ/P1BZ1/HAuUPlddz/gXrTuvWsoYx1ysiM7ZdMbnIMdU0Wvt1d2uFzeavZYmWLLcAZ28+1F2JUbqsMUOVB9cZtjlYZi8yRahVTQ0WbHivRDnv/zwTXDGog+4CKtqhsUmyq+rtqraetAjMCoBHnq0tvMkD+lsBABUGh4ngBoKuA2vj93BU9ZSFKAiDRfVwyQD7MADIk+TgM0Ujh5owHc4TLXddNz2figD7UNLZw5Qur2HS4krgoM3PPdDov5wDITZYiMSaSyyeqPqZXVrSaL2TLAH1Xovp77p09kimD0tyfp20WUFRdCTefPphv7zqD3509DLNJ46NNhZz3929YubfM/WMBi1Xnd29upLqxhYkD+nDz6a7ZNU3TmGUrg326JXCf2ncWVdPUYiUpJoL8tHiX+4wM0I6ialosVsebSvpQ9XcREe3YXkHKYN5r3f9jCGQGyL5v3onuZ9zYp0GXhv806Prjjg2WjQCo4qAaDtge5zlA3oiMAXOU7bEh1Adk7/8Z6Pi7NrYLqjyo/o57MAmARPdxCYC6IQO08xN1OWB6m7vMJo1HLx9LdITJvmXDDacMJD0h2nFQ6mC1C31Ttcd0vzEZeumOEpem6rpSldU4ak3l4vG5XH9yfjvfl+sn6ugIM789ayjv3Dyd/LQ4jlY2cNU/VzH/0+1ue4Ne/GYfqw+UEx9l5okrxhNhbvvf2iiDLdlWTLPF9/4id5zn/5hMrm+UA1LjiIsy09hi5UBZrVP/jyMTR46tDCYrwbzXegWYIZCrd9prgIaeNQ3a2JQ5MRf6DFRZL3TXgZ3u+DoHyPnYUBqG6BwAGWKSIX2Yut7Ds0ASAInu0+keICMD5EUA1FgNe5ao66MvdnvI4IwE5p2t/qOnxEVyw2mDXA+IiHKcp4eNOwdnJHDq0HR0Hf6z6oB66RYL23eq47XkXOZfOtZlmnQbHkoK4/NS+PiWU/nJpDx0HV5Yto9Lnv2OPSWON7gtRyp5/AuVXbn/wtH0T4tz+xIn5aeSnhBFVUMLq/a1yibVV0CJ7xuTbvTQAA2qR2qEbVn8tsJq1/4fgzHATzJA3mmqhZJt6nrrACgxyzZuIQCrd9xtgeHMZHJkgcJ9GrTR75M+VGVA7FnfDvqAjAyQN3sLGkJxJZjzCjBn9jJYz26ElgBIdJ+4VDjz/8HMB9V1XyX5MA1612dqhk/aEMga4/GwG04dxJ8uHsPLP59EUkxk2wOMT0Lt/EI0dolfuOYQdU0tPLBoK/GN6pPx1WdPszcje2QEQE3V0OjaHxAfHcEjl43l+Wsm0icukq1Hqzj/H8v5z8oD1DdZuG3hBpotOrNGZ/HjiZ7HCphNGmePMspgTm9aB1fBM5Ph2alqMrMPWm+B0ZrRB7TtaJUjgDR+nhBWK8GsVp0Xv9nLtx1tf9KVCjeBblGZUHf7yxkZm858am+scSwDd9cAbUgMkVlA5fv9Ct7t7AHQMNfLjpbC+1oCg/AKgOwToSUDJETgnHYnnHKbf4/1Zf7I1vfU5ehL2t2rx2zSuGbqACb07+P+ACNj4SEDBHD68Ez6p8ZR1dDCr/+zjv+tPkSOprIsmX0HeXycXXQiRNp6aDwsLT53TDaLbzuNU4em09hi5Q8fbOXMv33NnpIaMhKjO84y2Z4D4POtxWpT2LUL4JUf2V5Th52LOz5Xm5rGFnaXqGBtXD/3n4KNPqDtRyudZgA5ZYCyRgOaev1gv5F24KudJfz5kx3cvnBDp2c1+c1T/48hEH1ARZvUhsWJuY7A3J1QmAXUVAv/PAteOhPqyv17DqMB2gh8Olj4YOdrEzQ4xniE0lJ4jwGQUyN0D16lKQGQCB/Gp96akvabLxurYfcX6vqoizv3msYvxHaWxpqdlsR/u7uUOBpI1upcz7kjXqysyUqK4dXrJ3P/BaOIijBRWKnG9z92+VhS46M6fIlpg9JIiomgqqaGsjdugo9uV6t9+uSrA/Z95d25okpvug65yTFkJsW4PcaYBVRaeEBlt0wRrr9oo+IdbzwhvjGqkTUrrWniQFkHDbJdxR4AecjMBGL5cnvzf5zZp0EHcRbQjo/VnmjNtf6Xaoxen3Tb4of0jv+/A77PAXI+NlQyQJZmxwrM1gFQ1hj1/7WutEev0pQASISPuHS1dBq9/SFsOxeDpVE1WmeN7txrtjMM0dmPT8ojNlKVui4bYvtvFZ3k/SdEL2ermEwa1588kA/nnsLMkVn8v/NHcrptW46OREWYuHSImf9F/YnMXW8AGpx1P1zzrjrg0Oo2JThPNrbaANWd4dmJaBqk1hmfMgervipnYVAGa7ZY+WKb49/bugIv9orqCk5Tzd0yeqoqCqDW86rBdtlXgHUQAIVCBmjj/xzX/dm809LsyIDYM0C2y7K9nj9k6bpTE7Q/JbAQyQBVHlIl1YhYR0+XITLG0TrQg8tgEgCJ8GEyOQKF9laCbXtfXY6+uN3yl1fShgKa+qTZzpLQ5NhI5l96Aj+dnMc9p9h+0Xmb/QGfp+sOz07kn9edxA2nelFiMxxazd2Hb2KiaTdVxKNf/RacOk99+kvpr7JBB1d69VQd9f8AxEVFMDA9nqGaGgngsgLMEAZbYqzaV0ZlvePNcP3BIARAtaUqsAHP2ZnYFMd4CX9387avAGun/weCPw266ijs+9rxZ2PgqS+OHwBriyo/G3sNJvVTf7Y2OyYkt9bSqO4HH0tgIZYBcl4B5m4qfy/YGFUCIBFe7J88PTRCN1Q5yl+jL+n860XFqeAAOuwLuHhCX+ZfOpa4etubgi8BUIJ3GSC/rXsFXp5NTMMxduv9uKDxj2yJnazu0zQYdLq67vym0o6Nh9RmkO5WgDkbmZPEEM22VYhz/4+hi5fCv7v+MFP+vIS1B/zsEcGxhYixv9n6zmaAWpp871kxApO0oSrQ8SS3E31A9ccdb4odlcCCPQ1681uqVykmRf3Zn4DP3gA9xBEAmExOewB6+P9uz+BoaoCgt0IuAGq1BUZr9pKqn8F0GJAASISXpA5mAe36zFH+yhwVmNf0sgxmZ98F3o8MUKB7Klqa4MPb4MNb1afWkRfw7JDnKdCzXYciGgHQ3o77gEqqGzhSUY+mwQkeGqANo3KSGGpqJwNkbIlRcdD/RlYPahpbmP/hRjKqt/PU0g7munhgsep8tlX9nfzuHHX+O4urqWroxADAd2+Ex0f69qbdUQO0oTOf2o3z6ZPf8SrNYE6D1nXY+Ia6ftqdgKY+EPl6Lq1XgBk6aoR2ngHky36GRrYoVEpg7mYAOTOC6cINobV9RwBJACTCi5Gqtk1absPL1V8+8aIR2oVxbkl9vX+NQH+i1nXYsxT+dTasexnQ1AiCK/7DGWPVbKPFW4ocK5oGnq4uS7Z2GIRtsmV/hmQkkBAd0e6xo7ITnUpgbjJAsSmOJuwAZ4FeXXGAG5pf56Po/0fffQs5aht46Yt1BccprWkkMSaCC8fl0j81Dl2HDQcr/DupunLY/qEa0bDsUe8f520A5LyNga+rd7wtf0Fwp0EXbVbzkMzRMOFqx/9PX8tgrVeAGexL4T38f29U//59aoAGR79QyGSAPKwAM2QMV+XAphrvf/eFGQmARHhJaqf5sqGqw+GHfvFiKbyLzmSAOttTYQ98zoHXLlWf3qKT4aqF6tOypnHG8AyizCb2ldayx7aUnfg0RzZm/zftvoQ3/T+G0cmNpGi1WHSNhmQPnzSdN0YNkOqGZv65bDeXmpcD8GPzMt5Zd9jn5zHKX2ePzCIqwsSJ/VOATvQB7f5cNZ6CmlRubDraHl33PgDKPkFNL68t8fwhwRP7lGkvAqBgToM2sj/Dz4PYPo5yna99ZPYAqNVU+o4yQL5uhGoItUnQHQVAJrNjW4weOhFaAiARXuwZIDcB0C7b6q/0YYErf4HTrvDeZoCMAMiHDFBCJ0tguq6Cv3+drQKfw6shIgamzoG5a2DYLPuhiTGRnDJUbXzoMhTRyz6gDV6sADNkNKg+g4N6JrvLWtwf1AUrwV757gCDG7eRoalP6xNMe/hmzTqsVu+zIrqu89lW9fMxZihNHKDmRfm9EmzHR+rSbNty5dvHO35MRYFqwjdFQrbnoZ6A6lkz/u37+qbV0RYYzpynQXdnGczSovp/AMb9RF0aq998KSnquiOr0XpbHvtS+N1gdbNtjD8zgCC0eoCsFtUEDp4DIHD8W+ihK8EkABLhJamdJmij/DXq4sCVv8C2NNbWZ+BNlsKvEphtrkpjZccbMTpzCXwug8NrHIHPrZvg3D87ntuJ8Ya+2DkAGnyGutz3lcfyia7rbDqsgorxHTRAA2i2N5k9ej+2FVa6PyjAW2JUNTTz0rf7mGVe63L7hOqv224D0o5Nhys5UlFPXJSZ04apbVxOtAVAGw5W+BRMAdDcAHu+VNfP/6u63PquWnLdHiP7k32C2kS2I339eNOqLrb9u9UcAWlHjH9X3bkdxr6vVHYrLg2GzFS32d+kf/C+7FdbCg0VgNZ2W57UgSrYbK6FKjdZQ3+mQDsfHwoBUNURsDSpDVrb+z3Vw1eCSQAkwovzhqjOv+xcyl8BWP3lLCYZxlyqrn/5p/aPbaqDelszry8lsOgkiLTt4+XtG8q+ZT4HPoaZI7MwmzS2FVY5NnHtP01lJqqOQNket48rKKujsr6ZqAgTw7O96IGwlQ13633ZXujhF7+xEqxsj9dziNrz8vIDVDU086NIWwA0+CwAfmRexcK1h7x+nsW27M8ZwzOJsc14Gp6VSFyUmWqnSdhe279Mvakm9YUJP4Oh56iVTN/9vf3HedoA1RPnPiBvGdmTjOHe97YEYxaQMfvnhB+D2bZ1TfYJoJlsE8W9PBcj+5PSHyJjXe8zRzrtAegm6+vPRqjOx4dCAGSUv/rkq1KXJ8a/uaItavm/N3RdLb4IAxIAifBiBBUt9bZPcDY7P1WfaNKHQebIwL/uGfeq3ordn6n9szwxfgFHxvu2UaKmOU3X9SIAOvoD/OdiW+ATC9PmehX4GFLjo5gyUK30WbzVOOdY6D9FXfdQBjP6f0bnJhEV4cWvD1sfxW5rX7UnmDsJmbY3Ux2Kt3T8nO2orG/mn8v3MVorIEcvUT+bC55E10yMNe1n65YNVNZ13LSr67o9O2ZkywAizCbG20p/PpfBjPLX8Nnq7/vU36k/b/gvVLbTr9PRBOjW7FtibHBfwnHHyBZ50wBt6KqVi540VKrpz+Aof4Eq+2XY/s972wjtaQWYob09wYwAxu8SWAj0AHXU/2NIGQCxqWoFqTf/N3Ud3rsJHskL6eGmBgmARHiJjHXM/nDuA7IPPwzg6i9naYNhwjXq+pIHPafa7eWvXN/Pw/6J2osAaO3LKnsw6HS4dSPMetirwMfZee7KYB0sh9/Qzg7wbrlkgKo876MVoD6gfy3fT3VDC1clbVA3DJ2pPuUPPA2Ac/SVfLCx4+bgncXV7C+tJSrCxBkjXCdt+9UHZLU69lobcb667D8VBpys3lxWPu3+cZYWx5u6txmgzFEqG9hY6Xij64i3W2A46+rZVa1t+0Ctnksf7iibGoxmXW/7gDytADO01wjd2RJYU03wl5V7GwBpmm9brGx+Cza9of6elj/RuXPsBhIAifBjZIGMPqCGSkf5q7N7f7Vnxl2qRHRwhVpp5Y4/K8AM3u6w3VQLW2zbV5x2p8+Bj+Gc0eoNbP3BCoqr1L5iDLL1AR34Vr35tmJsgTHeiwZoasugVu2efsjUj+rGFg4f97AU3R4A+b8SrKKuiZeXq6brC6Nsv6xHXgiANlqVMH9kXsXCNR2XwYyg8LSh6W2W+p9o2zjXp5VgR9aq3pXoZMg/xXH7qfPU5bpX3E8aP7ZdZTujEts263pijlRlIfCuD6ixRp0feJ9lgu6fBWSs/hr3k7YfLpz7gLxhzwB5+Jm2tydYg62Xzd8MEKggqCM/vAb/ubT97KC/OhqC6KyvlyXVqkL45A7Hn7ctgkrfV152JwmARPhx7gMC295fTeqXVleUvwzJfWHyjer60gfdlxf8aYA2GN9XRz1A2z5Qm4v2GagyCH7KSoqxL+s2VjuRM05l2Bqr2ryZNFusbLGVsbxZAWYvH6T0p1+WWnW2rdBD+t++FN7/DNA/v91PdWMLMzMqSKzeoxpZh56j7hx5AbopglGmAuoLd7DliIeGbBtH+SunzX0TbD+z/aW1lNd62etglL+Gnu3oXQHVn5QzHprr4Pvn2z7O3v8zwbehe972Aek6LJqrpkAn5joCJ2/YRzd0QwB0vAAKvgM0GHtF2/t9bYQu6ygDZLv92I62z+dvBigyRjUdQ8d9QLoOXz4Me5fCh7cEfkf2joYgOrP/W2qnEVrX1Xk2VKq/iwEnq3EPq1/q/Ll2IQmARPhpPQvIPvzw4q4pfzk7ZZ76NF60CbZ/0Pb+zmSAvO0B+uE1dTnh6k5/v+fZ3uDtZTCT2V4uat0HtLOomqYWK0kxEeSnxXX85Eb5IGMEI207w3vsAzIyQMe2e99s6eR4bRMvf6c+1f7fANub26AZjm0j4lLRbOW9802reLOdZuj9pbXsKKomwqQxc2TbjWZT4qIYkpkA+LAtxo5P1KVR/jI49wJ9/6Iju2Dwdv5Pa/Y+oA4CoFXPqv8/pgj48SverTIzdGcGaNOb6nLgaZDcr+39WaMdu5d3NP+ouUEFVOA5A2TsAVh/vG1mzt85QOB9I3T5PkeGe88SR/YrEKxW/zJApbs8n/cPr6kZV+ZouPh51ZMIKrPZVNvpU+4qEgCJ8GOfBXRUvWHstZWjAr36y534NJhu+8/95cNty0RGAJTciQxQe28oZXvVJ2HNBOOu8v01WjEafL/fX+7oaXFeDu/Eef6P5k3gZQRA6cMYZQuAtnvKACX3szVbtqgpvz566dt91DZZ1NYb5V+rG0de4HqQrQx2vvl73v/hCA3N7vswjC1Cpg1OIyUuyu0xRuZsnTdlsGO7VMbBFOlYuu1sxI9U9rKxEtb8y/U+X1eAGezbGGxyW8oEoGAFfP4HdX3WfEcDvLeMf69dPQ1a1x2rv5ybn51Fxjo1QndQBivfC+hqkUJ8hvtjnPcAbN0I7e8cIPB+GKIxjNTIGC2+O3DN5jVFqqyqmSE5r+PjEzJtx+num8wrDsHie9T1M++FzBFq7liffLVQJZDBW4BJACTCj3MGyL76q4vLX86m/ka9WZftdvxiNhg1b79KYF5kgDa8ri4Hn+VfkNVKXmock/L7YLHqXPbcCn77vx84mjpV3XlotcuydJ/6f8AxOds5A+QpANI0vxuhy2ubeGXFAQDunh6PdvQHQIPhrbItI2ajmyIZYTpEZuMBR9mvlc/crP5qzWiE9ioDtNO2cmngae7fNE0mRy/Qymccc6Caah3BoK8BUNoQlaFoqVdZtdaqi+Ctn6syxQk/dpR2fRGb2j3ToA+vVUFLZFzboNaZt43QzivA2gvkPTVC+1sCA+8zQAe+VZfTf6v+XzRUwCe/8/313DHKXyn9Xcux7fE0D8gooTZVQ94UR+bHZIYpN6nr3z/v/WrEbhYSAdAzzzxDfn4+MTExTJkyhdWrV3s89pVXXkHTNJevmJgYj8ffdNNNaJrGk08+2QVnLoLCOQO09X11vTuyP4aYJEfZ4utHXEs2nWqC7qAHyGpRS6bBsSItAJ69eiI/ntgPTYMPNx7l9AUHqIjOUauTDq60H2csgR/r9QowRwnMyAAdPl7veSPRHP/6gF74Zi91TRbG9E3i1BbbiIIB0yGh1af72D5oQ9RMoAvM7stgRyrq2Xi4Ek2Dc0Z1HABtPFxBs6WDX+6eyl/Oxlym3pDqSh0lzsJNKkBJzPH935PJ5AgoW/cBWZrhzevU3JzMUXDB3/0rpXbXNOhNtgzCyAvan71j7wPa0P7zdbQCzOBpTzB/5wCBaoKH9pfC6zrstwVAg86Ai55Rgeb2Dx2/7zrD2xVgznI9lFTX/kuVyiNi4eLnXGcKjb9atQuU7oK9X3bqlLtK0AOghQsXMm/ePO6//37Wr1/PuHHjmDVrFiUlnj9RJCUlUVhYaP8qKChwe9x7773HqlWryM31481IhC4jA3T8gFP56+LuPYdJv1SBWNVhWLtA3dbcoN7AwL8MkNED1FAJzW5WS+39UmW9YlPVPkgBkpEYzWM/HsdHvz2FaYPSaGrR+bRW7X+27btFtFis1DgN/hvXwQ7w9u/B6GHIGEZyXCR9U9TAuR0eByL6vhKstKaRf69Q//9vnzkMzWg29pQpsAXK55tW8d2eUg6Vu07dNnqhJuWnkpHouR9mUHoCSTERNDRbPZf1QJUtDq9R14fP9nycORJOvlVd/+7vapCcv/0/Bk99QJ//AQ6tUhmMK1+DqHj/nh+6fhp0SyNseUdd91T+MnjbCN3RCjCDxwyQn3OAwLsMUOkutWLQHA39JqnG9FNsGcJP7lAb6naGL/0/BnsGyCm7Vr4fPr9PXZ/5QNuJ2jFJcOLP1PXvn/PrVLta0AOgxx9/nBtvvJHrr7+eUaNG8fzzzxMXF8eCBQs8PkbTNLKzs+1fWVltlwEfOXKE3/72t7z++utERnqZ5hPhwcgANVap8lfGiO4rfxkiY+H0u9T1b/6qfqEZTdkRMWqTRl/FJKtPUuD+E/UP/1GXY6/0rVnVS6Nzk/nvjVP457UnsSv+JAC0fV9x3t+/5aVv9qHrkJscQ2aS54yrnTFBNzHXPhDS0QjdwZYYxVs896208uI3+6hvtjCuXzJn9kP1tYDqq3Fn+GwwRzPEdJQR2iHeapUFspe/RnvO/gCYTJp9W4x2y2C7PgV09Qk6qe2KMhfjr1FBcNVh2PymIwDyZTaPM3erdza/7XgzuuT5tm9avurqadC7P7etUMuBgTPaPzZrtOqzqi+HioOej/M6A+RmKbylRU3zBkc2xxfeBEBG/0/eZLVyDOC0O9Tvudpjqh+oM/zJAOWMBzSoPAg1x1RJ64M56meRfypM/pX7x03+lXrcniWeN5cNoqAGQE1NTaxbt46ZMx2NgSaTiZkzZ7Jy5UqPj6upqWHAgAHk5eVx0UUXsXWr647KVquVn/3sZ9x5552MHj26y85fBElcmqM5ELp29k97xl+tfonUlcKq513LX/6UFDTNcx9QbZmjlDLhav/PucNT0Jg5Kovfz/01ACNNh6goOczfl6o3Da+Wv4NT/89w+02jctQvf49bYvQZqFLmLQ3u56+0UlLdwL9XHgDgtpnD0OzBxgRI8dDcGZOklqID55tX8da6w1hse3qVVDewpkB9um6v/8cw0TYPaN3BCs8HeVP+MkTGOHoolj+hel+g8xmg4m0qo1iyHRb9Vt12yjzvzqkjXb0SzGigPeHH7W/ZAOpDQZZtI1hPfUC67n0AZCyFrzriKHs5l678KoF5MQ3a6P8xVmOC+t4uekYtfti0EHZ95vtrG/wJgGKSHD+vo+tVX0/BdxCVABc97XlEQ+pAx78zd2MegiyoAVBpaSkWi6VNBicrK4uiIvf/oYYPH86CBQv44IMPeO2117BarUyfPp3Dhx0Dl/7yl78QERHBLbfc4tV5NDY2UlVV5fIlQpjJ5PjFC91f/jKYI9UWGQAr/uEYFe9P+cvgqQ9o85uqJydnvG+zWvwUmZhhn81z76hjRJnVrwqj96VDTg3QhlG5HTRCm0yO782LPqAXlu2jodnK+LwUTh+eoXokoP1GWbCXwS6MWEVhZT3f7lbDGj/fWoyuqyAvNyW2vWcAvGiEbqxxjBLwNtg46Xo1h6lsj/q0Df5ngJLz1Con3aLerBZeo+YNDTodzvx//j1na13ZA1RX7nijH/dT7x5j/KwKN7i/v+qoylqYItQqpfbE9nGUpY2gyQhcImIgwv0KwXZ1lAGyWuHAcnU9/1TX+/qdpBZgAHx4W9uRCd7Qdf9KYOAIqDctVHPQAM75Y8c/R6MZesP/Ol++C7Cgl8B8NW3aNK699lrGjx/PjBkzePfdd8nIyOCFF14AYN26dfz973+3N0t7Y/78+SQnJ9u/8vK8WBoogssogwWj/OVs9KWQdYL6xfj1I+q2zgRA7mYB6Tqst5W/Atj83CHbcviLk3azZN4MHr18LFdPGeDdY40MjlMGyCiB7SyupsVT47DRB1TUfh9QdUMzb6xWAcJtM4eiNVSqzWHBPv3Zo2HnQkQMAyhitHbA3gxtrArrqPxlGJeXgklTjdNFlQ1tD9i7FCyNKrPlFAi2KzrR8YYBah6NMcvIV5rmKIO9c4MKqpL6wWX/6jib4q2uzABteUcF/dljHZmdjnQ0Edr4d9lnoHcroFrvCWZvgPaj/wccfUOeMkDHtkNdmVrx5i7zd8a9KnCpPgpf3Of769eWqhVbaNDHy//LBuN8tryjsrSDz4SJ13f8uPxT1O/IlnpY/6rPp9yVghoApaenYzabKS52nW9QXFxMdrZ3v4QiIyOZMGECe/ao3au//fZbSkpK6N+/PxEREURERFBQUMDvfvc78vPz3T7HPffcQ2Vlpf3r0CHvd4wWQWJ8erHNdgkakwnOss1S8WcX+NbczQI6+gOUbFVNkSdc7v9z+8rYF2zfV/RPjeWKk/KIjfLyjdNNBiivTxwJ0RE0tVjZV+phOJqXK8HeXX+E2iYLQzITmDEsQ/WKWJvV63XU3BqdYJ8Q/SPzKr7YVsy+YzWs3FsGOPZI60h8dAQjstUbmtttMZzLX76URKf8Wm2mC/6XvwzGp/b646psfMW/IT69c8/prCunQdu3vvAy+wMdN0J7W/4ytG6E7kwDNDgCJ08ZIGP1V94U9xmmqDi48Cl1fd0rjqDfW0b5KznP9z5C541yo5PUeXjz71rTYOrN6vrql7p2ZpSPghoARUVFMXHiRJYudeyrZLVaWbp0KdOmTfPqOSwWC5s3byYnR71x/OxnP2PTpk1s2LDB/pWbm8udd97JZ5+5r5tGR0eTlJTk8iVC3Bm/h3MfgVNuC/aZqDfTvKmOP3cqAHKTATKWRY+8wL/man/1n6aCrqojKnvgraZaRxOqUwbIZNIYkW30AXUwEbpwk8fZIbqu86qt9+faaQNUpnf7InVnR+UvwxgVOF8atZpmi5XbFm6gxaozIjuR/HTvV0V53BjV0gy7Wm1+6q24VDjldnV9pIdmbm85v2md9yj062RA1VpXZYDK9qr9yTSzb0F/xkgV6DVUwvH9be/3dgWYoXUjdGdmAEHHgxDt/T+nur8fVEblpF+q64t+69ukZV+2wGgte4wq/YH63etuIrcnYy5T5diqI45SdQgIegls3rx5vPTSS7z66qts376dm2++mdraWq6/XqXWrr32Wu655x778Q899BCff/45+/btY/369VxzzTUUFBRwww03AJCWlsaYMWNcviIjI8nOzmb48OFuz0GEoZQ89amiC1ZD+UzT4CyndHQge4Ca69XKHXAsKe0ukbGO6cCttsVol/FmEZ+h3syd2PuAPG2JkT5c/ZJtqnb/BgZ8t6eMfcdqiY8yc8mEvmpw4G7bZrjeBkBDz4HIOLKsxYzV9rHpsOqnOM/N3l/tOXFACuAmADq4Ug2vi0tTn+Z9ddod8H/7vf9+PBk0Q62Im3EXTPx5557LHfs06GOB/WRvBLQDT1OTiL0VEQVZY9R1d/OAOtoDrDX7nmCtS2B+NEA7P85dBsil/+e0tvc7m/mAKmdWFMCXf/L+9f1pgDZERKvtUn70BIz3cQp9ZIwjaFsVOkvigx4AXXnllfz1r3/lvvvuY/z48WzYsIHFixfbG6MPHjxIYaFjieXx48e58cYbGTlyJLNnz6aqqooVK1YwapSXNWIhukL+yWoZc1I//97wDK17gLZ/pLZISO7f8S/FrmDsDu9LAOQ0ALG1DidCmyPUcmbwWAYzVn5dNrEfiTGRqtempV4NEjQ2Ve1IVLzqBQIuilxlv9mb1V/OJvZXAd7Wo5WuW2sY5a9h5/nXb6NpbYJHv0REw09eVxnTrtgnzz4NmsBOgzayBKM66Odyp70+IF9LYEYG6Ph+NefLyAB1RQmseIsKmqMSHFOtPYlJUgMsQQUUh9Z49/qdCYBAzR876Rf+/Vs66RdqTMHh1Y4VjkEW9AAIYO7cuRQUFNDY2Mj333/PlCmON5Cvv/6aV155xf7nJ554wn5sUVERH3/8MRMmtL9K4sCBA9x2221ddPZC2Fz0NNy+Re0X5q/WPUDG7J8JV/u2G3igGH1A+7/xejaPuyXwhrG2IYrf7ytvM4TQrp2d4Q8fr2PJdtUzeO00WxOnffXXhb79YraXwdagYWVQejzDshK8fzyQlxpLekI0zRbdscO8rsMO2/YXI9oZftgTdMU06MrDttlFbrYz8YanAKix2rFRavoQ754rMVvN+9GtajsOewnMjxlA0H4GyCh/9Z/mXYP20Jm2/ijdsSqrI50NgDojMctRzgyRLFBIBEBC9Aia1vlP2UYPUEOFGia4fxmg+Z5yDpSccWpZdmNVx3ssGdrJAI3OTebUoek0Waz89XMPg9HaWQn2+vcHseowfXAaQzIT1cTknbZeG1/LRUNmQlQCfVpKuDijkFtnDvV65ahB0zTHxqhGGax4i1rCHhHryKD1ZIFuhDaCx7wpjv8PvjCyJ4UbXfvIjD62+Azve+k0zbUM1pmNUKH9AGi/F/0/rZ35/1RW5cC3cOC7jo8PZgAEjhWO2953zE0LIgmAhAglMSmORsPlj6vLQTMcO1N3N5NZvT54XwZrJwMEcNe5I9A0+GDDUTYfdjPLxHkPq1JH83VDs4WFa9QKzWun5asbD3yjSoQJWdBvsnfnZ4iMtW9P8cSofVw03r/erTaN0Eb5a/CZatVOT2dvhA7QNGhv5zl5kjFC/R9qrHLtI/O1/GVwboRu7GwPkC1waqpWe/sZrBbHFPPW83/ak9zPMRrjm0fbP7auXH2wgo5n93SV3PEw4GSwtsCafwbnHJxIACREKNE0Rx/QpjfV5YRubn5uzb4c/uuOj21uUHu0gcfZN2P6JnOJLdj48yfb0VsvV84cpZaBN1TA0yfB/66CghV8vPEo5bVN5CbHMHOkrTF2u23vrxHn+1ciNDbR3fa+3ztW2wciHqxQ34uxH1lPL38ZArkSrLZMDW0E/1fAmSMdAzWds5a+rgAzuMsAdXYVGEBTjeN64UYVyEcnOz4AeOuU21Uf1r6v4eD3no8zBiAm5gY3MDeWxK99WS1gCCIJgIQINUYfkG5R+2gFYsuCzjACoEPfq+nG7Snbo/olYvuoUoMH884ZRlSEiZX7yvh61zHXOyNj4LoPbU3KOuz8GF4+jxMWX8qPTCu5ZkpfIswm9anZKJf4my0YcpZ606kuVBuE+mFM32QizRqlNY0cLditSneayd5k3eMFsgdo5yfq30/22M5lKdz1AdkDoM5kgDo5BygyxrGNj3MZzOj/GTDd96b5PgMcs5LaywIFu/xlGD5bZbTry9WE+yCSAEiIUOPc93DCj1WpJpj6DFS/sKzNsPW99o81yl/pw9vth+rXJ47rp+cD8MgnO+z7cTkOmAhXLYQ5q+HE67CaoxnWsouno57i1xsuh5XPwJ6latfsmGTfygbOIqIdAeYHc2Dlsz6P64+JNDM6VzXFlq6z/XzypgZ24GAoC2QGqLPlL4Oxsa5LAGQrp/oaABkZoNLdaqAk+J8BAvd9QP70/zg7dZ6ambRnCRxe5/6YzswACiSTGSarvQYp2R7cUwnqqwsh2kp0mkXTnVtfeKJpMML2hrRoLrx3k+cgwd4A3fHMrd+cPoTk2Eh2FlfzzvrD7g/KGA4X/oMHBi/kyZZLqTEnY646BJ/9Hv77Y3XM8NnerZrxZNpv1Bta+T747B7423B4+5dq5Zu7acJunNQ/iRHaQVL3vq9u6C3lL3A/vdwfDVWw7yt1vbMBkH1PMFsjtNXiaIL2tQSWMkD1FFkaoWSbus3fHiDnxxoBkKVZzY0C/wP51EEw9kp13VMWKFQCIIATr4W5a+G8vwT1NCQAEiLUGG8oWSc4PskG25n/z7aCQ4ON/4OnJ6kBja0DBDdbYHiSHBfJ3DPUcuTHP99FfZPF7XFlNY28sa2BJ1suZ8/V38OPnlR7ZBlGXeTHN+Qk+wS4bTOc/zdVerE0wZa34dUL4KkT1c7s1a7b9VBzDHZ+CksehFd+xN0bz2Fx9N3k1dneIId7DoD2lFTbN2DtEYyMZWdXge35Qv3s04Z4v3eaJ+nD1H5aTTUq8Kk4qAKYiBi1DYQvTGbHvzejbyfGz2Xw0HYa9NEN6nlj+ziGOPrjtDtU6XXXYvdDIEOlBAa23eV9DES7QESwT0AI0cq4n8DhNTBtbtcMr/NHVJz6tDbmcjV+/9h2eOeXsPktFTgYY/F9yAAB/GzaAF5ZcYAjFfW8vGI/vzm97XyWhWsP0dRi5YS+yYwbmA2DrocTr1Pp/vrywPTaxKbApBvU19EfYN2rKsAr3wdLHlDTdoedq95UD692NHrbRADVeiwb9cGcNPsXxKQNbvMSO4uq+cfS3Xy8Wa2W+uuPx3H5RB+2EwhVradB+5uNcy5/dfbfvTlCBbOHVqm/T2PZe+pg/wZTZgyD4s2OP3eqBGYLnowVZQe+UZcDTu7crK+0wapkvmkhfPOYGoDpzFgRFwoBUIiQDJAQoSYxW/3yGuDdfnjdKm8S/PobOP33av7IrsXwzBS1yWFLoxoWB15/go+JNHPnLBUsPffVXsprm1zut1h1Xl+l9hWz7/sF6o1i2DkqWAx0kJg7AS54En63Ay58Wi2vt7ao1V2b33Rd5TbhZ3DBP+DmlcyO+Q/XNP2edemuGakdRVX85vV1zHryG3vwA2oF3PFW329YCsQ06OYG2PW5uj6ik+UvgzEP6OgP/q8AM6S3Cuj9bYKGtiUwe/9PACa9n3oHoKl/q0VOAVtDlQpQQfX0CUACICGEryKi4PS74KblalhdUw18cge8MEMFClGJPm0Ie+G4XEbnJlHd2MJTX+52uW/p9mKOVNTTJy6SC8Z1YpNZf0QnqP3XbvgCbl6p3lxO/z387D24qwDmfK+mf0+8DrJGMT5fNT2vt80DMgKfc5/8lk82q/LQ+Sfk8NFvT2F4ViLltU38ZfGO7v2eukIgpkHv+wqaa9U+ekb/TmfZ+4A2+L8CzJDR6nGBaoJuaVKrK8H//h9nGcPsE85Z5tQLZGR/4jM6F7z1MBIACSH8kzkCrl8Ms/+q9i86ZlvRkdH+CrDWTCaN388eCcBrqwooKHPsbv3vlQUAXDEpj5hIP0oXgZI1Cs76gwr8Bp+pSmatGBOhl2wvdhv4fHbbaTxz9YmM6ZvMw5eoXo831hxi7QHfVp2FpM4OQzTKXyN+FLgtX5wboY3SrL8BkHMGSDN3bmWmPQCqUlt+NNdBXDpkjvT/OZ2ddqe63L4Iim09aaHU/xNCJAASQvjPZILJN6psyNBZ6jY/SncnD0lnxrAMmi06j32m3qz2lNSwfE8pmgbXTBkQyLPuEsZAxI2HK90GPsOzHSuHTspP5SeTVDPuve9todni3xDGkNGZ7TAsLWr+D3R+9ZeztCEqMG+uU31b4H8JLG2wCnxAZVA6U3Z1zgAZ83/yTwlcKTdzpGNhwDePqUsJgNySAEgI0XnJ/dTcnt+uh5lebszYyt3nqS0yPtpUyIZDFby2SmV/zhqRSV5q6G8pMTInib4pKjPgKfBxdte5I0iNj2JncTULlu93e0zY6MwsoILv1HyduDS1EWigmMyOjXV1W4CZ5uUmqK1FRDuWj3em/AWOElRjlRq1AP7P//HEyAJtfU9lvyQAcksCICFEYGia+qTszyobVABx2YlqVdRDH27l7XVqNpB9368QF2k28cHck1lx95ntBj6GPvFR3HOeahZ/csluDh8P7rYAndKZHiCj/DX8PLV6K5Cc+4mS+qm+Ln8ZZbDO9tAYAVRtKRyyZabyA9AA7Sz7BFVORIdv/urYBkMCIBeyDF4IETLmnT2MDzceZf3BCgAGpcdzypDwmaicnhDt0/GXT+zHW+sOs3p/OQ8s2sY/rzsp4OfU0GzhWHUjx2oaKatporSmkbKaRkpt10tttw/OSOCpqyYQafbjc7G/GSCr1bF32sgLfX/djjgHQOl+Zn8MGcPUtiydzQAZJbADy9VsooSsrpmJc9qd6me75W01vgFCYwhiCJEASAgRMnJTYvnFKQN57mu1nP6aqQMwmUJkFlIX0DSNhy8ew3l//5Yl24v5fGsR54zO9uk5KuubOXK8niMV9Rw5XqcuK+o5cryew8frKfNyqf3ukhreWXeYn0zu7/s34u806KPrVeN0VCIMnOHzy36w4QiV9c38bKrTiARnLgGQnw3Qhn6T1GVnl5EbAZAxVDH/1K6Z95U7Xs2u2rXY8VqSAXIhAZAQIqTcfPpg3v/hCC1Wnct6wqDADgzNSuRXpw3i2a/38sCirZw8JJ346PZ/NTdbrLy64gDPL9tHaU1jh68RHWEiPSGa9MRo0uOjSE+IJi3BcbnlSCUvfbuffyzdzSUn9iU6wscypm0adMPxo5z8xy94+JIxnDsmp4MHoVYqgZrpFBnj00tW1jUz782NWKw64/qlMC4vpe1BqYNUcNVU3fkAaPhs+PnHjr4if7XOIAW6/8fZaf+nAiBQwyCNgZACkABICBFikmIi+ez209B1SI7txB5fYeS3Zw5l0cajHD5ez9+X7raPBXBnxZ5S7l+0ld0lNfbb+sRF0q9PHH1TYunbJ5a+KbH066Ou90uJIyk2wn2GxGbW6Gw+3FjI0coG/vf9QX5+so9ZDlsGKKapjMqGOua9uZEhmQkMyWynD0rXO7X56cp9pfZNdN9Zf9h9AGQywfBzVTPwgJN9fg0XmqZWa3VW633EAjH/x5N+E2HITDU1XbI/bUgAJIQIOUkxvSPwMcRGmfnjRWO4/pU1/Gv5fi6Z0JeROa6ZgiMV9fz54+32adKp8VHcOWs4F47L7TBj1JGYSDNzzxzC/3t/C09/tZcrJ/UnNsqHLFBsKi1aBBF6CxlUUtiUxk2vreeDOSd7PreSbWp1kjkahpzt8zkv31Nqv75o41HuPX+k+8zVhU/B2X+EJC8yUt3BOQBK6tv1gcnMB9VO9mN/0rWvE4ZkFZgQQoSAM0Zkct6YbCxWnXvf24zVlt1oaLbw9Je7mfm3ZXy8uRCTBtdNG8BXvzudn07u3+ngx3DFSXnkpcZSWtPIqysP+PTYLYXVFFvVHlePz84iKymaPSU13P3uZvTWG+YajOzP4DP9Wp313Z4yQCVmKuqa+WqHhw1mI2NDJ/gB1xJYV/X/OMseA7dtgim/6trXCUMSAAkhRIi474JRxEeZWX+wgoVrD/HljmJmPfkNf/18F/XNFibnp/LRb0/lwYvGkBwX2CxZVISJ285SfTLPL9tLVUOzV4/TdZ2HPtxGia76S6ZlNPPMVScSYdL4cONR+zTvNrYbq798L38dqahnf2ktZpPGT21N2++sP+zz8wSFcwaoK/t/RIckABJCiBCRkxzLvHPUvJk/vL+FX7yyloKyOrKSovn7T8az8NdTGZXbdXs5XTyhL4Mz4qmoa/Z6OOPHmwtZfaCcUs3WYFtTxEn5qdxtm3H0p4+3sf7gcdcHle9Tu6trZjX/x0ff2cpfY/sl8/Pp+QB8taOEMi8awoMuMkZtIKuZ/Fr5JgJHAiAhhAgh100bwKicJFqsOpFmjV/PGMTS353OReP7ttvIHAhmk8a8s1UA9s9v93e4W319k4U/f6z2gMvMzVc32pbC//KUgcw+IZtmi86c19e7BidG9if/FIhL9fk8jQDolCHpDMtK5IS+ybRYdT7ceNTn5wqKqxbC1W9DSl6wz6RXkwBICCFCSITZxIvXTuTWs4by6a2ncc95I0kIUJ+PN84bk82onCRqGlt4/pu97R77wjd7OVrZQN+UWEYNsy0zt22Iqmkaf7lsLIPS4ymsbOC2hRvsq7Y6s/pL13V7AHSybUjmZSf2BeCd9Ud8fr6gyJsMQ84K9ln0ehIACSFEiOnXJ47bzx7GkMxObN3gJ5NJ43fnqGDm1RUHKKlucHvckYp6nl+mAqTfzx5JZLIxDLHYfkxiTCTPXTOR2Egz3+4u5e9Ld0NVoWNz0hHn+3x+O4urKa1pIjbSzIT+KQBcMC6XCJPG5iOV7Cqu9vk5Re8kAZAQQggXZ47IZEL/FBqarTz7lfss0PxPttPQbGXKwFRmn5DtcRr08OxE5l96AgCffPU1NQsuVnf0mwRJuT6fm7H6a/LAVPuy97SEaM4YkQnAO+vCpBlaBJ0EQEIIIVxomsYdtmbs/35/kCMV9S73r95fzkeb1JL8+y4YpXqTbNOgqWm7HcbF43N5YugmFkX+PxIqdmCJTYNZ8/06N0f5K83ldmMj3fd+OOIotQnRDgmAhBBCtHHykHSmDUqjyWLlqaW77bdbrDoPLNoKwE8m92d0rpr/Y88A1R4Di9MS+oZKePsXXHLoEeK0Rr61jOEXsU/SmHOiz+fUbLGyal+Z/fycnTkik5S4SEqqG12GJArhiQRAQggh3LpjluoFemvdYfaX1gLw5tpDbCusIjEmgt+d7bS/VmwqmGyziWpsfUCH18Lzp8LWd8EUQeXJ93JLxB9YdtTM41/s8vl8NhyqoK7JQmp8FCOzXccBREWYuHCcKqlJGUx4QwIgIYQQbk0ckMoZwzOwWHX+vmQXlfXN/PWznQDcPnMYaQnRjoNNJkiwlcGqCmH5E7BgFlQUQEp/uH4xyWf/H49cPh6A11cdpLaxxafzWb5bZXamD07DZGo7EsAog322tcjrQY6i95IASAghhEe/s/UCfbDxKL97cyNltU0MzojnZ9MGtD04MVtdvv0LWPIAWFtg9KVw03LImwTA2SOzGJQeT01jC+/94Nuydef5P+6M7ZfMkMwEGlusfGrbM00ITyQAEkII4dGYvsmcNyYbXYcl21Vp674LRhNpdvP2YQRAlQchIlZtRHr5AohJth9iMmlcPVUFT6+tKvC8V1grNY0tbDhUAbTt/zFommbPAr2zLkxmAoWReQs3cMULK6lvsgT7VAJCAiAhhBDtmnf2MPuenTNHZjJjWIb7AzNUtoisMfDrZXDitW43+7x8Yj9iIk3sKKpmzYHjbe53Z/X+MlqsOv1T48hLjfN43MUTctE0WH2gnINldV49t+hYeW0T7/5whNX7y/lsa9uVfuFIAiAhhBDtGpqVyG9OH8yQzAT+8KNRng889Q64+h24YakjGHIjOTaSi8er6c3/WeVhs9RWlu92v/qrtZzkWHuJLGw2SA0DW49W2q+/3UOazCUAEkII0aE7Z41gybwZDEiL93xQVBwMnak2/OyA0UO0eEuhx2nTzjrq/3FmlMHe/eGw1yU20b4tR6rs17/bW9pmNlQ4kgBICCFEtxudm8yJ/VNotugsXH2o3WNLqhvYWVyNpsG0wWntHgswa3Q28VFmDpXXe11iE+3bcsSRAdJ1eK8HZNckABJCCBEURhbov6sP0mKxejxu5V5V/hqVk0RqfFSHzxsbZWb2CWowYyjOBNpeWMU3u45hDaOJ1VtsJbBLJqjS5dvrwj+7JgGQEEKIoJh9Qg6p8VEUVjawdEeJx+OM+T/elL8Ml01UZbCPNxeG1KqlxhYLP31pFdcuWM3sf3zL0u3FIR9IVNY3U2BrKL9j1nDioswcKKtjXUF4Z9ckABJCCBEU0RFmrpyUB8B/VrpvhtZ13Wn/L+8DoMn5qfTrE0tNYwufbwudVUubDldSUaeGNO4oquaXr67l8udX2rf4CEXbjqr+n359YumbEmvProV7M7QEQEIIIYLmqsn90TRYvqeUvcdq2ty/v7SWo5UNRJlNTMpP9fp5TSaNS42ZQOtDZybQKls5b8awDG6aMZiYSBPrCo7zkxdVVmjz4coOnqH7Gf0/Y2z7vl1uy659tCm0smu+kgBICCFE0OSlxnHWiExADUZszcj+TBzQh9gos0/PfamtX2X57mMUV3W80qw7fL+/HICzRmZy93kj+ObOM7hman8iTBrf7DrGBU8v5zevr2NPSdtgMFiM/p8xfdX+a5PzU8lLVdm1cJ4JJAGQEEKIoLrGNhn67XWHqWty3R/suz3G/J+OV3+1lp8ez4n9U7DqsHS75x4jbxwqr+OCp5bzbidWPzW1WFlboAKgqYPU95OZFMOfLj6BL393OpdM6IumwSebizjniWXc9fYmn/dL6wr2DFBflQEymRwTt8O5DCYBkBBCiKA6bWgGA9LiqG5oYdGGo/bbLVadFXt97/9xeW7b1OrvbM/jrzfWHGTzkUqe+nKP38+x6XAFDc1WUuOjGJqZ4HJf/7Q4nrhyPItvPY2zR2Vh1WHh2kNc//KaoAZBtY0t7CutBdToAoMRAIXzTKCQCICeeeYZ8vPziYmJYcqUKaxevdrjsa+88gqaprl8xcQ4hm41Nzdz1113ccIJJxAfH09ubi7XXnstR48e9ficQgghgsdk0rhmisoC/XulY3+wLUcqqWpoITEmghP6Jrf3FB5NH6wCp1V7yzq17Hy5LRO1v7SWgrJav57DaHSeMjAVzc0WIQDDsxN56dqTeONXU0mMiWD1gfKgBkHbCqvQdchOiiEjMdp+e15qHFMHpYb1TKCgB0ALFy5k3rx53H///axfv55x48Yxa9YsSko8pyuTkpIoLCy0fxUUOOrGdXV1rF+/nj/84Q+sX7+ed999l507d3LhhRd2x7cjhBDCDz8+qR/RESa2FVax/mAFoBqjAaYNSiPC3earXhifl0JspJmy2iZ2Flf79RyVdc1sPlxh//OyXcf8eh6j/8cof7Vn6qA0/vPLKfYg6Ocvrw5KEOQofyW1ue/yiWoFX7jOBAp6APT4449z4403cv311zNq1Cief/554uLiWLBggcfHaJpGdna2/SsrK8t+X3JyMl988QVXXHEFw4cPZ+rUqTz99NOsW7eOgwcPdse3JIQQwkcpcVFcOC4XcDRD27e/GOpf+QsgKsLE5IGpLs/nq5X7SnFOHn290/cAqKnFylrbVGpvAiBQwdtrtiBozYHjQQmCjC0wxrjJwJ03JjusZwIFNQBqampi3bp1zJw5036byWRi5syZrFy50uPjampqGDBgAHl5eVx00UVs3bq13deprKxE0zRSUlLc3t/Y2EhVVZXLlxBCiO5lTIb+eFMhRyrqWWt7UzXKWP4yGqhX7PVv1s63tkGMU2yB1Mq9ZTQ0+7b8e/ORCuqbLW77f9ozzk0QVNONQZCxCeqY3LYBUHx0RFjPBApqAFRaWorFYnHJ4ABkZWVRVOR+ad3w4cNZsGABH3zwAa+99hpWq5Xp06dz+LD7H35DQwN33XUXP/3pT0lKapvCA5g/fz7Jycn2r7y8vM59Y0IIIXw2tl8K4/ol02Sxctfbm2hqsZKdFMPgjHY2YPWCEUB9v6+M5na23PDEyBzdcOogMhOjqW+2sOZAuU/PsWqfOn5yfiomk/v+H09aB0HXd1MQ1NBsYbdtOb67DBCE90ygoJfAfDVt2jSuvfZaxo8fz4wZM3j33XfJyMjghRdeaHNsc3MzV1xxBbqu89xzz3l8znvuuYfKykr716FD7W/MJ4QQomv8bFo+4Oj/OXlIuseGYW+NykkiJS6S2iYLm3wcNHiovI4DZXWYTRpTB6Uyw7aqzNcymNEAPXWQ98McnY3LS+H1G5wyQQu6PgjaXliFxaqTnhBFVlK022PCeSZQUAOg9PR0zGYzxcXFLrcXFxeTnZ3t1XNERkYyYcIE9uxxXZpoBD8FBQV88cUXHrM/ANHR0SQlJbl8CSGE6H4/GptDSlyk/c+nDPV9/k9rJpPGNFvfzQof+4CM7M+EvBQSYyI5fbga2uhLI3Szxan/x4vd7D0Z288RBK0t6PogaMtRR/+PpyA0nGcCBTUAioqKYuLEiSxdutR+m9VqZenSpUybNs2r57BYLGzevJmcnBz7bUbws3v3bpYsWUJaWuf/AwkhhOh6MZFmrjzJ0YbQ2f4f+/PY5gj5Og9oeat9yE4Zmo7ZpLGnpIbDx+u8eo5Nhyupb7bQJy6SYZmJPr1+a0YQlOQUBHl7Hr7aesRz/4+zcJ0JFPQS2Lx583jppZd49dVX2b59OzfffDO1tbVcf/31AFx77bXcc8899uMfeughPv/8c/bt28f69eu55pprKCgo4IYbbgBU8HP55Zezdu1aXn/9dSwWC0VFRRQVFdHU1BSU71EIIYT3rpk6gKSYCKYPTiMrKabjB3hhui3zsr6gwusGZqtVtzdOGyvRkmMjmZCXAnhfBvt+v3qOyQN97/9xZ2y/FF5zCoJO+ctXXPbcCv698gClNY2dfn7D5naWwDsL15lAEcE+gSuvvJJjx45x3333UVRUxPjx41m8eLG9MfrgwYOYTI447fjx49x4440UFRXRp08fJk6cyIoVKxg1ahQAR44cYdGiRQCMHz/e5bW++uorTj/99G75voQQQvgnLzWO5XefSXRE4D6jD0qPJzsphqKqBtYeOO7V0vpthVWU1zYRH2VmvC3oATh9eAZrC46zbNcx+zYe7TEaoL1d/u6Nsf1S+N+vpvLwx9tZua+MdQXHWVdwnAc/3MbJQ9K5aFwu54zOIjEmsuMnc6OxxcIu29yk0R1kgEDNBFq1r5y31x1mzhlDOt231R00PRynF3WxqqoqkpOTqayslH4gIYToIea9uYF31x/h5tMHc9e5Izo8/oVle5n/6Q7OGpHJv34+yX77liOV/Oip5cRHmfnhvnOIaidQa7ZYGffg59Q1Wfj01lMZmRP495TiqgY+2lTIog1H2OjU5B0dYeKskZlcOC6XmSOzfBomaXyPKXGR/PCHszsMaGobW5j08BLqmiy8fdM0Tsr3r9m7s3x5/w56CUwIIYToDifb+om8bYRe7mEQ46icJNIToqhtstg3N/Vky5FK6pospMRFMjyrc/0/nmQlxfDLUwbywdxT+OqO05l39jAGZcTT2GLlk81F3PTaeh78cJtPz7nFqf/Hm2xOOM4EkgBICCFErzDdNhBx85FKKuub2z22odnCatvWFae02ojVZNLsm6wu66APqDPzf/wxMD2eW84aytJ5M/jot6dw/cn5gNpYtaLO+z5Yo/9ndAf9P85+7DQTaPnuUkqqGkJ6i4yg9wAJIYQQ3SEnOZZB6fHsK63l+31lnDPa87iVdQXHaWyxkpUUzRA3k5tnDMvg3fVH+HrnMe6ZPdLj8zjm/3TvamRN0xjTN5nRuUms3FvGjqJqFm08yrW2OUsdMZbA+7IJ7aT8VPqnxnGwvI5r/vU9oJrGh2YmMDQr0XaZwLCsRDITo4PeJyQBkBBCiF5j+pA09pXWsmJv+wFQR4MYTxuagUmDncXVFFbWk5Mc2+aYFouVtQcC3wDtC03TuOKkPB76aBtvrj3kVQDUbLGyvdA2A8iLBmiDyaTx6OVjWbB8P7tLaigoq6Wyvpm1Bcft25oYkmIi+MUpA7lt5jCfvp9AkgBICCFErzF9cDqvrTrIig7mAS237f/Vuvxl6BMfxbi8FH44WMGyncf4yeT+bY7ZcrSK2iYLybGRjMjumv4fb1w8oS/zP93OliNVbD1a2eGqrr3HamhqsZIYHUH/1DifXmvqoDR7sNfQbGHfsVp2l1Szp6SGXcXVtsCojqqGFiJ9aMruChIACSGE6DWmDUpD02BXcQ0l1Q1kJradM3S8tokttk1APQVAoMpgPxys4GsPAZBR/grU/B9/pcZHcfaoLD7ZXMRbaw8z+sL2A6DNtpVko3KTOnXeMZFmRuUmMSrXtY+oscXC/tJakmP9W6IfKNIELYQQotfoEx/FKNtS9JUedodfua8MXYdhWQlktjOI0dgW47s9pW43WQ1W/487P7ZN135/wxEaW9ofBLnVj/4fX0RHmBmRneS2bNidJAASQgjRqxjbWnznYTn8t/byV0a7zzO2bzKp8VFUN7awvlWPS4vz/l9+boAaSKcNzSA7KYaKumaWbi9p91j7EvguCoBChQRAQgghepVptm0xVnjIAH1nn//TfubGZNI41TYj6OtWm6NuPVpFTWMLSTERjMgO/kBds0njsol9AXhz7SGPx1msOtuMBmgflsCHIwmAhBBC9CqT81OJMGkcPl7PwTLXjUQPltVxsLyOCJPGlIEdl65OH+5+HpCj/ycNcxD7f5z9eKIqg32z6xiFle43Ld1fWkNdk4W4KDMD09su/+9JJAASQgjRq8RHRzChfwrQdnd4Y/n7if37EB/d8Tqh04ZmoGlq37CSqgb77d/vN5a/B7/8ZchPj2fywFSsOry7/ojbY7YcUdmfUTlJIRO4dRUJgIQQQvQ60we77wNavkdlck5uZ/WXs7SEaHuz8DJbGazFYmXN/uDO//HEmNb85tpDbqc095b+H5AASAghRC803dYHtHJvmT0QsFh1e1+QN7vFG063bYth9AFtK6yiurGFxJiILtn8tDNmn5BDfJSZgrI6+1Yfzozl/6NzQ+u8u4IEQEIIIXqdCf37EBtppqy2iZ3F1QBsO1pFRV0zidERjOvnfQZkhq0P6Ntdx2ixWO39P1MGpoZcGSk+OoIfjc0F4M21rpuWWq06W48YDdCSARJCCCF6nKgIE5MGqv6c7/aogOVbW/lr6uA0InyYUjw+rw/JsZFUNbSw8XAF3+8LzfKX4YpJqgz2yeZCqhscm8IeLK+jurGF6AgTQ93sf9bTSAAkhBCiVzrZXgZTfUD25e9e9v8YzE7L4ZduL7GXlkI1ADqxfx8GZcRT32zh402F9tuN8teInCSfAsBw1fO/QyGEEMINoxH6+33l1DS2sMY2uNCX/h/DDFsf0OvfHwzZ/h+DsUEqwFvrHGUwYwXYmF7Q/wMSAAkhhOilRuUmkRwbSXVjCwuW76epxUpOcgyD0uN9fi6jD6iyXpWUJueHXv+Ps0sn9MVs0lhXcJw9JTVA71oBBhIACSGE6KXMJo1ptjLVS9/sA9Tyd03zPXDJTIxxWTkVquUvQ2ZSDGfYgra31qkl8UYJrKv2AAs1EgAJIYTotU4eogKV6sYWAHsvjz+MMhiEfgAEcLltMvQ7645QUFZHRV0zkWaNoVk9vwEaJAASQgjRi00b7BrwTB/sfwB05gi1O3xSTASjwqCP5swRmaTFR1Fa08gzX+0BYFhWItER5iCfWfeQAEgIIUSvNTgjnqykaABGZCeSkRjt93NNHNCHhy8Zw3PXTAzp/h9DVISJSyaoDVKNZugxub2j/AUSAAkhhOjFNE3jlCGqdHWaUwnL3+e6esoAr7fRCAU/tq0GM4zxYQBkuOt4pzchhBCiB7vr3OH0T43j5yfnB/tUut3w7ETG5aWw8VAF0HuWwINkgIQQQvRymUkx3DpzKMmxkcE+laC44iQ1Gdps0kJ2dlFXkAyQEEII0YtdNL4vH/xwlJE5icRE9o4GaJAASAghhOjVEqIjePOmacE+jW4nJTAhhBBC9DoSAAkhhBCi15EASAghhBC9jgRAQgghhOh1JAASQgghRK8jAZAQQggheh0JgIQQQgjR60gAJIQQQoheRwIgIYQQQvQ6EgAJIYQQoteRAEgIIYQQvY4EQEIIIYTodSQAEkIIIUSvIwGQEEIIIXqdiGCfQCjSdR2AqqqqIJ+JEEIIIbxlvG8b7+PtkQDIjerqagDy8vKCfCZCCCGE8FV1dTXJycntHqPp3oRJvYzVauXo0aMkJiaiaVpAn7uqqoq8vDwOHTpEUlJSQJ9btCU/7+4lP+/uJT/v7iU/7+7lz89b13Wqq6vJzc3FZGq/y0cyQG6YTCb69evXpa+RlJQk/4G6kfy8u5f8vLuX/Ly7l/y8u5evP++OMj8GaYIWQgghRK8jAZAQQggheh0JgLpZdHQ0999/P9HR0cE+lV5Bft7dS37e3Ut+3t1Lft7dq6t/3tIELYQQQoheRzJAQgghhOh1JAASQgghRK8jAZAQQggheh0JgIQQQgjR60gA1I2eeeYZ8vPziYmJYcqUKaxevTrYp9QjfPPNN1xwwQXk5uaiaRrvv/++y/26rnPfffeRk5NDbGwsM2fOZPfu3cE52R5g/vz5TJo0icTERDIzM7n44ovZuXOnyzENDQ3MmTOHtLQ0EhISuOyyyyguLg7SGYe35557jrFjx9qHwU2bNo1PP/3Ufr/8rLvWI488gqZp3Hbbbfbb5GceOA888ACaprl8jRgxwn5/V/6sJQDqJgsXLmTevHncf//9rF+/nnHjxjFr1ixKSkqCfWphr7a2lnHjxvHMM8+4vf/RRx/lH//4B88//zzff/898fHxzJo1i4aGhm4+055h2bJlzJkzh1WrVvHFF1/Q3NzMOeecQ21trf2Y22+/nQ8//JC33nqLZcuWcfToUS699NIgnnX46tevH4888gjr1q1j7dq1nHnmmVx00UVs3boVkJ91V1qzZg0vvPACY8eOdbldfuaBNXr0aAoLC+1fy5cvt9/XpT9rXXSLyZMn63PmzLH/2WKx6Lm5ufr8+fODeFY9D6C/99579j9brVY9Oztbf+yxx+y3VVRU6NHR0fr//ve/IJxhz1NSUqID+rJly3RdVz/fyMhI/a233rIfs337dh3QV65cGazT7FH69Omj//Of/5SfdReqrq7Whw4dqn/xxRf6jBkz9FtvvVXXdfn3HWj333+/Pm7cOLf3dfXPWjJA3aCpqYl169Yxc+ZM+20mk4mZM2eycuXKIJ5Zz7d//36KiopcfvbJyclMmTJFfvYBUllZCUBqaioA69ato7m52eVnPmLECPr37y8/806yWCy88cYb1NbWMm3aNPlZd6E5c+Zw/vnnu/xsQf59d4Xdu3eTm5vLoEGDuPrqqzl48CD8//buLSSqLYwD+H+YcZtanVE0tUKxNFHLsJFk1G6MhAqRImnigxlkmoKBFAYZ+FD6IJH1IAahdCEpyTLJ0Lw9CNpFxwuaYIhd0MTukhnkdx7iDGeOHShzHG3+P1iw91p7z/7mYz98rL02G5bPNT+GugAmJibw7ds3uLu7m/W7u7vj6dOnVorKNoyNjQHAD3P/zxjN3czMDI4ePYqIiAhs3LgRwPecK4oCrVZrdixzPne9vb3Q6/X48uULli9fjurqagQGBsJoNDLXFlBZWYnOzk48evRo1hjv7/kVFhaGiooK+Pv7Y3R0FAUFBdi2bRv6+vosnmsWQEQ0Z1lZWejr6zN7Zk/zz9/fH0ajER8+fEBVVRVSU1PR2tpq7bD+SC9evEBOTg4aGhqwbNkya4fzx4uJiTFtBwcHIywsDN7e3rhx4wYcHBwsem0+AlsArq6uUKvVs1auv379Gh4eHlaKyjb8k1/mfv5lZ2ejtrYWzc3NWLt2ranfw8MDX79+xfv3782OZ87nTlEU+Pr6QqfTobCwEJs3b0ZJSQlzbQFPnjzB+Pg4tmzZAo1GA41Gg9bWVpw/fx4ajQbu7u7MuQVptVps2LABQ0NDFr+/WQAtAEVRoNPp0NjYaOqbmZlBY2Mj9Hq9FSP78/n4+MDDw8Ms9x8/fkRHRwdzP0ciguzsbFRXV6OpqQk+Pj5m4zqdDnZ2dmY5HxwcxPPnz5nzeTIzM4Pp6Wnm2gIMBgN6e3thNBpNLTQ0FCkpKaZt5txyJicn8ezZM3h6elr+/v7tZdT0UyorK8Xe3l4qKiqkv79f0tPTRavVytjYmLVDW/I+ffokXV1d0tXVJQDk7Nmz0tXVJSMjIyIiUlRUJFqtVu7cuSM9PT2yd+9e8fHxkampKStHvjRlZmbKX3/9JS0tLTI6Ompqnz9/Nh2TkZEhXl5e0tTUJI8fPxa9Xi96vd6KUS9deXl50traKsPDw9LT0yN5eXmiUqmkvr5eRJjrhfDvt8BEmPP5lJubKy0tLTI8PCxtbW0SFRUlrq6uMj4+LiKWzTULoAV04cIF8fLyEkVRZOvWrdLe3m7tkP4Izc3NAmBWS01NFZHvr8Ln5+eLu7u72Nvbi8FgkMHBQesGvYT9KNcApLy83HTM1NSUHDlyRJydncXR0VHi4+NldHTUekEvYQcPHhRvb29RFEXc3NzEYDCYih8R5noh/LcAYs7nT1JSknh6eoqiKLJmzRpJSkqSoaEh07glc60SEfn9eSQiIiKipYNrgIiIiMjmsAAiIiIim8MCiIiIiGwOCyAiIiKyOSyAiIiIyOawACIiIiKbwwKIiIiIbA4LICKi/6FSqXD79m1rh0FEFsACiIgWpQMHDkClUs1q0dHR1g6NiP4AGmsHQET0f6Kjo1FeXm7WZ29vb6VoiOhPwhkgIlq07O3t4eHhYdacnZ0BfH88VVpaipiYGDg4OGDdunWoqqoyO//ly5dITk6Gi4sLnJycEBoaio6ODtN4aWkp1q9fD0VR4O/vjytXrsyKYWJiAvHx8XB0dISfnx9qampMY+/evUNKSgrc3Nzg4OAAPz+/WQUbES1OLICIaMnKz89HQkICuru7kZKSgv3792NgYAAAMDk5iR07duDVq1eoqalBd3c3jh8/jpmZGQBAdXU1cnJykJubi76+Phw+fBhpaWlobm42u0ZBQQESExPR09OD2NhYpKSk4O3bt6br9/f3o66uDgMDAygtLYWrq+vCJoGI5mZePqlKRDTPUlNTRa1Wi5OTk1k7ffq0iHz/Kn1GRobZOWFhYZKZmSkiImVlZbJixQp58+bND38/PDxcDh06ZNa3b98+iY2NNe0DkJMnT5r2JycnBYDU1dWJiMiePXskLS3t9/8sES04rgEiokVr165dKC0tNetzcXExbev1erMxvV4Po9EIADAajQgJCTE7/t8GBgaQnp5u1hcREYGSkhKzvuDgYNO2k5MTVq5cifHxcQBAZmYmEhIS0NnZid27dyMuLg7h4eG/9ieJyCpYABHRouXk5ARfX985nevg4DAvMdjZ2Zntq1Qq02O0mJgYjIyM4N69e2hoaIDBYEBWVhaKi4vn5dpEZDlcA0RES1Z7e/us/YCAAADfZ26MRqNpvc5/BQQEoK2tzayvra0NgYGBvxSDm5sbUlNTcfXqVZw7dw4XL178pfOJyDo4A0REi9b09DTGxsbM+jQajWmh8c2bNxEaGorIyEhcu3YNDx8+xKVLlwAAycnJOHPmDOLi4lBYWAhPT090dXVh9erV0Ov1OHbsGBITExESEoKoqCjcvXsXt27dwoMHD346vlOnTkGn0yEoKAjT09Oora01FWBEtLhxBoiIFq379+/D09PTrEVGRprGCwoKUFlZieDgYFy+fBnXr183zeAoioL6+nqsWrUKsbGx2LRpE4qKiqBWqwEAcXFxKCkpQXFxMYKCglBWVoby8nLs3Lnzp+NTFAUnTpxAcHAwtm/fDrVajcrKynnNARFZhkpExNpBEBH9KpVKherqasTFxVk7FCJagjgDRERERDaHBRARERHZHC6CJqIliU/vieh3cAaIiIiIbA4LICIiIrI5LICIiIjI5rAAIiIiIpvDAoiIiIhsDgsgIiIisjksgIiIiMjmsAAiIiIim8MCiIiIiGzO30LjT3SN0noWAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epcohs')\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epcohs')\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeTjVIJRSRtt"
      },
      "source": [
        "# Uncertainity Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuvagCQQSO5g",
        "outputId": "1b78e8b5-45de-4048-8da4-f778e604a349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6371 - accuracy: 0.6650 - val_loss: 0.6331 - val_accuracy: 0.6474\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6182 - accuracy: 0.6740 - val_loss: 0.6257 - val_accuracy: 0.6474\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6007 - accuracy: 0.6752 - val_loss: 0.6026 - val_accuracy: 0.7051\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5970 - accuracy: 0.6916 - val_loss: 0.6098 - val_accuracy: 0.6474\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5904 - accuracy: 0.6899 - val_loss: 0.5826 - val_accuracy: 0.6987\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5870 - accuracy: 0.7098 - val_loss: 0.5842 - val_accuracy: 0.6827\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5808 - accuracy: 0.6927 - val_loss: 0.5818 - val_accuracy: 0.6859\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5647 - accuracy: 0.7183 - val_loss: 0.5653 - val_accuracy: 0.7115\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5768 - accuracy: 0.7012 - val_loss: 0.5760 - val_accuracy: 0.7051\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5737 - accuracy: 0.7069 - val_loss: 0.5679 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5692 - accuracy: 0.7103 - val_loss: 0.5738 - val_accuracy: 0.7019\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5636 - accuracy: 0.7160 - val_loss: 0.5478 - val_accuracy: 0.7276\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5641 - accuracy: 0.7239 - val_loss: 0.5582 - val_accuracy: 0.7147\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5550 - accuracy: 0.7319 - val_loss: 0.5794 - val_accuracy: 0.7308\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5609 - accuracy: 0.7279 - val_loss: 0.5608 - val_accuracy: 0.7115\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5515 - accuracy: 0.7256 - val_loss: 0.5510 - val_accuracy: 0.7019\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5584 - accuracy: 0.7177 - val_loss: 0.5568 - val_accuracy: 0.6987\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5470 - accuracy: 0.7336 - val_loss: 0.5504 - val_accuracy: 0.7179\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5517 - accuracy: 0.7330 - val_loss: 0.5795 - val_accuracy: 0.7212\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5549 - accuracy: 0.7256 - val_loss: 0.5846 - val_accuracy: 0.7276\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5455 - accuracy: 0.7392 - val_loss: 0.5536 - val_accuracy: 0.6987\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5466 - accuracy: 0.7404 - val_loss: 0.5501 - val_accuracy: 0.7147\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7336 - val_loss: 0.5429 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5399 - accuracy: 0.7409 - val_loss: 0.5612 - val_accuracy: 0.7147\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7449 - val_loss: 0.5511 - val_accuracy: 0.7179\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7432 - val_loss: 0.5670 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 0.5468 - accuracy: 0.7222 - val_loss: 0.5446 - val_accuracy: 0.7244\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5380 - accuracy: 0.7307 - val_loss: 0.5469 - val_accuracy: 0.7308\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 0.5330 - accuracy: 0.7455 - val_loss: 0.5398 - val_accuracy: 0.7404\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5311 - accuracy: 0.7438 - val_loss: 0.6045 - val_accuracy: 0.6987\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.5491 - accuracy: 0.7370 - val_loss: 0.5736 - val_accuracy: 0.7147\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5366 - accuracy: 0.7398 - val_loss: 0.5462 - val_accuracy: 0.7276\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5387 - accuracy: 0.7438 - val_loss: 0.5659 - val_accuracy: 0.7083\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5411 - accuracy: 0.7370 - val_loss: 0.5457 - val_accuracy: 0.7276\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5253 - accuracy: 0.7551 - val_loss: 0.5461 - val_accuracy: 0.7372\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5217 - accuracy: 0.7545 - val_loss: 0.5601 - val_accuracy: 0.7179\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5259 - accuracy: 0.7404 - val_loss: 0.5426 - val_accuracy: 0.7308\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5242 - accuracy: 0.7562 - val_loss: 0.5531 - val_accuracy: 0.7244\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5194 - accuracy: 0.7511 - val_loss: 0.5435 - val_accuracy: 0.7212\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5249 - accuracy: 0.7511 - val_loss: 0.5446 - val_accuracy: 0.7372\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5226 - accuracy: 0.7477 - val_loss: 0.5582 - val_accuracy: 0.7212\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.7341 - val_loss: 0.5378 - val_accuracy: 0.7436\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5213 - accuracy: 0.7506 - val_loss: 0.5490 - val_accuracy: 0.7212\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5214 - accuracy: 0.7534 - val_loss: 0.5526 - val_accuracy: 0.7244\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5164 - accuracy: 0.7557 - val_loss: 0.5691 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5229 - accuracy: 0.7460 - val_loss: 0.5741 - val_accuracy: 0.7244\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.7585 - val_loss: 0.5604 - val_accuracy: 0.7147\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5188 - accuracy: 0.7579 - val_loss: 0.5484 - val_accuracy: 0.7276\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.7358 - val_loss: 0.5558 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5147 - accuracy: 0.7534 - val_loss: 0.5715 - val_accuracy: 0.7244\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.6788461538461539\n",
            "Accuracy: 0.6788461538461539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6385 - accuracy: 0.6542 - val_loss: 0.6238 - val_accuracy: 0.6827\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6316 - accuracy: 0.6587 - val_loss: 0.5991 - val_accuracy: 0.6891\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6048 - accuracy: 0.6650 - val_loss: 0.5561 - val_accuracy: 0.6923\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6069 - accuracy: 0.6791 - val_loss: 0.5690 - val_accuracy: 0.6923\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5873 - accuracy: 0.6978 - val_loss: 0.5233 - val_accuracy: 0.7596\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.6978 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5824 - accuracy: 0.6893 - val_loss: 0.5549 - val_accuracy: 0.7212\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5736 - accuracy: 0.7092 - val_loss: 0.5941 - val_accuracy: 0.6955\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5685 - accuracy: 0.7086 - val_loss: 0.5206 - val_accuracy: 0.7596\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5669 - accuracy: 0.7183 - val_loss: 0.5214 - val_accuracy: 0.7692\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5661 - accuracy: 0.7200 - val_loss: 0.5361 - val_accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5564 - accuracy: 0.7239 - val_loss: 0.5309 - val_accuracy: 0.7724\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5699 - accuracy: 0.7103 - val_loss: 0.5491 - val_accuracy: 0.7276\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7307 - val_loss: 0.5146 - val_accuracy: 0.7660\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5528 - accuracy: 0.7313 - val_loss: 0.5235 - val_accuracy: 0.7244\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5571 - accuracy: 0.7177 - val_loss: 0.5173 - val_accuracy: 0.7596\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5497 - accuracy: 0.7302 - val_loss: 0.5435 - val_accuracy: 0.7179\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5549 - accuracy: 0.7375 - val_loss: 0.5322 - val_accuracy: 0.7308\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5501 - accuracy: 0.7285 - val_loss: 0.5175 - val_accuracy: 0.7436\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.7302 - val_loss: 0.5212 - val_accuracy: 0.7212\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7364 - val_loss: 0.5108 - val_accuracy: 0.7564\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5518 - accuracy: 0.7347 - val_loss: 0.5198 - val_accuracy: 0.7532\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5435 - accuracy: 0.7324 - val_loss: 0.5197 - val_accuracy: 0.7628\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7262 - val_loss: 0.5223 - val_accuracy: 0.7596\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5435 - accuracy: 0.7455 - val_loss: 0.5084 - val_accuracy: 0.7692\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 9ms/step - loss: 0.5392 - accuracy: 0.7421 - val_loss: 0.5059 - val_accuracy: 0.7660\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 0.5443 - accuracy: 0.7381 - val_loss: 0.5255 - val_accuracy: 0.7308\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5420 - accuracy: 0.7279 - val_loss: 0.5118 - val_accuracy: 0.7628\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5389 - accuracy: 0.7353 - val_loss: 0.5007 - val_accuracy: 0.7853\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5334 - accuracy: 0.7404 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5329 - accuracy: 0.7449 - val_loss: 0.5234 - val_accuracy: 0.7628\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5361 - accuracy: 0.7409 - val_loss: 0.5253 - val_accuracy: 0.7628\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5342 - accuracy: 0.7489 - val_loss: 0.5278 - val_accuracy: 0.7660\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5307 - accuracy: 0.7455 - val_loss: 0.5051 - val_accuracy: 0.7628\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.7500 - val_loss: 0.5286 - val_accuracy: 0.7724\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.7364 - val_loss: 0.5178 - val_accuracy: 0.7885\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7477 - val_loss: 0.5192 - val_accuracy: 0.7564\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5390 - accuracy: 0.7387 - val_loss: 0.5250 - val_accuracy: 0.7660\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7455 - val_loss: 0.5092 - val_accuracy: 0.7692\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7489 - val_loss: 0.5020 - val_accuracy: 0.7660\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5269 - accuracy: 0.7472 - val_loss: 0.5171 - val_accuracy: 0.7596\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7415 - val_loss: 0.5060 - val_accuracy: 0.7660\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5305 - accuracy: 0.7466 - val_loss: 0.4916 - val_accuracy: 0.7917\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7500 - val_loss: 0.5122 - val_accuracy: 0.7660\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5240 - accuracy: 0.7421 - val_loss: 0.5111 - val_accuracy: 0.7724\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5207 - accuracy: 0.7545 - val_loss: 0.5018 - val_accuracy: 0.7756\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5169 - accuracy: 0.7517 - val_loss: 0.5059 - val_accuracy: 0.7724\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5202 - accuracy: 0.7523 - val_loss: 0.4951 - val_accuracy: 0.7724\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7466 - val_loss: 0.5067 - val_accuracy: 0.7821\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7511 - val_loss: 0.5150 - val_accuracy: 0.7885\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7096153846153846\n",
            "Accuracy: 0.7096153846153846\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6389 - accuracy: 0.6576 - val_loss: 0.6280 - val_accuracy: 0.6571\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6650 - val_loss: 0.6371 - val_accuracy: 0.6571\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6650 - val_loss: 0.6166 - val_accuracy: 0.6571\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6094 - accuracy: 0.6706 - val_loss: 0.5985 - val_accuracy: 0.7115\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5961 - accuracy: 0.6865 - val_loss: 0.5839 - val_accuracy: 0.7115\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5869 - accuracy: 0.7069 - val_loss: 0.6262 - val_accuracy: 0.6635\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5759 - accuracy: 0.7149 - val_loss: 0.5748 - val_accuracy: 0.7212\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7103 - val_loss: 0.5760 - val_accuracy: 0.7276\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5568 - accuracy: 0.7143 - val_loss: 0.5645 - val_accuracy: 0.7276\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5706 - accuracy: 0.7012 - val_loss: 0.5692 - val_accuracy: 0.7372\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5632 - accuracy: 0.7200 - val_loss: 0.5680 - val_accuracy: 0.7372\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5627 - accuracy: 0.7160 - val_loss: 0.5665 - val_accuracy: 0.7244\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5593 - accuracy: 0.7177 - val_loss: 0.5751 - val_accuracy: 0.7308\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5525 - accuracy: 0.7217 - val_loss: 0.5608 - val_accuracy: 0.7308\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5576 - accuracy: 0.7126 - val_loss: 0.5850 - val_accuracy: 0.7179\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5522 - accuracy: 0.7313 - val_loss: 0.5687 - val_accuracy: 0.7276\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5509 - accuracy: 0.7262 - val_loss: 0.5740 - val_accuracy: 0.7051\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5519 - accuracy: 0.7279 - val_loss: 0.5902 - val_accuracy: 0.7372\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7273 - val_loss: 0.5664 - val_accuracy: 0.7372\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5475 - accuracy: 0.7245 - val_loss: 0.5700 - val_accuracy: 0.7212\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7330 - val_loss: 0.5702 - val_accuracy: 0.7276\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5454 - accuracy: 0.7279 - val_loss: 0.5585 - val_accuracy: 0.7244\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5412 - accuracy: 0.7375 - val_loss: 0.5641 - val_accuracy: 0.7372\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5468 - accuracy: 0.7143 - val_loss: 0.5687 - val_accuracy: 0.7083\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5451 - accuracy: 0.7290 - val_loss: 0.5605 - val_accuracy: 0.7404\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7290 - val_loss: 0.5624 - val_accuracy: 0.7340\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5423 - accuracy: 0.7426 - val_loss: 0.5597 - val_accuracy: 0.7468\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5338 - accuracy: 0.7438 - val_loss: 0.5920 - val_accuracy: 0.7115\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5392 - accuracy: 0.7500 - val_loss: 0.5600 - val_accuracy: 0.7308\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5386 - accuracy: 0.7353 - val_loss: 0.5577 - val_accuracy: 0.7372\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5317 - accuracy: 0.7409 - val_loss: 0.5647 - val_accuracy: 0.7404\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5324 - accuracy: 0.7330 - val_loss: 0.5684 - val_accuracy: 0.7244\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5405 - accuracy: 0.7375 - val_loss: 0.5654 - val_accuracy: 0.7340\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.7432 - val_loss: 0.5825 - val_accuracy: 0.7308\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7415 - val_loss: 0.5820 - val_accuracy: 0.7212\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7404 - val_loss: 0.5704 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5341 - accuracy: 0.7404 - val_loss: 0.5798 - val_accuracy: 0.7372\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.7358 - val_loss: 0.5715 - val_accuracy: 0.7212\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.7455 - val_loss: 0.5880 - val_accuracy: 0.6891\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5397 - accuracy: 0.7324 - val_loss: 0.5690 - val_accuracy: 0.7212\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5235 - accuracy: 0.7483 - val_loss: 0.5803 - val_accuracy: 0.7212\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5256 - accuracy: 0.7500 - val_loss: 0.5682 - val_accuracy: 0.7308\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5214 - accuracy: 0.7545 - val_loss: 0.5651 - val_accuracy: 0.7340\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5270 - accuracy: 0.7426 - val_loss: 0.5672 - val_accuracy: 0.7404\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5220 - accuracy: 0.7477 - val_loss: 0.5865 - val_accuracy: 0.7340\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5297 - accuracy: 0.7443 - val_loss: 0.5815 - val_accuracy: 0.7404\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5223 - accuracy: 0.7489 - val_loss: 0.5726 - val_accuracy: 0.7372\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5144 - accuracy: 0.7489 - val_loss: 0.5867 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7455 - val_loss: 0.5838 - val_accuracy: 0.7340\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5138 - accuracy: 0.7534 - val_loss: 0.5874 - val_accuracy: 0.7179\n",
            "17/17 [==============================] - 0s 3ms/step\n",
            "0.7192307692307692\n",
            "Accuracy: 0.7192307692307692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 6ms/step - loss: 0.6288 - accuracy: 0.6667 - val_loss: 0.6074 - val_accuracy: 0.6603\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6301 - accuracy: 0.6655 - val_loss: 0.6181 - val_accuracy: 0.6603\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6059 - accuracy: 0.6723 - val_loss: 0.5939 - val_accuracy: 0.6667\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5916 - accuracy: 0.6967 - val_loss: 0.5913 - val_accuracy: 0.6699\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5900 - accuracy: 0.7001 - val_loss: 0.5883 - val_accuracy: 0.6859\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5763 - accuracy: 0.6973 - val_loss: 0.5659 - val_accuracy: 0.7179\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5816 - accuracy: 0.6973 - val_loss: 0.5536 - val_accuracy: 0.7340\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5671 - accuracy: 0.7126 - val_loss: 0.5485 - val_accuracy: 0.7404\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5666 - accuracy: 0.7234 - val_loss: 0.5673 - val_accuracy: 0.7115\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5684 - accuracy: 0.7217 - val_loss: 0.5455 - val_accuracy: 0.7179\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5631 - accuracy: 0.7222 - val_loss: 0.5456 - val_accuracy: 0.7404\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5475 - accuracy: 0.7307 - val_loss: 0.5625 - val_accuracy: 0.7147\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5423 - accuracy: 0.7364 - val_loss: 0.5775 - val_accuracy: 0.7115\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5490 - accuracy: 0.7279 - val_loss: 0.5586 - val_accuracy: 0.7276\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5673 - accuracy: 0.7234 - val_loss: 0.5925 - val_accuracy: 0.7244\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5579 - accuracy: 0.7200 - val_loss: 0.5635 - val_accuracy: 0.6955\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5484 - accuracy: 0.7279 - val_loss: 0.5384 - val_accuracy: 0.7179\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5502 - accuracy: 0.7302 - val_loss: 0.5388 - val_accuracy: 0.7372\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5400 - accuracy: 0.7319 - val_loss: 0.5567 - val_accuracy: 0.7083\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5494 - accuracy: 0.7234 - val_loss: 0.5415 - val_accuracy: 0.7308\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5469 - accuracy: 0.7290 - val_loss: 0.5372 - val_accuracy: 0.7404\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5391 - accuracy: 0.7375 - val_loss: 0.5572 - val_accuracy: 0.7244\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5429 - accuracy: 0.7455 - val_loss: 0.5285 - val_accuracy: 0.7308\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7296 - val_loss: 0.5245 - val_accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7466 - val_loss: 0.5566 - val_accuracy: 0.7276\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5411 - accuracy: 0.7330 - val_loss: 0.5381 - val_accuracy: 0.7147\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7330 - val_loss: 0.5360 - val_accuracy: 0.7244\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5299 - accuracy: 0.7477 - val_loss: 0.5478 - val_accuracy: 0.7340\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.7443 - val_loss: 0.5360 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7426 - val_loss: 0.5352 - val_accuracy: 0.7372\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5196 - accuracy: 0.7574 - val_loss: 0.5343 - val_accuracy: 0.7147\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.7432 - val_loss: 0.5548 - val_accuracy: 0.7404\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7489 - val_loss: 0.5790 - val_accuracy: 0.7019\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7466 - val_loss: 0.5554 - val_accuracy: 0.7115\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7443 - val_loss: 0.5474 - val_accuracy: 0.7212\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7381 - val_loss: 0.5436 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5239 - accuracy: 0.7551 - val_loss: 0.5702 - val_accuracy: 0.7051\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7483 - val_loss: 0.5535 - val_accuracy: 0.7019\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.7483 - val_loss: 0.5381 - val_accuracy: 0.7244\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5232 - accuracy: 0.7591 - val_loss: 0.5418 - val_accuracy: 0.7147\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5176 - accuracy: 0.7511 - val_loss: 0.5452 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5130 - accuracy: 0.7704 - val_loss: 0.5375 - val_accuracy: 0.7147\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5181 - accuracy: 0.7511 - val_loss: 0.5319 - val_accuracy: 0.7372\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5128 - accuracy: 0.7630 - val_loss: 0.5350 - val_accuracy: 0.7308\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5093 - accuracy: 0.7545 - val_loss: 0.5192 - val_accuracy: 0.7340\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.7506 - val_loss: 0.5269 - val_accuracy: 0.7276\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.7562 - val_loss: 0.5386 - val_accuracy: 0.7212\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5092 - accuracy: 0.7579 - val_loss: 0.5453 - val_accuracy: 0.7276\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5073 - accuracy: 0.7534 - val_loss: 0.5520 - val_accuracy: 0.7372\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5076 - accuracy: 0.7574 - val_loss: 0.5337 - val_accuracy: 0.7276\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7076923076923077\n",
            "Accuracy: 0.7076923076923077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6298 - accuracy: 0.6548 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6235 - accuracy: 0.6638 - val_loss: 0.6262 - val_accuracy: 0.7212\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6088 - accuracy: 0.6587 - val_loss: 0.5812 - val_accuracy: 0.7276\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5967 - accuracy: 0.6865 - val_loss: 0.5730 - val_accuracy: 0.7404\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5750 - accuracy: 0.7080 - val_loss: 0.6420 - val_accuracy: 0.6250\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5785 - accuracy: 0.7103 - val_loss: 0.5618 - val_accuracy: 0.7340\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5668 - accuracy: 0.7273 - val_loss: 0.5699 - val_accuracy: 0.7244\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5644 - accuracy: 0.7166 - val_loss: 0.6398 - val_accuracy: 0.6154\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5676 - accuracy: 0.7120 - val_loss: 0.5627 - val_accuracy: 0.7372\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5622 - accuracy: 0.7205 - val_loss: 0.5555 - val_accuracy: 0.7372\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5549 - accuracy: 0.7273 - val_loss: 0.5575 - val_accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5638 - accuracy: 0.7166 - val_loss: 0.5617 - val_accuracy: 0.7179\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.7341 - val_loss: 0.5589 - val_accuracy: 0.7372\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5488 - accuracy: 0.7324 - val_loss: 0.5600 - val_accuracy: 0.7340\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5560 - accuracy: 0.7341 - val_loss: 0.5662 - val_accuracy: 0.7147\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5466 - accuracy: 0.7324 - val_loss: 0.5602 - val_accuracy: 0.7276\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5548 - accuracy: 0.7200 - val_loss: 0.5600 - val_accuracy: 0.7147\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5445 - accuracy: 0.7358 - val_loss: 0.5635 - val_accuracy: 0.7404\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5500 - accuracy: 0.7336 - val_loss: 0.5581 - val_accuracy: 0.7436\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5459 - accuracy: 0.7341 - val_loss: 0.5635 - val_accuracy: 0.7404\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7438 - val_loss: 0.5516 - val_accuracy: 0.7404\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5408 - accuracy: 0.7347 - val_loss: 0.5662 - val_accuracy: 0.7244\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.7302 - val_loss: 0.5592 - val_accuracy: 0.7276\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5449 - accuracy: 0.7285 - val_loss: 0.5579 - val_accuracy: 0.7372\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7336 - val_loss: 0.5635 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5422 - accuracy: 0.7279 - val_loss: 0.5529 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5351 - accuracy: 0.7381 - val_loss: 0.5792 - val_accuracy: 0.7308\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7426 - val_loss: 0.5583 - val_accuracy: 0.7372\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5435 - accuracy: 0.7222 - val_loss: 0.5525 - val_accuracy: 0.7404\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7460 - val_loss: 0.5595 - val_accuracy: 0.7340\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5313 - accuracy: 0.7449 - val_loss: 0.5692 - val_accuracy: 0.7147\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5320 - accuracy: 0.7477 - val_loss: 0.5621 - val_accuracy: 0.7212\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5420 - accuracy: 0.7330 - val_loss: 0.5773 - val_accuracy: 0.7340\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5320 - accuracy: 0.7443 - val_loss: 0.5550 - val_accuracy: 0.7276\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5263 - accuracy: 0.7534 - val_loss: 0.6200 - val_accuracy: 0.6955\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5270 - accuracy: 0.7579 - val_loss: 0.5607 - val_accuracy: 0.7372\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5299 - accuracy: 0.7489 - val_loss: 0.5590 - val_accuracy: 0.7308\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.7523 - val_loss: 0.5643 - val_accuracy: 0.7308\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5254 - accuracy: 0.7409 - val_loss: 0.5659 - val_accuracy: 0.7051\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7426 - val_loss: 0.5655 - val_accuracy: 0.7308\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5158 - accuracy: 0.7523 - val_loss: 0.5591 - val_accuracy: 0.7244\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5269 - accuracy: 0.7540 - val_loss: 0.5464 - val_accuracy: 0.7308\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5256 - accuracy: 0.7472 - val_loss: 0.5645 - val_accuracy: 0.7244\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5127 - accuracy: 0.7466 - val_loss: 0.5616 - val_accuracy: 0.7308\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5222 - accuracy: 0.7591 - val_loss: 0.5792 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5238 - accuracy: 0.7557 - val_loss: 0.5589 - val_accuracy: 0.7340\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5210 - accuracy: 0.7409 - val_loss: 0.5676 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5205 - accuracy: 0.7449 - val_loss: 0.5808 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.7540 - val_loss: 0.5757 - val_accuracy: 0.7372\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5194 - accuracy: 0.7545 - val_loss: 0.5608 - val_accuracy: 0.7308\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7192307692307692\n",
            "Accuracy: 0.7192307692307692\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6396 - accuracy: 0.6610 - val_loss: 0.6217 - val_accuracy: 0.6731\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6178 - accuracy: 0.6684 - val_loss: 0.6022 - val_accuracy: 0.6731\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6121 - accuracy: 0.6684 - val_loss: 0.5895 - val_accuracy: 0.6731\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6023 - accuracy: 0.6689 - val_loss: 0.5852 - val_accuracy: 0.7019\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5765 - accuracy: 0.7046 - val_loss: 0.5663 - val_accuracy: 0.7147\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5682 - accuracy: 0.7143 - val_loss: 0.5617 - val_accuracy: 0.7212\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5729 - accuracy: 0.7171 - val_loss: 0.5640 - val_accuracy: 0.7179\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5519 - accuracy: 0.7324 - val_loss: 0.5568 - val_accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5675 - accuracy: 0.7217 - val_loss: 0.5679 - val_accuracy: 0.6923\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5407 - accuracy: 0.7370 - val_loss: 0.5902 - val_accuracy: 0.6667\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.7234 - val_loss: 0.5567 - val_accuracy: 0.7115\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5542 - accuracy: 0.7404 - val_loss: 0.5462 - val_accuracy: 0.7372\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5442 - accuracy: 0.7313 - val_loss: 0.5533 - val_accuracy: 0.7244\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.7347 - val_loss: 0.5666 - val_accuracy: 0.6987\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.7421 - val_loss: 0.5630 - val_accuracy: 0.7083\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5475 - accuracy: 0.7290 - val_loss: 0.5626 - val_accuracy: 0.7436\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5404 - accuracy: 0.7438 - val_loss: 0.5570 - val_accuracy: 0.7340\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5322 - accuracy: 0.7477 - val_loss: 0.5552 - val_accuracy: 0.6955\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5381 - accuracy: 0.7381 - val_loss: 0.5473 - val_accuracy: 0.7212\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.7398 - val_loss: 0.5471 - val_accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5243 - accuracy: 0.7460 - val_loss: 0.5446 - val_accuracy: 0.7436\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5242 - accuracy: 0.7500 - val_loss: 0.5640 - val_accuracy: 0.7083\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5234 - accuracy: 0.7387 - val_loss: 0.5425 - val_accuracy: 0.7276\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5187 - accuracy: 0.7602 - val_loss: 0.5647 - val_accuracy: 0.6891\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5195 - accuracy: 0.7409 - val_loss: 0.5577 - val_accuracy: 0.6891\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5180 - accuracy: 0.7500 - val_loss: 0.5803 - val_accuracy: 0.7051\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5146 - accuracy: 0.7551 - val_loss: 0.5675 - val_accuracy: 0.6923\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5179 - accuracy: 0.7500 - val_loss: 0.5520 - val_accuracy: 0.7276\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5131 - accuracy: 0.7472 - val_loss: 0.5584 - val_accuracy: 0.7212\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5157 - accuracy: 0.7534 - val_loss: 0.5510 - val_accuracy: 0.7147\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5083 - accuracy: 0.7579 - val_loss: 0.5618 - val_accuracy: 0.7051\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5225 - accuracy: 0.7466 - val_loss: 0.5893 - val_accuracy: 0.6827\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7511 - val_loss: 0.5854 - val_accuracy: 0.7147\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5252 - accuracy: 0.7415 - val_loss: 0.5474 - val_accuracy: 0.7179\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.7517 - val_loss: 0.5651 - val_accuracy: 0.7276\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5056 - accuracy: 0.7613 - val_loss: 0.5489 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5180 - accuracy: 0.7500 - val_loss: 0.5667 - val_accuracy: 0.7147\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5088 - accuracy: 0.7585 - val_loss: 0.5511 - val_accuracy: 0.7372\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.7460 - val_loss: 0.5656 - val_accuracy: 0.7115\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5013 - accuracy: 0.7591 - val_loss: 0.5433 - val_accuracy: 0.7244\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5030 - accuracy: 0.7585 - val_loss: 0.5824 - val_accuracy: 0.6891\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4978 - accuracy: 0.7676 - val_loss: 0.5599 - val_accuracy: 0.7244\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5037 - accuracy: 0.7506 - val_loss: 0.5533 - val_accuracy: 0.7276\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4946 - accuracy: 0.7540 - val_loss: 0.5581 - val_accuracy: 0.7276\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5025 - accuracy: 0.7562 - val_loss: 0.5578 - val_accuracy: 0.7340\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5076 - accuracy: 0.7534 - val_loss: 0.5586 - val_accuracy: 0.7179\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5007 - accuracy: 0.7681 - val_loss: 0.5530 - val_accuracy: 0.7276\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.4983 - accuracy: 0.7591 - val_loss: 0.5644 - val_accuracy: 0.7276\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5009 - accuracy: 0.7574 - val_loss: 0.5625 - val_accuracy: 0.7179\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4956 - accuracy: 0.7602 - val_loss: 0.5746 - val_accuracy: 0.7244\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7057692307692308\n",
            "Accuracy: 0.7057692307692308\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 9ms/step - loss: 0.6438 - accuracy: 0.6559 - val_loss: 0.6313 - val_accuracy: 0.6731\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6339 - accuracy: 0.6610 - val_loss: 0.6223 - val_accuracy: 0.6731\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6144 - accuracy: 0.6638 - val_loss: 0.6125 - val_accuracy: 0.6731\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6003 - accuracy: 0.6723 - val_loss: 0.6290 - val_accuracy: 0.6667\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6122 - accuracy: 0.6655 - val_loss: 0.6141 - val_accuracy: 0.7019\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5796 - accuracy: 0.6820 - val_loss: 0.5893 - val_accuracy: 0.6987\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5787 - accuracy: 0.6910 - val_loss: 0.5782 - val_accuracy: 0.7308\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5760 - accuracy: 0.7018 - val_loss: 0.5767 - val_accuracy: 0.7276\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5720 - accuracy: 0.6990 - val_loss: 0.5666 - val_accuracy: 0.7179\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5782 - accuracy: 0.7018 - val_loss: 0.5799 - val_accuracy: 0.7179\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5603 - accuracy: 0.7137 - val_loss: 0.5794 - val_accuracy: 0.7147\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5749 - accuracy: 0.6842 - val_loss: 0.5777 - val_accuracy: 0.7115\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7234 - val_loss: 0.5875 - val_accuracy: 0.7083\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5550 - accuracy: 0.7177 - val_loss: 0.5750 - val_accuracy: 0.7244\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5545 - accuracy: 0.7217 - val_loss: 0.5912 - val_accuracy: 0.6827\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5635 - accuracy: 0.7183 - val_loss: 0.5653 - val_accuracy: 0.7179\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5577 - accuracy: 0.7029 - val_loss: 0.5743 - val_accuracy: 0.7115\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7194 - val_loss: 0.5575 - val_accuracy: 0.7404\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5498 - accuracy: 0.7098 - val_loss: 0.5669 - val_accuracy: 0.7244\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5504 - accuracy: 0.7126 - val_loss: 0.5791 - val_accuracy: 0.7147\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5467 - accuracy: 0.7177 - val_loss: 0.5615 - val_accuracy: 0.7532\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5462 - accuracy: 0.7251 - val_loss: 0.5644 - val_accuracy: 0.7147\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5438 - accuracy: 0.7313 - val_loss: 0.5589 - val_accuracy: 0.7404\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5576 - accuracy: 0.7058 - val_loss: 0.5797 - val_accuracy: 0.6795\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5364 - accuracy: 0.7296 - val_loss: 0.5706 - val_accuracy: 0.7083\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5490 - accuracy: 0.7256 - val_loss: 0.5937 - val_accuracy: 0.6603\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5485 - accuracy: 0.7273 - val_loss: 0.5798 - val_accuracy: 0.7147\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5541 - accuracy: 0.7188 - val_loss: 0.5633 - val_accuracy: 0.7404\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5424 - accuracy: 0.7262 - val_loss: 0.5638 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5452 - accuracy: 0.7319 - val_loss: 0.6198 - val_accuracy: 0.6603\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.7392 - val_loss: 0.5533 - val_accuracy: 0.7468\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7188 - val_loss: 0.5708 - val_accuracy: 0.7179\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5389 - accuracy: 0.7234 - val_loss: 0.5622 - val_accuracy: 0.7532\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7353 - val_loss: 0.5734 - val_accuracy: 0.7147\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7251 - val_loss: 0.5623 - val_accuracy: 0.7372\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7353 - val_loss: 0.5676 - val_accuracy: 0.7308\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7443 - val_loss: 0.5914 - val_accuracy: 0.7115\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7370 - val_loss: 0.5619 - val_accuracy: 0.7692\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5347 - accuracy: 0.7330 - val_loss: 0.5583 - val_accuracy: 0.7692\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5251 - accuracy: 0.7489 - val_loss: 0.5653 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5276 - accuracy: 0.7347 - val_loss: 0.5851 - val_accuracy: 0.7500\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7415 - val_loss: 0.5808 - val_accuracy: 0.7628\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.7370 - val_loss: 0.5839 - val_accuracy: 0.7436\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.7409 - val_loss: 0.5616 - val_accuracy: 0.7500\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5325 - accuracy: 0.7296 - val_loss: 0.5730 - val_accuracy: 0.7692\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5219 - accuracy: 0.7347 - val_loss: 0.5793 - val_accuracy: 0.7436\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5211 - accuracy: 0.7330 - val_loss: 0.5795 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5256 - accuracy: 0.7239 - val_loss: 0.5684 - val_accuracy: 0.7340\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7262 - val_loss: 0.5713 - val_accuracy: 0.7660\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.7460 - val_loss: 0.5718 - val_accuracy: 0.7628\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7326923076923076\n",
            "Accuracy: 0.7326923076923076\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 9ms/step - loss: 0.6379 - accuracy: 0.6593 - val_loss: 0.5986 - val_accuracy: 0.6731\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.6616 - val_loss: 0.5793 - val_accuracy: 0.6763\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6059 - accuracy: 0.6723 - val_loss: 0.5855 - val_accuracy: 0.6667\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5934 - accuracy: 0.6933 - val_loss: 0.5920 - val_accuracy: 0.7372\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5874 - accuracy: 0.7109 - val_loss: 0.5673 - val_accuracy: 0.7179\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5742 - accuracy: 0.7018 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5763 - accuracy: 0.7080 - val_loss: 0.5606 - val_accuracy: 0.7404\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5659 - accuracy: 0.7251 - val_loss: 0.5651 - val_accuracy: 0.7276\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5756 - accuracy: 0.7098 - val_loss: 0.5478 - val_accuracy: 0.7276\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5651 - accuracy: 0.7177 - val_loss: 0.5467 - val_accuracy: 0.7308\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5570 - accuracy: 0.7177 - val_loss: 0.5541 - val_accuracy: 0.7212\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5650 - accuracy: 0.7137 - val_loss: 0.5546 - val_accuracy: 0.7276\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5566 - accuracy: 0.7188 - val_loss: 0.5644 - val_accuracy: 0.7147\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5590 - accuracy: 0.7200 - val_loss: 0.5617 - val_accuracy: 0.7308\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5563 - accuracy: 0.7205 - val_loss: 0.5687 - val_accuracy: 0.7308\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5522 - accuracy: 0.7307 - val_loss: 0.5664 - val_accuracy: 0.6891\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5484 - accuracy: 0.7268 - val_loss: 0.5508 - val_accuracy: 0.7372\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5458 - accuracy: 0.7268 - val_loss: 0.5534 - val_accuracy: 0.7372\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5506 - accuracy: 0.7279 - val_loss: 0.5540 - val_accuracy: 0.7468\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5435 - accuracy: 0.7387 - val_loss: 0.5696 - val_accuracy: 0.6955\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5420 - accuracy: 0.7222 - val_loss: 0.5516 - val_accuracy: 0.7179\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5434 - accuracy: 0.7313 - val_loss: 0.5590 - val_accuracy: 0.7436\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5393 - accuracy: 0.7313 - val_loss: 0.5564 - val_accuracy: 0.7372\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7319 - val_loss: 0.5667 - val_accuracy: 0.7115\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5397 - accuracy: 0.7364 - val_loss: 0.5619 - val_accuracy: 0.7404\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5377 - accuracy: 0.7353 - val_loss: 0.5587 - val_accuracy: 0.7308\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.7279 - val_loss: 0.5623 - val_accuracy: 0.7179\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7302 - val_loss: 0.5795 - val_accuracy: 0.7372\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5338 - accuracy: 0.7432 - val_loss: 0.5611 - val_accuracy: 0.7468\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.7449 - val_loss: 0.5907 - val_accuracy: 0.6891\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.7302 - val_loss: 0.5753 - val_accuracy: 0.7308\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.7296 - val_loss: 0.5695 - val_accuracy: 0.7436\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5347 - accuracy: 0.7353 - val_loss: 0.5807 - val_accuracy: 0.7436\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5273 - accuracy: 0.7409 - val_loss: 0.5791 - val_accuracy: 0.7179\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5248 - accuracy: 0.7483 - val_loss: 0.5690 - val_accuracy: 0.7340\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.7415 - val_loss: 0.5904 - val_accuracy: 0.7115\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7409 - val_loss: 0.5728 - val_accuracy: 0.7404\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.7455 - val_loss: 0.5785 - val_accuracy: 0.7404\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5276 - accuracy: 0.7387 - val_loss: 0.5818 - val_accuracy: 0.7404\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5363 - accuracy: 0.7381 - val_loss: 0.5763 - val_accuracy: 0.7083\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7443 - val_loss: 0.5853 - val_accuracy: 0.7147\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5242 - accuracy: 0.7472 - val_loss: 0.5722 - val_accuracy: 0.7468\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5235 - accuracy: 0.7472 - val_loss: 0.5872 - val_accuracy: 0.7372\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5226 - accuracy: 0.7489 - val_loss: 0.5744 - val_accuracy: 0.7404\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5235 - accuracy: 0.7443 - val_loss: 0.6123 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.7460 - val_loss: 0.5756 - val_accuracy: 0.7276\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5148 - accuracy: 0.7489 - val_loss: 0.6290 - val_accuracy: 0.7340\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.7409 - val_loss: 0.6012 - val_accuracy: 0.7244\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.7579 - val_loss: 0.5799 - val_accuracy: 0.7532\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.7568 - val_loss: 0.6092 - val_accuracy: 0.7019\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6942307692307692\n",
            "Accuracy: 0.6942307692307692\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 6ms/step - loss: 0.6364 - accuracy: 0.6604 - val_loss: 0.6085 - val_accuracy: 0.6667\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6300 - accuracy: 0.6599 - val_loss: 0.5930 - val_accuracy: 0.6667\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6081 - accuracy: 0.6610 - val_loss: 0.5764 - val_accuracy: 0.6763\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5953 - accuracy: 0.6808 - val_loss: 0.5873 - val_accuracy: 0.6955\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5897 - accuracy: 0.7046 - val_loss: 0.5661 - val_accuracy: 0.7179\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5959 - accuracy: 0.6712 - val_loss: 0.5837 - val_accuracy: 0.7051\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5765 - accuracy: 0.7086 - val_loss: 0.5615 - val_accuracy: 0.7244\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5720 - accuracy: 0.7183 - val_loss: 0.5557 - val_accuracy: 0.7276\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5739 - accuracy: 0.7092 - val_loss: 0.5504 - val_accuracy: 0.7244\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5685 - accuracy: 0.7285 - val_loss: 0.5638 - val_accuracy: 0.7212\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5634 - accuracy: 0.7063 - val_loss: 0.5541 - val_accuracy: 0.7179\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.7307 - val_loss: 0.5669 - val_accuracy: 0.7147\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5530 - accuracy: 0.7313 - val_loss: 0.5572 - val_accuracy: 0.7147\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5656 - accuracy: 0.7149 - val_loss: 0.5481 - val_accuracy: 0.7340\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5501 - accuracy: 0.7177 - val_loss: 0.5501 - val_accuracy: 0.7147\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7375 - val_loss: 0.5674 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5477 - accuracy: 0.7307 - val_loss: 0.5643 - val_accuracy: 0.7244\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5487 - accuracy: 0.7290 - val_loss: 0.5519 - val_accuracy: 0.7308\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5493 - accuracy: 0.7341 - val_loss: 0.5480 - val_accuracy: 0.7372\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5417 - accuracy: 0.7392 - val_loss: 0.5553 - val_accuracy: 0.7212\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5377 - accuracy: 0.7387 - val_loss: 0.5559 - val_accuracy: 0.7276\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.7307 - val_loss: 0.5775 - val_accuracy: 0.7212\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5395 - accuracy: 0.7347 - val_loss: 0.5537 - val_accuracy: 0.7340\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5421 - accuracy: 0.7279 - val_loss: 0.5688 - val_accuracy: 0.7083\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7375 - val_loss: 0.5698 - val_accuracy: 0.7276\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5354 - accuracy: 0.7392 - val_loss: 0.5599 - val_accuracy: 0.7340\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.7466 - val_loss: 0.5607 - val_accuracy: 0.7179\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5358 - accuracy: 0.7307 - val_loss: 0.5615 - val_accuracy: 0.7340\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5279 - accuracy: 0.7426 - val_loss: 0.6189 - val_accuracy: 0.6635\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5370 - accuracy: 0.7358 - val_loss: 0.5535 - val_accuracy: 0.7212\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7455 - val_loss: 0.5538 - val_accuracy: 0.7147\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7438 - val_loss: 0.5678 - val_accuracy: 0.7179\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5391 - accuracy: 0.7324 - val_loss: 0.5729 - val_accuracy: 0.7147\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.7398 - val_loss: 0.5539 - val_accuracy: 0.7179\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5249 - accuracy: 0.7438 - val_loss: 0.5780 - val_accuracy: 0.7147\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.7415 - val_loss: 0.5583 - val_accuracy: 0.7147\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5279 - accuracy: 0.7432 - val_loss: 0.5554 - val_accuracy: 0.7179\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5263 - accuracy: 0.7415 - val_loss: 0.5551 - val_accuracy: 0.7308\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5183 - accuracy: 0.7528 - val_loss: 0.5645 - val_accuracy: 0.7212\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5171 - accuracy: 0.7517 - val_loss: 0.5671 - val_accuracy: 0.7212\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5196 - accuracy: 0.7438 - val_loss: 0.5613 - val_accuracy: 0.7212\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5255 - accuracy: 0.7489 - val_loss: 0.5732 - val_accuracy: 0.7051\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.7477 - val_loss: 0.5610 - val_accuracy: 0.7244\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5127 - accuracy: 0.7449 - val_loss: 0.5699 - val_accuracy: 0.7308\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5117 - accuracy: 0.7489 - val_loss: 0.5673 - val_accuracy: 0.7372\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.7489 - val_loss: 0.5559 - val_accuracy: 0.7276\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5161 - accuracy: 0.7494 - val_loss: 0.5614 - val_accuracy: 0.7404\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5105 - accuracy: 0.7455 - val_loss: 0.5743 - val_accuracy: 0.7212\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.7557 - val_loss: 0.5540 - val_accuracy: 0.7436\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.7472 - val_loss: 0.5646 - val_accuracy: 0.7083\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.725\n",
            "Accuracy: 0.725\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6372 - accuracy: 0.6616 - val_loss: 0.6233 - val_accuracy: 0.6603\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6242 - accuracy: 0.6695 - val_loss: 0.6232 - val_accuracy: 0.6603\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6073 - accuracy: 0.6695 - val_loss: 0.5865 - val_accuracy: 0.6603\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6007 - accuracy: 0.6814 - val_loss: 0.5864 - val_accuracy: 0.6763\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5813 - accuracy: 0.7035 - val_loss: 0.5774 - val_accuracy: 0.7083\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5824 - accuracy: 0.6984 - val_loss: 0.5946 - val_accuracy: 0.6699\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5634 - accuracy: 0.7205 - val_loss: 0.5744 - val_accuracy: 0.7019\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5661 - accuracy: 0.7205 - val_loss: 0.5874 - val_accuracy: 0.6891\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5629 - accuracy: 0.7137 - val_loss: 0.5653 - val_accuracy: 0.7212\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5660 - accuracy: 0.7222 - val_loss: 0.5781 - val_accuracy: 0.7051\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5552 - accuracy: 0.7341 - val_loss: 0.5671 - val_accuracy: 0.7051\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5477 - accuracy: 0.7154 - val_loss: 0.5656 - val_accuracy: 0.7115\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5628 - accuracy: 0.7234 - val_loss: 0.5635 - val_accuracy: 0.7212\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5515 - accuracy: 0.7381 - val_loss: 0.5613 - val_accuracy: 0.7147\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5450 - accuracy: 0.7330 - val_loss: 0.5721 - val_accuracy: 0.7179\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5498 - accuracy: 0.7319 - val_loss: 0.5597 - val_accuracy: 0.7147\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.7438 - val_loss: 0.5578 - val_accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5449 - accuracy: 0.7381 - val_loss: 0.5643 - val_accuracy: 0.7019\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.7330 - val_loss: 0.5604 - val_accuracy: 0.7340\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5340 - accuracy: 0.7438 - val_loss: 0.5768 - val_accuracy: 0.7083\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5449 - accuracy: 0.7353 - val_loss: 0.5571 - val_accuracy: 0.7340\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5435 - accuracy: 0.7387 - val_loss: 0.5965 - val_accuracy: 0.6987\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7370 - val_loss: 0.5585 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.7392 - val_loss: 0.5644 - val_accuracy: 0.7115\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5321 - accuracy: 0.7483 - val_loss: 0.5653 - val_accuracy: 0.7179\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7511 - val_loss: 0.5530 - val_accuracy: 0.7308\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5511 - accuracy: 0.7234 - val_loss: 0.5542 - val_accuracy: 0.7244\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7438 - val_loss: 0.5605 - val_accuracy: 0.7179\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5254 - accuracy: 0.7432 - val_loss: 0.5640 - val_accuracy: 0.7179\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7404 - val_loss: 0.5686 - val_accuracy: 0.7083\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7426 - val_loss: 0.5615 - val_accuracy: 0.7276\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.7443 - val_loss: 0.5659 - val_accuracy: 0.7179\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7432 - val_loss: 0.5581 - val_accuracy: 0.7340\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.7421 - val_loss: 0.5630 - val_accuracy: 0.7244\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5297 - accuracy: 0.7500 - val_loss: 0.5855 - val_accuracy: 0.7051\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5234 - accuracy: 0.7511 - val_loss: 0.5569 - val_accuracy: 0.7179\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5233 - accuracy: 0.7472 - val_loss: 0.5576 - val_accuracy: 0.7147\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5219 - accuracy: 0.7494 - val_loss: 0.5593 - val_accuracy: 0.7179\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5171 - accuracy: 0.7460 - val_loss: 0.5622 - val_accuracy: 0.7308\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5235 - accuracy: 0.7574 - val_loss: 0.5601 - val_accuracy: 0.7308\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5205 - accuracy: 0.7489 - val_loss: 0.5886 - val_accuracy: 0.6859\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5188 - accuracy: 0.7511 - val_loss: 0.5651 - val_accuracy: 0.7244\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5081 - accuracy: 0.7613 - val_loss: 0.6070 - val_accuracy: 0.6827\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5239 - accuracy: 0.7466 - val_loss: 0.5701 - val_accuracy: 0.7051\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5212 - accuracy: 0.7557 - val_loss: 0.5659 - val_accuracy: 0.7147\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5138 - accuracy: 0.7455 - val_loss: 0.5596 - val_accuracy: 0.7308\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.7579 - val_loss: 0.5586 - val_accuracy: 0.7147\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5167 - accuracy: 0.7477 - val_loss: 0.5678 - val_accuracy: 0.7147\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5077 - accuracy: 0.7653 - val_loss: 0.5742 - val_accuracy: 0.7212\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5090 - accuracy: 0.7636 - val_loss: 0.5823 - val_accuracy: 0.6987\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7192307692307692\n",
            "Accuracy: 0.7192307692307692\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6352 - accuracy: 0.6706 - val_loss: 0.6359 - val_accuracy: 0.6667\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6106 - accuracy: 0.6718 - val_loss: 0.6139 - val_accuracy: 0.6667\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5951 - accuracy: 0.6740 - val_loss: 0.6489 - val_accuracy: 0.5449\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5989 - accuracy: 0.6808 - val_loss: 0.6027 - val_accuracy: 0.6827\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5847 - accuracy: 0.7046 - val_loss: 0.5916 - val_accuracy: 0.6955\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5675 - accuracy: 0.7200 - val_loss: 0.6195 - val_accuracy: 0.6987\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5610 - accuracy: 0.7245 - val_loss: 0.6295 - val_accuracy: 0.6667\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5785 - accuracy: 0.6899 - val_loss: 0.6180 - val_accuracy: 0.7147\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5608 - accuracy: 0.7268 - val_loss: 0.5864 - val_accuracy: 0.7212\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5428 - accuracy: 0.7387 - val_loss: 0.5923 - val_accuracy: 0.7051\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5512 - accuracy: 0.7183 - val_loss: 0.5975 - val_accuracy: 0.7212\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5524 - accuracy: 0.7353 - val_loss: 0.5899 - val_accuracy: 0.7051\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5535 - accuracy: 0.7279 - val_loss: 0.5848 - val_accuracy: 0.7276\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5465 - accuracy: 0.7330 - val_loss: 0.6207 - val_accuracy: 0.6538\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5579 - accuracy: 0.7109 - val_loss: 0.6043 - val_accuracy: 0.6763\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5460 - accuracy: 0.7268 - val_loss: 0.5885 - val_accuracy: 0.7179\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5405 - accuracy: 0.7234 - val_loss: 0.6225 - val_accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.7251 - val_loss: 0.5967 - val_accuracy: 0.6923\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5376 - accuracy: 0.7415 - val_loss: 0.6130 - val_accuracy: 0.7147\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5414 - accuracy: 0.7364 - val_loss: 0.5922 - val_accuracy: 0.7147\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5453 - accuracy: 0.7330 - val_loss: 0.5988 - val_accuracy: 0.7083\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7392 - val_loss: 0.5834 - val_accuracy: 0.7244\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5425 - accuracy: 0.7364 - val_loss: 0.6270 - val_accuracy: 0.7051\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.7387 - val_loss: 0.5856 - val_accuracy: 0.7019\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5268 - accuracy: 0.7409 - val_loss: 0.6209 - val_accuracy: 0.7147\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7387 - val_loss: 0.5873 - val_accuracy: 0.7019\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7415 - val_loss: 0.6182 - val_accuracy: 0.7179\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.7381 - val_loss: 0.5884 - val_accuracy: 0.7179\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7472 - val_loss: 0.6059 - val_accuracy: 0.7179\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5276 - accuracy: 0.7449 - val_loss: 0.5911 - val_accuracy: 0.6891\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5231 - accuracy: 0.7455 - val_loss: 0.6167 - val_accuracy: 0.6699\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5314 - accuracy: 0.7358 - val_loss: 0.5988 - val_accuracy: 0.7019\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5216 - accuracy: 0.7404 - val_loss: 0.5976 - val_accuracy: 0.6859\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5174 - accuracy: 0.7517 - val_loss: 0.6450 - val_accuracy: 0.6891\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5164 - accuracy: 0.7528 - val_loss: 0.5922 - val_accuracy: 0.7372\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.7466 - val_loss: 0.6033 - val_accuracy: 0.7308\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7477 - val_loss: 0.5893 - val_accuracy: 0.7147\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.7483 - val_loss: 0.5909 - val_accuracy: 0.7276\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7387 - val_loss: 0.6236 - val_accuracy: 0.7179\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7506 - val_loss: 0.6000 - val_accuracy: 0.7051\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5097 - accuracy: 0.7591 - val_loss: 0.5942 - val_accuracy: 0.6987\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5104 - accuracy: 0.7568 - val_loss: 0.6067 - val_accuracy: 0.6923\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5113 - accuracy: 0.7472 - val_loss: 0.5853 - val_accuracy: 0.7179\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5197 - accuracy: 0.7528 - val_loss: 0.6066 - val_accuracy: 0.7083\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5125 - accuracy: 0.7557 - val_loss: 0.6058 - val_accuracy: 0.7212\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5135 - accuracy: 0.7494 - val_loss: 0.6044 - val_accuracy: 0.7019\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5152 - accuracy: 0.7438 - val_loss: 0.6065 - val_accuracy: 0.7276\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5075 - accuracy: 0.7596 - val_loss: 0.6299 - val_accuracy: 0.7051\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5080 - accuracy: 0.7579 - val_loss: 0.5999 - val_accuracy: 0.7115\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5109 - accuracy: 0.7562 - val_loss: 0.6308 - val_accuracy: 0.6955\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7134615384615385\n",
            "Accuracy: 0.7134615384615385\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6304 - accuracy: 0.6735 - val_loss: 0.6510 - val_accuracy: 0.6282\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6274 - accuracy: 0.6723 - val_loss: 0.6441 - val_accuracy: 0.6282\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6042 - accuracy: 0.6752 - val_loss: 0.6212 - val_accuracy: 0.6442\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5994 - accuracy: 0.6990 - val_loss: 0.6233 - val_accuracy: 0.6506\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5840 - accuracy: 0.7109 - val_loss: 0.6249 - val_accuracy: 0.6571\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5731 - accuracy: 0.7166 - val_loss: 0.5982 - val_accuracy: 0.6827\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7132 - val_loss: 0.5933 - val_accuracy: 0.6987\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5727 - accuracy: 0.7143 - val_loss: 0.6359 - val_accuracy: 0.6410\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5699 - accuracy: 0.7120 - val_loss: 0.5944 - val_accuracy: 0.6955\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5538 - accuracy: 0.7353 - val_loss: 0.5986 - val_accuracy: 0.6763\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.7460 - val_loss: 0.6229 - val_accuracy: 0.6635\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5510 - accuracy: 0.7217 - val_loss: 0.5866 - val_accuracy: 0.6987\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5540 - accuracy: 0.7268 - val_loss: 0.5882 - val_accuracy: 0.6795\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7375 - val_loss: 0.5825 - val_accuracy: 0.6987\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5585 - accuracy: 0.7313 - val_loss: 0.6001 - val_accuracy: 0.7019\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.7319 - val_loss: 0.5867 - val_accuracy: 0.7019\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5451 - accuracy: 0.7319 - val_loss: 0.5880 - val_accuracy: 0.6795\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5429 - accuracy: 0.7313 - val_loss: 0.5814 - val_accuracy: 0.7115\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5409 - accuracy: 0.7398 - val_loss: 0.5863 - val_accuracy: 0.6891\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5458 - accuracy: 0.7353 - val_loss: 0.5973 - val_accuracy: 0.6795\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5310 - accuracy: 0.7387 - val_loss: 0.5991 - val_accuracy: 0.7019\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5328 - accuracy: 0.7460 - val_loss: 0.5959 - val_accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7364 - val_loss: 0.5856 - val_accuracy: 0.7019\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5358 - accuracy: 0.7409 - val_loss: 0.6017 - val_accuracy: 0.6763\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5307 - accuracy: 0.7387 - val_loss: 0.5798 - val_accuracy: 0.6923\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5338 - accuracy: 0.7426 - val_loss: 0.6048 - val_accuracy: 0.6763\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5264 - accuracy: 0.7460 - val_loss: 0.6110 - val_accuracy: 0.6667\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5306 - accuracy: 0.7591 - val_loss: 0.6098 - val_accuracy: 0.6795\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5199 - accuracy: 0.7443 - val_loss: 0.5938 - val_accuracy: 0.6603\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5248 - accuracy: 0.7477 - val_loss: 0.6214 - val_accuracy: 0.6795\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5276 - accuracy: 0.7455 - val_loss: 0.5950 - val_accuracy: 0.6859\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.7613 - val_loss: 0.5914 - val_accuracy: 0.6923\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5152 - accuracy: 0.7506 - val_loss: 0.6073 - val_accuracy: 0.6891\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5197 - accuracy: 0.7534 - val_loss: 0.5894 - val_accuracy: 0.6731\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5167 - accuracy: 0.7557 - val_loss: 0.5972 - val_accuracy: 0.6763\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.7398 - val_loss: 0.6321 - val_accuracy: 0.6827\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5274 - accuracy: 0.7506 - val_loss: 0.6011 - val_accuracy: 0.6603\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5163 - accuracy: 0.7596 - val_loss: 0.5854 - val_accuracy: 0.6635\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5114 - accuracy: 0.7664 - val_loss: 0.6167 - val_accuracy: 0.6859\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5163 - accuracy: 0.7483 - val_loss: 0.6079 - val_accuracy: 0.6923\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.7596 - val_loss: 0.6026 - val_accuracy: 0.6763\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5124 - accuracy: 0.7579 - val_loss: 0.5962 - val_accuracy: 0.6795\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5040 - accuracy: 0.7585 - val_loss: 0.6000 - val_accuracy: 0.6827\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5055 - accuracy: 0.7625 - val_loss: 0.6089 - val_accuracy: 0.6699\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5242 - accuracy: 0.7540 - val_loss: 0.5998 - val_accuracy: 0.6699\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5038 - accuracy: 0.7642 - val_loss: 0.6232 - val_accuracy: 0.6859\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5248 - accuracy: 0.7517 - val_loss: 0.5887 - val_accuracy: 0.6795\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5044 - accuracy: 0.7625 - val_loss: 0.6124 - val_accuracy: 0.6859\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.7659 - val_loss: 0.6393 - val_accuracy: 0.6859\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5091 - accuracy: 0.7630 - val_loss: 0.6137 - val_accuracy: 0.6731\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7115384615384616\n",
            "Accuracy: 0.7115384615384616\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 9ms/step - loss: 0.6481 - accuracy: 0.6451 - val_loss: 0.5815 - val_accuracy: 0.7244\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6418 - accuracy: 0.6457 - val_loss: 0.5586 - val_accuracy: 0.7244\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6198 - accuracy: 0.6593 - val_loss: 0.5327 - val_accuracy: 0.7436\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6097 - accuracy: 0.6797 - val_loss: 0.5411 - val_accuracy: 0.7468\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5996 - accuracy: 0.6933 - val_loss: 0.5253 - val_accuracy: 0.7436\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5884 - accuracy: 0.7001 - val_loss: 0.5965 - val_accuracy: 0.6571\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5840 - accuracy: 0.7063 - val_loss: 0.5420 - val_accuracy: 0.7564\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5888 - accuracy: 0.6933 - val_loss: 0.5225 - val_accuracy: 0.7404\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5699 - accuracy: 0.7132 - val_loss: 0.5095 - val_accuracy: 0.7532\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5912 - accuracy: 0.6984 - val_loss: 0.5290 - val_accuracy: 0.7308\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5706 - accuracy: 0.7149 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5711 - accuracy: 0.7171 - val_loss: 0.5373 - val_accuracy: 0.7340\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5619 - accuracy: 0.7211 - val_loss: 0.5601 - val_accuracy: 0.7340\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5652 - accuracy: 0.7154 - val_loss: 0.5363 - val_accuracy: 0.7372\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5584 - accuracy: 0.7160 - val_loss: 0.5103 - val_accuracy: 0.7692\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5681 - accuracy: 0.7166 - val_loss: 0.5415 - val_accuracy: 0.7468\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7211 - val_loss: 0.5353 - val_accuracy: 0.7372\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5586 - accuracy: 0.7160 - val_loss: 0.5435 - val_accuracy: 0.7147\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5524 - accuracy: 0.7279 - val_loss: 0.5127 - val_accuracy: 0.7692\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.7262 - val_loss: 0.5618 - val_accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5622 - accuracy: 0.7319 - val_loss: 0.5456 - val_accuracy: 0.7212\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5525 - accuracy: 0.7347 - val_loss: 0.5242 - val_accuracy: 0.7564\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5491 - accuracy: 0.7239 - val_loss: 0.5208 - val_accuracy: 0.7788\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5648 - accuracy: 0.7126 - val_loss: 0.5184 - val_accuracy: 0.7756\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5444 - accuracy: 0.7375 - val_loss: 0.5216 - val_accuracy: 0.7756\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5497 - accuracy: 0.7273 - val_loss: 0.5218 - val_accuracy: 0.7596\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5500 - accuracy: 0.7302 - val_loss: 0.5156 - val_accuracy: 0.7724\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5391 - accuracy: 0.7443 - val_loss: 0.5857 - val_accuracy: 0.7051\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5454 - accuracy: 0.7415 - val_loss: 0.5281 - val_accuracy: 0.7692\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7239 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.7460 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5459 - accuracy: 0.7404 - val_loss: 0.5360 - val_accuracy: 0.7692\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5441 - accuracy: 0.7313 - val_loss: 0.5668 - val_accuracy: 0.7019\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7279 - val_loss: 0.5161 - val_accuracy: 0.7596\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5405 - accuracy: 0.7421 - val_loss: 0.5519 - val_accuracy: 0.7500\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5358 - accuracy: 0.7460 - val_loss: 0.5634 - val_accuracy: 0.7436\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5398 - accuracy: 0.7381 - val_loss: 0.5762 - val_accuracy: 0.7340\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7358 - val_loss: 0.5181 - val_accuracy: 0.7628\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5289 - accuracy: 0.7562 - val_loss: 0.5702 - val_accuracy: 0.7404\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5373 - accuracy: 0.7381 - val_loss: 0.5497 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5373 - accuracy: 0.7375 - val_loss: 0.5257 - val_accuracy: 0.7564\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7506 - val_loss: 0.5968 - val_accuracy: 0.7340\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5283 - accuracy: 0.7483 - val_loss: 0.5427 - val_accuracy: 0.7660\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5260 - accuracy: 0.7494 - val_loss: 0.5584 - val_accuracy: 0.7756\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5401 - accuracy: 0.7415 - val_loss: 0.5278 - val_accuracy: 0.7660\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7409 - val_loss: 0.5932 - val_accuracy: 0.7212\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5233 - accuracy: 0.7551 - val_loss: 0.6168 - val_accuracy: 0.7115\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5419 - accuracy: 0.7313 - val_loss: 0.5323 - val_accuracy: 0.7596\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5303 - accuracy: 0.7523 - val_loss: 0.5714 - val_accuracy: 0.7308\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5217 - accuracy: 0.7466 - val_loss: 0.5596 - val_accuracy: 0.7628\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7192307692307692\n",
            "Accuracy: 0.7192307692307692\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 9ms/step - loss: 0.6297 - accuracy: 0.6633 - val_loss: 0.6345 - val_accuracy: 0.6571\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6316 - accuracy: 0.6633 - val_loss: 0.6087 - val_accuracy: 0.6571\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6105 - accuracy: 0.6633 - val_loss: 0.5938 - val_accuracy: 0.6731\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6049 - accuracy: 0.6746 - val_loss: 0.6019 - val_accuracy: 0.6731\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5965 - accuracy: 0.6893 - val_loss: 0.5765 - val_accuracy: 0.6763\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5866 - accuracy: 0.7086 - val_loss: 0.5658 - val_accuracy: 0.7051\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5764 - accuracy: 0.7132 - val_loss: 0.5782 - val_accuracy: 0.7276\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5839 - accuracy: 0.7115 - val_loss: 0.5574 - val_accuracy: 0.7115\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5855 - accuracy: 0.7018 - val_loss: 0.5613 - val_accuracy: 0.7276\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5656 - accuracy: 0.7177 - val_loss: 0.5695 - val_accuracy: 0.7051\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5737 - accuracy: 0.7251 - val_loss: 0.6071 - val_accuracy: 0.6859\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5750 - accuracy: 0.7154 - val_loss: 0.5544 - val_accuracy: 0.7147\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5652 - accuracy: 0.7188 - val_loss: 0.5550 - val_accuracy: 0.7179\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5594 - accuracy: 0.7222 - val_loss: 0.5434 - val_accuracy: 0.7179\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5580 - accuracy: 0.7268 - val_loss: 0.5669 - val_accuracy: 0.6923\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5634 - accuracy: 0.7234 - val_loss: 0.5563 - val_accuracy: 0.7115\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5590 - accuracy: 0.7217 - val_loss: 0.5534 - val_accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5529 - accuracy: 0.7279 - val_loss: 0.5565 - val_accuracy: 0.7276\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5672 - accuracy: 0.7256 - val_loss: 0.5766 - val_accuracy: 0.6827\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5624 - accuracy: 0.7251 - val_loss: 0.5584 - val_accuracy: 0.7051\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5521 - accuracy: 0.7324 - val_loss: 0.5455 - val_accuracy: 0.7276\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5460 - accuracy: 0.7313 - val_loss: 0.5442 - val_accuracy: 0.7340\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5550 - accuracy: 0.7273 - val_loss: 0.5467 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5464 - accuracy: 0.7336 - val_loss: 0.5597 - val_accuracy: 0.7468\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5508 - accuracy: 0.7302 - val_loss: 0.5506 - val_accuracy: 0.7276\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5475 - accuracy: 0.7347 - val_loss: 0.5651 - val_accuracy: 0.7115\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.7341 - val_loss: 0.5533 - val_accuracy: 0.7276\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5456 - accuracy: 0.7341 - val_loss: 0.5605 - val_accuracy: 0.7051\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5530 - accuracy: 0.7370 - val_loss: 0.5567 - val_accuracy: 0.7244\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5392 - accuracy: 0.7415 - val_loss: 0.5738 - val_accuracy: 0.6891\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.7455 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5406 - accuracy: 0.7353 - val_loss: 0.5509 - val_accuracy: 0.7276\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5433 - accuracy: 0.7302 - val_loss: 0.5532 - val_accuracy: 0.7147\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.7421 - val_loss: 0.5559 - val_accuracy: 0.7372\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5457 - accuracy: 0.7307 - val_loss: 0.5563 - val_accuracy: 0.7212\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5360 - accuracy: 0.7472 - val_loss: 0.5625 - val_accuracy: 0.7083\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5421 - accuracy: 0.7330 - val_loss: 0.5640 - val_accuracy: 0.6923\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7330 - val_loss: 0.5446 - val_accuracy: 0.7244\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5348 - accuracy: 0.7398 - val_loss: 0.5498 - val_accuracy: 0.7212\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5296 - accuracy: 0.7358 - val_loss: 0.5510 - val_accuracy: 0.7083\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7443 - val_loss: 0.5726 - val_accuracy: 0.7276\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5265 - accuracy: 0.7421 - val_loss: 0.5550 - val_accuracy: 0.7115\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5301 - accuracy: 0.7409 - val_loss: 0.5625 - val_accuracy: 0.7179\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5314 - accuracy: 0.7443 - val_loss: 0.5494 - val_accuracy: 0.7147\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5307 - accuracy: 0.7432 - val_loss: 0.5536 - val_accuracy: 0.7147\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.7591 - val_loss: 0.5545 - val_accuracy: 0.7308\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5229 - accuracy: 0.7562 - val_loss: 0.5596 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5230 - accuracy: 0.7506 - val_loss: 0.5493 - val_accuracy: 0.7212\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5295 - accuracy: 0.7387 - val_loss: 0.5780 - val_accuracy: 0.6923\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5240 - accuracy: 0.7540 - val_loss: 0.6041 - val_accuracy: 0.6859\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7\n",
            "Accuracy: 0.7\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 9ms/step - loss: 0.6347 - accuracy: 0.6604 - val_loss: 0.6364 - val_accuracy: 0.6763\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6155 - accuracy: 0.6616 - val_loss: 0.6151 - val_accuracy: 0.6763\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5974 - accuracy: 0.6797 - val_loss: 0.5800 - val_accuracy: 0.7147\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5869 - accuracy: 0.6995 - val_loss: 0.5780 - val_accuracy: 0.7212\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5725 - accuracy: 0.7205 - val_loss: 0.5792 - val_accuracy: 0.6923\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5659 - accuracy: 0.7160 - val_loss: 0.5756 - val_accuracy: 0.7212\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7183 - val_loss: 0.5725 - val_accuracy: 0.7340\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5558 - accuracy: 0.7222 - val_loss: 0.5823 - val_accuracy: 0.7115\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5512 - accuracy: 0.7262 - val_loss: 0.5695 - val_accuracy: 0.7179\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5581 - accuracy: 0.7307 - val_loss: 0.5672 - val_accuracy: 0.7340\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5486 - accuracy: 0.7245 - val_loss: 0.5705 - val_accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5407 - accuracy: 0.7426 - val_loss: 0.5669 - val_accuracy: 0.7404\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5472 - accuracy: 0.7279 - val_loss: 0.5692 - val_accuracy: 0.7404\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5462 - accuracy: 0.7347 - val_loss: 0.5689 - val_accuracy: 0.7340\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7370 - val_loss: 0.5754 - val_accuracy: 0.7308\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7319 - val_loss: 0.5674 - val_accuracy: 0.7372\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5327 - accuracy: 0.7319 - val_loss: 0.6108 - val_accuracy: 0.6891\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.7483 - val_loss: 0.5882 - val_accuracy: 0.7244\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5452 - accuracy: 0.7302 - val_loss: 0.5725 - val_accuracy: 0.7147\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5387 - accuracy: 0.7387 - val_loss: 0.5596 - val_accuracy: 0.7308\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5307 - accuracy: 0.7341 - val_loss: 0.5935 - val_accuracy: 0.6923\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5339 - accuracy: 0.7358 - val_loss: 0.5618 - val_accuracy: 0.7372\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5306 - accuracy: 0.7341 - val_loss: 0.5588 - val_accuracy: 0.7276\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5305 - accuracy: 0.7477 - val_loss: 0.5702 - val_accuracy: 0.7276\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.7511 - val_loss: 0.5901 - val_accuracy: 0.7404\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7398 - val_loss: 0.5617 - val_accuracy: 0.7404\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5252 - accuracy: 0.7506 - val_loss: 0.5602 - val_accuracy: 0.7340\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.7443 - val_loss: 0.6001 - val_accuracy: 0.6923\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5251 - accuracy: 0.7449 - val_loss: 0.5692 - val_accuracy: 0.7500\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5269 - accuracy: 0.7409 - val_loss: 0.5799 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.7443 - val_loss: 0.5586 - val_accuracy: 0.7468\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7477 - val_loss: 0.5702 - val_accuracy: 0.7404\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5167 - accuracy: 0.7477 - val_loss: 0.5917 - val_accuracy: 0.6955\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5138 - accuracy: 0.7415 - val_loss: 0.5704 - val_accuracy: 0.7436\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.7375 - val_loss: 0.5643 - val_accuracy: 0.7564\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.7449 - val_loss: 0.5680 - val_accuracy: 0.7468\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5205 - accuracy: 0.7466 - val_loss: 0.5738 - val_accuracy: 0.7436\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5083 - accuracy: 0.7557 - val_loss: 0.5914 - val_accuracy: 0.7179\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5115 - accuracy: 0.7528 - val_loss: 0.5979 - val_accuracy: 0.7244\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5124 - accuracy: 0.7528 - val_loss: 0.5645 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5179 - accuracy: 0.7511 - val_loss: 0.5775 - val_accuracy: 0.7372\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5691 - val_accuracy: 0.7244\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5070 - accuracy: 0.7608 - val_loss: 0.5660 - val_accuracy: 0.7308\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5110 - accuracy: 0.7455 - val_loss: 0.5964 - val_accuracy: 0.7212\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.7540 - val_loss: 0.5987 - val_accuracy: 0.7468\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5133 - accuracy: 0.7500 - val_loss: 0.5679 - val_accuracy: 0.7532\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5051 - accuracy: 0.7500 - val_loss: 0.6089 - val_accuracy: 0.6859\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5056 - accuracy: 0.7523 - val_loss: 0.5780 - val_accuracy: 0.7308\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4991 - accuracy: 0.7517 - val_loss: 0.5971 - val_accuracy: 0.7019\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5012 - accuracy: 0.7596 - val_loss: 0.5704 - val_accuracy: 0.7500\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7230769230769231\n",
            "Accuracy: 0.7230769230769231\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 7ms/step - loss: 0.6367 - accuracy: 0.6621 - val_loss: 0.5822 - val_accuracy: 0.7179\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6219 - accuracy: 0.6621 - val_loss: 0.5814 - val_accuracy: 0.7179\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5975 - accuracy: 0.6718 - val_loss: 0.5532 - val_accuracy: 0.7340\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5748 - accuracy: 0.7063 - val_loss: 0.5556 - val_accuracy: 0.7340\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5676 - accuracy: 0.7166 - val_loss: 0.5551 - val_accuracy: 0.7115\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5685 - accuracy: 0.7177 - val_loss: 0.5372 - val_accuracy: 0.7404\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5634 - accuracy: 0.7188 - val_loss: 0.5617 - val_accuracy: 0.7372\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5613 - accuracy: 0.7245 - val_loss: 0.5995 - val_accuracy: 0.6763\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5638 - accuracy: 0.7160 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5578 - accuracy: 0.7217 - val_loss: 0.5650 - val_accuracy: 0.6891\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5512 - accuracy: 0.7285 - val_loss: 0.5344 - val_accuracy: 0.7564\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5557 - accuracy: 0.7166 - val_loss: 0.5295 - val_accuracy: 0.7564\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5509 - accuracy: 0.7256 - val_loss: 0.5247 - val_accuracy: 0.7692\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5428 - accuracy: 0.7324 - val_loss: 0.5237 - val_accuracy: 0.7724\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5449 - accuracy: 0.7347 - val_loss: 0.5257 - val_accuracy: 0.7596\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5474 - accuracy: 0.7285 - val_loss: 0.5938 - val_accuracy: 0.6538\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5382 - accuracy: 0.7381 - val_loss: 0.5261 - val_accuracy: 0.7564\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5405 - accuracy: 0.7347 - val_loss: 0.5262 - val_accuracy: 0.7596\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5433 - accuracy: 0.7336 - val_loss: 0.5197 - val_accuracy: 0.7564\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5399 - accuracy: 0.7494 - val_loss: 0.5244 - val_accuracy: 0.7660\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5380 - accuracy: 0.7415 - val_loss: 0.5199 - val_accuracy: 0.7628\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5412 - accuracy: 0.7330 - val_loss: 0.5357 - val_accuracy: 0.7564\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.7347 - val_loss: 0.5288 - val_accuracy: 0.7628\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5387 - accuracy: 0.7285 - val_loss: 0.5278 - val_accuracy: 0.7628\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5301 - accuracy: 0.7375 - val_loss: 0.5403 - val_accuracy: 0.7115\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5431 - accuracy: 0.7398 - val_loss: 0.5304 - val_accuracy: 0.7468\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5354 - accuracy: 0.7421 - val_loss: 0.5262 - val_accuracy: 0.7628\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5273 - accuracy: 0.7398 - val_loss: 0.5248 - val_accuracy: 0.7564\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.7477 - val_loss: 0.5204 - val_accuracy: 0.7596\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5345 - accuracy: 0.7347 - val_loss: 0.5271 - val_accuracy: 0.7628\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5326 - accuracy: 0.7455 - val_loss: 0.5336 - val_accuracy: 0.7212\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.7313 - val_loss: 0.5309 - val_accuracy: 0.7468\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7460 - val_loss: 0.5150 - val_accuracy: 0.7628\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.7438 - val_loss: 0.5334 - val_accuracy: 0.7404\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.7528 - val_loss: 0.5237 - val_accuracy: 0.7436\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5221 - accuracy: 0.7517 - val_loss: 0.5225 - val_accuracy: 0.7788\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.7562 - val_loss: 0.5401 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.7557 - val_loss: 0.5230 - val_accuracy: 0.7436\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5132 - accuracy: 0.7613 - val_loss: 0.5263 - val_accuracy: 0.7596\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5205 - accuracy: 0.7466 - val_loss: 0.5326 - val_accuracy: 0.7532\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5133 - accuracy: 0.7472 - val_loss: 0.5235 - val_accuracy: 0.7628\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5122 - accuracy: 0.7579 - val_loss: 0.5406 - val_accuracy: 0.7308\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5194 - accuracy: 0.7483 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5186 - accuracy: 0.7528 - val_loss: 0.5213 - val_accuracy: 0.7596\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.7534 - val_loss: 0.5766 - val_accuracy: 0.6827\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5087 - accuracy: 0.7596 - val_loss: 0.5318 - val_accuracy: 0.7532\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5145 - accuracy: 0.7443 - val_loss: 0.5462 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7585 - val_loss: 0.5261 - val_accuracy: 0.7628\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5096 - accuracy: 0.7585 - val_loss: 0.5417 - val_accuracy: 0.7308\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5098 - accuracy: 0.7579 - val_loss: 0.5239 - val_accuracy: 0.7564\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6884615384615385\n",
            "Accuracy: 0.6884615384615385\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6403 - accuracy: 0.6451 - val_loss: 0.6305 - val_accuracy: 0.6763\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6064 - accuracy: 0.6706 - val_loss: 0.6051 - val_accuracy: 0.6891\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5890 - accuracy: 0.7007 - val_loss: 0.5986 - val_accuracy: 0.6955\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5650 - accuracy: 0.7285 - val_loss: 0.6171 - val_accuracy: 0.6506\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5764 - accuracy: 0.7188 - val_loss: 0.5898 - val_accuracy: 0.7019\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5734 - accuracy: 0.7115 - val_loss: 0.6205 - val_accuracy: 0.6154\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5641 - accuracy: 0.7262 - val_loss: 0.5953 - val_accuracy: 0.6635\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5560 - accuracy: 0.7245 - val_loss: 0.5849 - val_accuracy: 0.6955\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5507 - accuracy: 0.7273 - val_loss: 0.5825 - val_accuracy: 0.6987\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7330 - val_loss: 0.5782 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5492 - accuracy: 0.7273 - val_loss: 0.5861 - val_accuracy: 0.7051\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5554 - accuracy: 0.7290 - val_loss: 0.5969 - val_accuracy: 0.7019\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5593 - accuracy: 0.7211 - val_loss: 0.5767 - val_accuracy: 0.7051\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5408 - accuracy: 0.7404 - val_loss: 0.5921 - val_accuracy: 0.7051\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5406 - accuracy: 0.7370 - val_loss: 0.6051 - val_accuracy: 0.6763\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5467 - accuracy: 0.7319 - val_loss: 0.5787 - val_accuracy: 0.6955\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5479 - accuracy: 0.7290 - val_loss: 0.5899 - val_accuracy: 0.6795\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5396 - accuracy: 0.7455 - val_loss: 0.5706 - val_accuracy: 0.7244\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5358 - accuracy: 0.7432 - val_loss: 0.6756 - val_accuracy: 0.6218\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5431 - accuracy: 0.7375 - val_loss: 0.6030 - val_accuracy: 0.6474\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5381 - accuracy: 0.7358 - val_loss: 0.5701 - val_accuracy: 0.7212\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5345 - accuracy: 0.7426 - val_loss: 0.5888 - val_accuracy: 0.6859\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5296 - accuracy: 0.7336 - val_loss: 0.5800 - val_accuracy: 0.7051\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5208 - accuracy: 0.7523 - val_loss: 0.5724 - val_accuracy: 0.7147\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5394 - accuracy: 0.7330 - val_loss: 0.5707 - val_accuracy: 0.7308\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5373 - accuracy: 0.7404 - val_loss: 0.5934 - val_accuracy: 0.6891\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5262 - accuracy: 0.7398 - val_loss: 0.5951 - val_accuracy: 0.6891\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.7460 - val_loss: 0.5603 - val_accuracy: 0.7179\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.7432 - val_loss: 0.5653 - val_accuracy: 0.7179\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5241 - accuracy: 0.7438 - val_loss: 0.5672 - val_accuracy: 0.7244\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7381 - val_loss: 0.6096 - val_accuracy: 0.6474\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7404 - val_loss: 0.5720 - val_accuracy: 0.7179\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5222 - accuracy: 0.7483 - val_loss: 0.5859 - val_accuracy: 0.7147\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5184 - accuracy: 0.7517 - val_loss: 0.5745 - val_accuracy: 0.7179\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5223 - accuracy: 0.7438 - val_loss: 0.5850 - val_accuracy: 0.7019\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5068 - accuracy: 0.7568 - val_loss: 0.6277 - val_accuracy: 0.6603\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5153 - accuracy: 0.7551 - val_loss: 0.5789 - val_accuracy: 0.7147\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5174 - accuracy: 0.7562 - val_loss: 0.5646 - val_accuracy: 0.7212\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5197 - accuracy: 0.7438 - val_loss: 0.5769 - val_accuracy: 0.7019\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5258 - accuracy: 0.7358 - val_loss: 0.5827 - val_accuracy: 0.7051\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.7619 - val_loss: 0.5741 - val_accuracy: 0.7244\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5168 - accuracy: 0.7438 - val_loss: 0.5651 - val_accuracy: 0.7244\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5183 - accuracy: 0.7443 - val_loss: 0.5750 - val_accuracy: 0.7244\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5199 - accuracy: 0.7523 - val_loss: 0.5643 - val_accuracy: 0.7308\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5084 - accuracy: 0.7562 - val_loss: 0.5730 - val_accuracy: 0.7019\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5141 - accuracy: 0.7596 - val_loss: 0.5692 - val_accuracy: 0.7115\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5051 - accuracy: 0.7545 - val_loss: 0.5642 - val_accuracy: 0.7244\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.7523 - val_loss: 0.5657 - val_accuracy: 0.7147\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.7534 - val_loss: 0.5805 - val_accuracy: 0.7147\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5085 - accuracy: 0.7545 - val_loss: 0.5707 - val_accuracy: 0.7147\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7230769230769231\n",
            "Accuracy: 0.7230769230769231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6272 - accuracy: 0.6689 - val_loss: 0.6534 - val_accuracy: 0.6346\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6157 - accuracy: 0.6723 - val_loss: 0.6205 - val_accuracy: 0.6346\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6037 - accuracy: 0.6723 - val_loss: 0.6223 - val_accuracy: 0.6346\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5947 - accuracy: 0.6837 - val_loss: 0.5980 - val_accuracy: 0.6795\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5703 - accuracy: 0.7007 - val_loss: 0.5853 - val_accuracy: 0.7019\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5872 - accuracy: 0.6888 - val_loss: 0.6091 - val_accuracy: 0.6571\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5634 - accuracy: 0.7234 - val_loss: 0.5822 - val_accuracy: 0.6891\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5637 - accuracy: 0.7273 - val_loss: 0.6167 - val_accuracy: 0.6827\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5566 - accuracy: 0.7296 - val_loss: 0.5895 - val_accuracy: 0.6795\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5586 - accuracy: 0.7211 - val_loss: 0.5715 - val_accuracy: 0.7244\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5456 - accuracy: 0.7290 - val_loss: 0.5703 - val_accuracy: 0.7051\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5472 - accuracy: 0.7341 - val_loss: 0.5842 - val_accuracy: 0.7019\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5531 - accuracy: 0.7222 - val_loss: 0.5767 - val_accuracy: 0.7179\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5468 - accuracy: 0.7370 - val_loss: 0.5791 - val_accuracy: 0.7051\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5529 - accuracy: 0.7319 - val_loss: 0.5680 - val_accuracy: 0.7147\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.7460 - val_loss: 0.5767 - val_accuracy: 0.6987\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.7421 - val_loss: 0.5702 - val_accuracy: 0.7051\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5440 - accuracy: 0.7460 - val_loss: 0.5799 - val_accuracy: 0.7115\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5510 - accuracy: 0.7285 - val_loss: 0.5783 - val_accuracy: 0.7051\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.7404 - val_loss: 0.5631 - val_accuracy: 0.7083\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5291 - accuracy: 0.7472 - val_loss: 0.5722 - val_accuracy: 0.7019\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5268 - accuracy: 0.7460 - val_loss: 0.5649 - val_accuracy: 0.7083\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.7460 - val_loss: 0.5641 - val_accuracy: 0.7372\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.7438 - val_loss: 0.5654 - val_accuracy: 0.6923\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.7483 - val_loss: 0.6002 - val_accuracy: 0.6635\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5289 - accuracy: 0.7438 - val_loss: 0.5893 - val_accuracy: 0.6827\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5160 - accuracy: 0.7557 - val_loss: 0.5629 - val_accuracy: 0.7340\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5235 - accuracy: 0.7404 - val_loss: 0.5735 - val_accuracy: 0.6763\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7466 - val_loss: 0.5736 - val_accuracy: 0.6955\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5258 - accuracy: 0.7415 - val_loss: 0.5716 - val_accuracy: 0.7051\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5206 - accuracy: 0.7460 - val_loss: 0.5724 - val_accuracy: 0.7179\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5151 - accuracy: 0.7613 - val_loss: 0.5712 - val_accuracy: 0.7179\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.7477 - val_loss: 0.5725 - val_accuracy: 0.7115\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5263 - accuracy: 0.7387 - val_loss: 0.5678 - val_accuracy: 0.7083\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5275 - accuracy: 0.7460 - val_loss: 0.5800 - val_accuracy: 0.7308\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.7551 - val_loss: 0.5651 - val_accuracy: 0.7212\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5113 - accuracy: 0.7534 - val_loss: 0.5697 - val_accuracy: 0.7147\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5189 - accuracy: 0.7438 - val_loss: 0.5604 - val_accuracy: 0.7404\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5094 - accuracy: 0.7517 - val_loss: 0.5680 - val_accuracy: 0.7019\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5119 - accuracy: 0.7438 - val_loss: 0.5688 - val_accuracy: 0.7147\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5144 - accuracy: 0.7483 - val_loss: 0.5729 - val_accuracy: 0.7115\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5101 - accuracy: 0.7517 - val_loss: 0.5850 - val_accuracy: 0.6987\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5094 - accuracy: 0.7534 - val_loss: 0.5803 - val_accuracy: 0.7179\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.7591 - val_loss: 0.5725 - val_accuracy: 0.6955\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5116 - accuracy: 0.7506 - val_loss: 0.5677 - val_accuracy: 0.7019\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4999 - accuracy: 0.7710 - val_loss: 0.5685 - val_accuracy: 0.7115\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4969 - accuracy: 0.7687 - val_loss: 0.5684 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5063 - accuracy: 0.7551 - val_loss: 0.6044 - val_accuracy: 0.6731\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5018 - accuracy: 0.7562 - val_loss: 0.5706 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5078 - accuracy: 0.7602 - val_loss: 0.5869 - val_accuracy: 0.6827\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7\n",
            "Accuracy: 0.7\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6457 - accuracy: 0.6576 - val_loss: 0.6334 - val_accuracy: 0.6410\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6246 - accuracy: 0.6582 - val_loss: 0.6174 - val_accuracy: 0.6410\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6102 - accuracy: 0.6763 - val_loss: 0.6125 - val_accuracy: 0.6603\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5958 - accuracy: 0.6763 - val_loss: 0.5815 - val_accuracy: 0.6827\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5838 - accuracy: 0.7052 - val_loss: 0.6199 - val_accuracy: 0.6571\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5711 - accuracy: 0.7063 - val_loss: 0.5754 - val_accuracy: 0.6987\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5735 - accuracy: 0.7239 - val_loss: 0.5910 - val_accuracy: 0.6827\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5704 - accuracy: 0.7075 - val_loss: 0.5754 - val_accuracy: 0.6859\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5705 - accuracy: 0.7069 - val_loss: 0.6150 - val_accuracy: 0.6474\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5653 - accuracy: 0.7171 - val_loss: 0.5682 - val_accuracy: 0.6987\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5611 - accuracy: 0.7205 - val_loss: 0.5825 - val_accuracy: 0.6987\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5696 - accuracy: 0.7177 - val_loss: 0.5945 - val_accuracy: 0.6795\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5651 - accuracy: 0.7245 - val_loss: 0.5795 - val_accuracy: 0.6795\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5519 - accuracy: 0.7268 - val_loss: 0.5766 - val_accuracy: 0.6923\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5531 - accuracy: 0.7370 - val_loss: 0.5683 - val_accuracy: 0.7051\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5474 - accuracy: 0.7285 - val_loss: 0.5658 - val_accuracy: 0.6891\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5458 - accuracy: 0.7251 - val_loss: 0.5864 - val_accuracy: 0.7115\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5550 - accuracy: 0.7370 - val_loss: 0.5753 - val_accuracy: 0.6955\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.7353 - val_loss: 0.5729 - val_accuracy: 0.7019\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5418 - accuracy: 0.7387 - val_loss: 0.6021 - val_accuracy: 0.6571\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5513 - accuracy: 0.7160 - val_loss: 0.5687 - val_accuracy: 0.6859\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5404 - accuracy: 0.7364 - val_loss: 0.5723 - val_accuracy: 0.6955\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5341 - accuracy: 0.7375 - val_loss: 0.5743 - val_accuracy: 0.7244\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.7455 - val_loss: 0.5755 - val_accuracy: 0.7115\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5518 - accuracy: 0.7273 - val_loss: 0.5676 - val_accuracy: 0.7051\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5340 - accuracy: 0.7381 - val_loss: 0.5721 - val_accuracy: 0.7019\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5385 - accuracy: 0.7392 - val_loss: 0.5825 - val_accuracy: 0.7083\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5336 - accuracy: 0.7415 - val_loss: 0.5892 - val_accuracy: 0.6827\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7432 - val_loss: 0.5785 - val_accuracy: 0.7019\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5401 - accuracy: 0.7409 - val_loss: 0.5672 - val_accuracy: 0.7244\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5362 - accuracy: 0.7347 - val_loss: 0.5965 - val_accuracy: 0.6859\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7432 - val_loss: 0.5820 - val_accuracy: 0.6859\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5343 - accuracy: 0.7477 - val_loss: 0.5811 - val_accuracy: 0.6987\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.7392 - val_loss: 0.6073 - val_accuracy: 0.6667\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.7489 - val_loss: 0.6070 - val_accuracy: 0.6603\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5270 - accuracy: 0.7528 - val_loss: 0.5885 - val_accuracy: 0.6955\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5260 - accuracy: 0.7540 - val_loss: 0.5887 - val_accuracy: 0.6859\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.7585 - val_loss: 0.5950 - val_accuracy: 0.6891\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5296 - accuracy: 0.7438 - val_loss: 0.5897 - val_accuracy: 0.7115\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5187 - accuracy: 0.7517 - val_loss: 0.5949 - val_accuracy: 0.6987\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5210 - accuracy: 0.7409 - val_loss: 0.6204 - val_accuracy: 0.6763\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.7500 - val_loss: 0.5797 - val_accuracy: 0.6891\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5171 - accuracy: 0.7534 - val_loss: 0.6071 - val_accuracy: 0.6795\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.7489 - val_loss: 0.5894 - val_accuracy: 0.7179\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5081 - accuracy: 0.7574 - val_loss: 0.5984 - val_accuracy: 0.7019\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5167 - accuracy: 0.7511 - val_loss: 0.5850 - val_accuracy: 0.7019\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5091 - accuracy: 0.7506 - val_loss: 0.6134 - val_accuracy: 0.6955\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5068 - accuracy: 0.7681 - val_loss: 0.6192 - val_accuracy: 0.6955\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5125 - accuracy: 0.7591 - val_loss: 0.6154 - val_accuracy: 0.6891\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5209 - accuracy: 0.7477 - val_loss: 0.5942 - val_accuracy: 0.6955\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7192307692307692\n",
            "Accuracy: 0.7192307692307692\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6396 - accuracy: 0.6616 - val_loss: 0.6229 - val_accuracy: 0.6538\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6228 - accuracy: 0.6627 - val_loss: 0.6133 - val_accuracy: 0.6538\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6140 - accuracy: 0.6667 - val_loss: 0.6125 - val_accuracy: 0.6538\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6059 - accuracy: 0.6712 - val_loss: 0.5852 - val_accuracy: 0.7115\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5912 - accuracy: 0.6990 - val_loss: 0.6001 - val_accuracy: 0.7051\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5743 - accuracy: 0.7046 - val_loss: 0.5488 - val_accuracy: 0.7244\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5793 - accuracy: 0.6950 - val_loss: 0.5459 - val_accuracy: 0.7147\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5746 - accuracy: 0.7018 - val_loss: 0.5497 - val_accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5630 - accuracy: 0.7029 - val_loss: 0.5304 - val_accuracy: 0.7436\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5692 - accuracy: 0.7137 - val_loss: 0.5608 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.7092 - val_loss: 0.5380 - val_accuracy: 0.7179\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5585 - accuracy: 0.7268 - val_loss: 0.5746 - val_accuracy: 0.7051\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7222 - val_loss: 0.5809 - val_accuracy: 0.6955\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5596 - accuracy: 0.7319 - val_loss: 0.5510 - val_accuracy: 0.7115\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5523 - accuracy: 0.7239 - val_loss: 0.5430 - val_accuracy: 0.7628\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7330 - val_loss: 0.5541 - val_accuracy: 0.7468\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5569 - accuracy: 0.7166 - val_loss: 0.5818 - val_accuracy: 0.6795\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.7285 - val_loss: 0.5415 - val_accuracy: 0.7372\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.7239 - val_loss: 0.5484 - val_accuracy: 0.7340\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5477 - accuracy: 0.7285 - val_loss: 0.5327 - val_accuracy: 0.7468\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5484 - accuracy: 0.7307 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5454 - accuracy: 0.7319 - val_loss: 0.5283 - val_accuracy: 0.7596\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5381 - accuracy: 0.7358 - val_loss: 0.5534 - val_accuracy: 0.7340\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5450 - accuracy: 0.7347 - val_loss: 0.5490 - val_accuracy: 0.7308\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5327 - accuracy: 0.7353 - val_loss: 0.6148 - val_accuracy: 0.6827\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5472 - accuracy: 0.7307 - val_loss: 0.5586 - val_accuracy: 0.7147\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5356 - accuracy: 0.7302 - val_loss: 0.5512 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5353 - accuracy: 0.7460 - val_loss: 0.5393 - val_accuracy: 0.7372\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5361 - accuracy: 0.7358 - val_loss: 0.5487 - val_accuracy: 0.7404\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5340 - accuracy: 0.7483 - val_loss: 0.5379 - val_accuracy: 0.7372\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5394 - accuracy: 0.7307 - val_loss: 0.5345 - val_accuracy: 0.7404\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5363 - accuracy: 0.7449 - val_loss: 0.5446 - val_accuracy: 0.7276\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5282 - accuracy: 0.7466 - val_loss: 0.5526 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.7319 - val_loss: 0.5432 - val_accuracy: 0.7404\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7477 - val_loss: 0.5719 - val_accuracy: 0.7147\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5250 - accuracy: 0.7443 - val_loss: 0.5375 - val_accuracy: 0.7500\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.7421 - val_loss: 0.5506 - val_accuracy: 0.7340\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7438 - val_loss: 0.5641 - val_accuracy: 0.7468\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5226 - accuracy: 0.7443 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5263 - accuracy: 0.7455 - val_loss: 0.5529 - val_accuracy: 0.7372\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.7273 - val_loss: 0.5512 - val_accuracy: 0.7468\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.7449 - val_loss: 0.5553 - val_accuracy: 0.7340\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5176 - accuracy: 0.7534 - val_loss: 0.5540 - val_accuracy: 0.7115\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.7200 - val_loss: 0.5455 - val_accuracy: 0.7564\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5229 - accuracy: 0.7426 - val_loss: 0.5690 - val_accuracy: 0.7083\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7466 - val_loss: 0.5442 - val_accuracy: 0.7372\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5185 - accuracy: 0.7443 - val_loss: 0.5452 - val_accuracy: 0.7276\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5230 - accuracy: 0.7426 - val_loss: 0.5454 - val_accuracy: 0.7340\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5201 - accuracy: 0.7426 - val_loss: 0.5556 - val_accuracy: 0.7660\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5127 - accuracy: 0.7574 - val_loss: 0.5725 - val_accuracy: 0.7436\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7288461538461538\n",
            "Accuracy: 0.7288461538461538\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 10ms/step - loss: 0.6362 - accuracy: 0.6638 - val_loss: 0.6338 - val_accuracy: 0.6346\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6091 - accuracy: 0.6695 - val_loss: 0.6198 - val_accuracy: 0.6378\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5956 - accuracy: 0.6888 - val_loss: 0.5861 - val_accuracy: 0.7083\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5928 - accuracy: 0.6910 - val_loss: 0.5779 - val_accuracy: 0.7115\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5867 - accuracy: 0.7018 - val_loss: 0.5736 - val_accuracy: 0.7276\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5652 - accuracy: 0.7268 - val_loss: 0.5599 - val_accuracy: 0.7244\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.7092 - val_loss: 0.5881 - val_accuracy: 0.6859\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5650 - accuracy: 0.7188 - val_loss: 0.5624 - val_accuracy: 0.7051\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5571 - accuracy: 0.7211 - val_loss: 0.5848 - val_accuracy: 0.7115\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7296 - val_loss: 0.5921 - val_accuracy: 0.6859\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5579 - accuracy: 0.7222 - val_loss: 0.5751 - val_accuracy: 0.7083\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5488 - accuracy: 0.7222 - val_loss: 0.5611 - val_accuracy: 0.7115\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5405 - accuracy: 0.7415 - val_loss: 0.5651 - val_accuracy: 0.7083\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5354 - accuracy: 0.7489 - val_loss: 0.5644 - val_accuracy: 0.7179\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5440 - accuracy: 0.7268 - val_loss: 0.5848 - val_accuracy: 0.6923\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.7545 - val_loss: 0.5751 - val_accuracy: 0.6891\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5421 - accuracy: 0.7415 - val_loss: 0.5851 - val_accuracy: 0.6891\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.7472 - val_loss: 0.5818 - val_accuracy: 0.6955\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5317 - accuracy: 0.7307 - val_loss: 0.5736 - val_accuracy: 0.7019\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5367 - accuracy: 0.7364 - val_loss: 0.5686 - val_accuracy: 0.6923\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5275 - accuracy: 0.7494 - val_loss: 0.5802 - val_accuracy: 0.6955\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5368 - accuracy: 0.7392 - val_loss: 0.5733 - val_accuracy: 0.6987\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5277 - accuracy: 0.7528 - val_loss: 0.5829 - val_accuracy: 0.6827\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5233 - accuracy: 0.7613 - val_loss: 0.5769 - val_accuracy: 0.6859\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5319 - accuracy: 0.7398 - val_loss: 0.5801 - val_accuracy: 0.6859\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5247 - accuracy: 0.7455 - val_loss: 0.5700 - val_accuracy: 0.6955\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5209 - accuracy: 0.7517 - val_loss: 0.6171 - val_accuracy: 0.6699\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7506 - val_loss: 0.5735 - val_accuracy: 0.6891\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5123 - accuracy: 0.7534 - val_loss: 0.5691 - val_accuracy: 0.6891\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5209 - accuracy: 0.7568 - val_loss: 0.6211 - val_accuracy: 0.6795\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5115 - accuracy: 0.7574 - val_loss: 0.5860 - val_accuracy: 0.7083\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.7579 - val_loss: 0.5712 - val_accuracy: 0.7083\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5158 - accuracy: 0.7602 - val_loss: 0.5896 - val_accuracy: 0.6923\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5073 - accuracy: 0.7613 - val_loss: 0.5814 - val_accuracy: 0.7051\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.7540 - val_loss: 0.5887 - val_accuracy: 0.6635\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.7460 - val_loss: 0.5740 - val_accuracy: 0.6891\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5241 - accuracy: 0.7483 - val_loss: 0.5746 - val_accuracy: 0.6923\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.7613 - val_loss: 0.5972 - val_accuracy: 0.6795\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5099 - accuracy: 0.7528 - val_loss: 0.5756 - val_accuracy: 0.7019\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5097 - accuracy: 0.7625 - val_loss: 0.6095 - val_accuracy: 0.6795\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5170 - accuracy: 0.7608 - val_loss: 0.5996 - val_accuracy: 0.6859\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7625 - val_loss: 0.5937 - val_accuracy: 0.6731\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5141 - accuracy: 0.7523 - val_loss: 0.5891 - val_accuracy: 0.6827\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5029 - accuracy: 0.7562 - val_loss: 0.6473 - val_accuracy: 0.6571\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5105 - accuracy: 0.7619 - val_loss: 0.5850 - val_accuracy: 0.6603\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5043 - accuracy: 0.7693 - val_loss: 0.5788 - val_accuracy: 0.6699\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5110 - accuracy: 0.7574 - val_loss: 0.5839 - val_accuracy: 0.6603\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.4992 - accuracy: 0.7693 - val_loss: 0.5911 - val_accuracy: 0.6891\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5029 - accuracy: 0.7647 - val_loss: 0.5837 - val_accuracy: 0.6699\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4953 - accuracy: 0.7749 - val_loss: 0.6127 - val_accuracy: 0.6923\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6807692307692308\n",
            "Accuracy: 0.6807692307692308\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 9ms/step - loss: 0.6400 - accuracy: 0.6604 - val_loss: 0.5943 - val_accuracy: 0.6955\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6224 - accuracy: 0.6650 - val_loss: 0.5877 - val_accuracy: 0.6955\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6175 - accuracy: 0.6706 - val_loss: 0.5990 - val_accuracy: 0.7244\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6068 - accuracy: 0.6973 - val_loss: 0.5642 - val_accuracy: 0.6987\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5944 - accuracy: 0.6944 - val_loss: 0.5534 - val_accuracy: 0.7468\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5835 - accuracy: 0.7109 - val_loss: 0.5123 - val_accuracy: 0.7692\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5878 - accuracy: 0.7075 - val_loss: 0.5345 - val_accuracy: 0.7756\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5819 - accuracy: 0.7098 - val_loss: 0.5282 - val_accuracy: 0.7821\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5777 - accuracy: 0.7080 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5832 - accuracy: 0.7098 - val_loss: 0.5479 - val_accuracy: 0.7179\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5790 - accuracy: 0.7092 - val_loss: 0.5229 - val_accuracy: 0.7596\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5697 - accuracy: 0.7149 - val_loss: 0.5078 - val_accuracy: 0.7660\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5732 - accuracy: 0.7160 - val_loss: 0.5686 - val_accuracy: 0.7179\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5662 - accuracy: 0.7222 - val_loss: 0.5314 - val_accuracy: 0.7532\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5580 - accuracy: 0.7251 - val_loss: 0.5227 - val_accuracy: 0.7532\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5640 - accuracy: 0.7188 - val_loss: 0.5606 - val_accuracy: 0.7917\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5587 - accuracy: 0.7307 - val_loss: 0.4915 - val_accuracy: 0.7724\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5494 - accuracy: 0.7296 - val_loss: 0.5017 - val_accuracy: 0.7628\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5671 - accuracy: 0.7211 - val_loss: 0.5030 - val_accuracy: 0.7692\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5580 - accuracy: 0.7239 - val_loss: 0.5172 - val_accuracy: 0.7564\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5584 - accuracy: 0.7205 - val_loss: 0.5143 - val_accuracy: 0.7436\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5556 - accuracy: 0.7358 - val_loss: 0.5035 - val_accuracy: 0.7821\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5506 - accuracy: 0.7302 - val_loss: 0.5121 - val_accuracy: 0.7532\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5532 - accuracy: 0.7256 - val_loss: 0.5410 - val_accuracy: 0.7756\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7392 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5434 - accuracy: 0.7398 - val_loss: 0.5026 - val_accuracy: 0.7660\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5505 - accuracy: 0.7307 - val_loss: 0.5135 - val_accuracy: 0.7756\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5400 - accuracy: 0.7347 - val_loss: 0.4954 - val_accuracy: 0.7724\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5475 - accuracy: 0.7256 - val_loss: 0.5111 - val_accuracy: 0.7436\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5469 - accuracy: 0.7347 - val_loss: 0.5196 - val_accuracy: 0.7532\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5474 - accuracy: 0.7313 - val_loss: 0.5070 - val_accuracy: 0.7660\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5373 - accuracy: 0.7398 - val_loss: 0.4950 - val_accuracy: 0.7660\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5431 - accuracy: 0.7392 - val_loss: 0.5032 - val_accuracy: 0.7692\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7449 - val_loss: 0.5418 - val_accuracy: 0.7308\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7324 - val_loss: 0.5171 - val_accuracy: 0.7628\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5409 - accuracy: 0.7404 - val_loss: 0.5423 - val_accuracy: 0.7564\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5323 - accuracy: 0.7432 - val_loss: 0.5158 - val_accuracy: 0.7628\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5381 - accuracy: 0.7426 - val_loss: 0.5044 - val_accuracy: 0.7756\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5420 - accuracy: 0.7455 - val_loss: 0.5136 - val_accuracy: 0.7564\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.7398 - val_loss: 0.4933 - val_accuracy: 0.7853\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5268 - accuracy: 0.7466 - val_loss: 0.5357 - val_accuracy: 0.7660\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5358 - accuracy: 0.7387 - val_loss: 0.5171 - val_accuracy: 0.7724\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5299 - accuracy: 0.7392 - val_loss: 0.5257 - val_accuracy: 0.7468\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5263 - accuracy: 0.7472 - val_loss: 0.4966 - val_accuracy: 0.7692\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5287 - accuracy: 0.7477 - val_loss: 0.5189 - val_accuracy: 0.7468\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5333 - accuracy: 0.7455 - val_loss: 0.5074 - val_accuracy: 0.7660\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5290 - accuracy: 0.7449 - val_loss: 0.5101 - val_accuracy: 0.7564\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5297 - accuracy: 0.7494 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5353 - accuracy: 0.7466 - val_loss: 0.5209 - val_accuracy: 0.7660\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7494 - val_loss: 0.5171 - val_accuracy: 0.7660\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7173076923076923\n",
            "Accuracy: 0.7173076923076923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6340 - accuracy: 0.6689 - val_loss: 0.5829 - val_accuracy: 0.7083\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6178 - accuracy: 0.6712 - val_loss: 0.5722 - val_accuracy: 0.7083\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6100 - accuracy: 0.6650 - val_loss: 0.5925 - val_accuracy: 0.7051\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5895 - accuracy: 0.6905 - val_loss: 0.5713 - val_accuracy: 0.6603\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5894 - accuracy: 0.6939 - val_loss: 0.5884 - val_accuracy: 0.6795\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5694 - accuracy: 0.7092 - val_loss: 0.5739 - val_accuracy: 0.6538\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5776 - accuracy: 0.7143 - val_loss: 0.5472 - val_accuracy: 0.7468\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5707 - accuracy: 0.7205 - val_loss: 0.5476 - val_accuracy: 0.7372\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5718 - accuracy: 0.7092 - val_loss: 0.5578 - val_accuracy: 0.7404\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5580 - accuracy: 0.7273 - val_loss: 0.5552 - val_accuracy: 0.7276\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5630 - accuracy: 0.7177 - val_loss: 0.5752 - val_accuracy: 0.6923\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.7370 - val_loss: 0.5379 - val_accuracy: 0.7596\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5419 - accuracy: 0.7421 - val_loss: 0.5837 - val_accuracy: 0.6731\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5572 - accuracy: 0.7234 - val_loss: 0.5521 - val_accuracy: 0.7564\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5485 - accuracy: 0.7211 - val_loss: 0.5477 - val_accuracy: 0.7468\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5437 - accuracy: 0.7273 - val_loss: 0.5557 - val_accuracy: 0.7276\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7290 - val_loss: 0.5405 - val_accuracy: 0.7532\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.7245 - val_loss: 0.5480 - val_accuracy: 0.7532\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5377 - accuracy: 0.7364 - val_loss: 0.5682 - val_accuracy: 0.6699\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5388 - accuracy: 0.7375 - val_loss: 0.5468 - val_accuracy: 0.7468\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7387 - val_loss: 0.5447 - val_accuracy: 0.7404\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7324 - val_loss: 0.5784 - val_accuracy: 0.6506\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.7285 - val_loss: 0.5553 - val_accuracy: 0.7468\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.7483 - val_loss: 0.5543 - val_accuracy: 0.7372\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5321 - accuracy: 0.7432 - val_loss: 0.5593 - val_accuracy: 0.7436\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5299 - accuracy: 0.7455 - val_loss: 0.5680 - val_accuracy: 0.7404\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7409 - val_loss: 0.5990 - val_accuracy: 0.6763\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.7534 - val_loss: 0.5769 - val_accuracy: 0.6859\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5226 - accuracy: 0.7511 - val_loss: 0.5394 - val_accuracy: 0.7436\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.7574 - val_loss: 0.5467 - val_accuracy: 0.7372\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5239 - accuracy: 0.7494 - val_loss: 0.5405 - val_accuracy: 0.7468\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5221 - accuracy: 0.7523 - val_loss: 0.5633 - val_accuracy: 0.7212\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5201 - accuracy: 0.7494 - val_loss: 0.5699 - val_accuracy: 0.7276\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5264 - accuracy: 0.7489 - val_loss: 0.5584 - val_accuracy: 0.7372\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5075 - accuracy: 0.7534 - val_loss: 0.5450 - val_accuracy: 0.7340\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5075 - accuracy: 0.7579 - val_loss: 0.5693 - val_accuracy: 0.7115\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5268 - accuracy: 0.7392 - val_loss: 0.5455 - val_accuracy: 0.7179\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5148 - accuracy: 0.7517 - val_loss: 0.5395 - val_accuracy: 0.7340\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5116 - accuracy: 0.7557 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5144 - accuracy: 0.7636 - val_loss: 0.5421 - val_accuracy: 0.7564\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5117 - accuracy: 0.7551 - val_loss: 0.5626 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5137 - accuracy: 0.7568 - val_loss: 0.5369 - val_accuracy: 0.7244\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5027 - accuracy: 0.7506 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.7415 - val_loss: 0.5684 - val_accuracy: 0.7436\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5086 - accuracy: 0.7557 - val_loss: 0.5651 - val_accuracy: 0.7340\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5149 - accuracy: 0.7517 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5110 - accuracy: 0.7523 - val_loss: 0.5678 - val_accuracy: 0.7372\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5031 - accuracy: 0.7670 - val_loss: 0.5611 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5175 - accuracy: 0.7483 - val_loss: 0.5625 - val_accuracy: 0.7212\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4997 - accuracy: 0.7608 - val_loss: 0.5786 - val_accuracy: 0.7019\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6961538461538461\n",
            "Accuracy: 0.6961538461538461\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6393 - accuracy: 0.6576 - val_loss: 0.6271 - val_accuracy: 0.6635\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6125 - accuracy: 0.6638 - val_loss: 0.5885 - val_accuracy: 0.6667\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5980 - accuracy: 0.6899 - val_loss: 0.5818 - val_accuracy: 0.6763\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5775 - accuracy: 0.7103 - val_loss: 0.5934 - val_accuracy: 0.7051\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5742 - accuracy: 0.6995 - val_loss: 0.5739 - val_accuracy: 0.7179\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5664 - accuracy: 0.7177 - val_loss: 0.5738 - val_accuracy: 0.6859\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5638 - accuracy: 0.7307 - val_loss: 0.5833 - val_accuracy: 0.6795\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5581 - accuracy: 0.7080 - val_loss: 0.5831 - val_accuracy: 0.6827\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5609 - accuracy: 0.7211 - val_loss: 0.5755 - val_accuracy: 0.7115\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5590 - accuracy: 0.7234 - val_loss: 0.5934 - val_accuracy: 0.7019\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5442 - accuracy: 0.7336 - val_loss: 0.5787 - val_accuracy: 0.7179\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5467 - accuracy: 0.7370 - val_loss: 0.5766 - val_accuracy: 0.7212\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5437 - accuracy: 0.7324 - val_loss: 0.6030 - val_accuracy: 0.6923\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7285 - val_loss: 0.5980 - val_accuracy: 0.7051\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.7364 - val_loss: 0.5914 - val_accuracy: 0.7019\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5439 - accuracy: 0.7296 - val_loss: 0.5823 - val_accuracy: 0.7051\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5470 - accuracy: 0.7273 - val_loss: 0.5766 - val_accuracy: 0.7308\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7375 - val_loss: 0.5770 - val_accuracy: 0.7308\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5303 - accuracy: 0.7426 - val_loss: 0.5698 - val_accuracy: 0.7436\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5439 - accuracy: 0.7228 - val_loss: 0.6181 - val_accuracy: 0.6763\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.7426 - val_loss: 0.5740 - val_accuracy: 0.7340\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7353 - val_loss: 0.5741 - val_accuracy: 0.7340\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.7421 - val_loss: 0.6022 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7404 - val_loss: 0.6049 - val_accuracy: 0.6763\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7432 - val_loss: 0.5725 - val_accuracy: 0.7372\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5140 - accuracy: 0.7500 - val_loss: 0.6042 - val_accuracy: 0.7115\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.7523 - val_loss: 0.5910 - val_accuracy: 0.7372\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7523 - val_loss: 0.5750 - val_accuracy: 0.7147\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5197 - accuracy: 0.7392 - val_loss: 0.5670 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5120 - accuracy: 0.7494 - val_loss: 0.5911 - val_accuracy: 0.7051\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5148 - accuracy: 0.7483 - val_loss: 0.5802 - val_accuracy: 0.7147\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5110 - accuracy: 0.7500 - val_loss: 0.6010 - val_accuracy: 0.7340\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5096 - accuracy: 0.7540 - val_loss: 0.5990 - val_accuracy: 0.7083\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5209 - accuracy: 0.7455 - val_loss: 0.5891 - val_accuracy: 0.7083\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5181 - accuracy: 0.7483 - val_loss: 0.5856 - val_accuracy: 0.7436\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5124 - accuracy: 0.7500 - val_loss: 0.5922 - val_accuracy: 0.6955\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5134 - accuracy: 0.7466 - val_loss: 0.5950 - val_accuracy: 0.7147\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7528 - val_loss: 0.5729 - val_accuracy: 0.7179\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5143 - accuracy: 0.7494 - val_loss: 0.5767 - val_accuracy: 0.7276\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5149 - accuracy: 0.7460 - val_loss: 0.5763 - val_accuracy: 0.7212\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.7528 - val_loss: 0.5994 - val_accuracy: 0.7083\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4915 - accuracy: 0.7670 - val_loss: 0.5971 - val_accuracy: 0.7147\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5005 - accuracy: 0.7557 - val_loss: 0.6778 - val_accuracy: 0.6891\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5135 - accuracy: 0.7579 - val_loss: 0.5822 - val_accuracy: 0.7179\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5001 - accuracy: 0.7642 - val_loss: 0.5963 - val_accuracy: 0.7147\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5020 - accuracy: 0.7562 - val_loss: 0.5979 - val_accuracy: 0.7179\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4975 - accuracy: 0.7710 - val_loss: 0.5858 - val_accuracy: 0.7147\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5052 - accuracy: 0.7472 - val_loss: 0.5840 - val_accuracy: 0.7244\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.7494 - val_loss: 0.6074 - val_accuracy: 0.7051\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4989 - accuracy: 0.7568 - val_loss: 0.6147 - val_accuracy: 0.6987\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.6961538461538461\n",
            "Accuracy: 0.6961538461538461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 10ms/step - loss: 0.6309 - accuracy: 0.6701 - val_loss: 0.6067 - val_accuracy: 0.6827\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.6718 - val_loss: 0.6039 - val_accuracy: 0.6827\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6019 - accuracy: 0.6808 - val_loss: 0.6346 - val_accuracy: 0.6506\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5992 - accuracy: 0.6774 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5892 - accuracy: 0.6780 - val_loss: 0.6056 - val_accuracy: 0.7019\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5764 - accuracy: 0.7046 - val_loss: 0.5799 - val_accuracy: 0.6827\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5865 - accuracy: 0.7171 - val_loss: 0.5589 - val_accuracy: 0.7468\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5754 - accuracy: 0.6973 - val_loss: 0.5605 - val_accuracy: 0.7596\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5762 - accuracy: 0.7143 - val_loss: 0.5794 - val_accuracy: 0.6923\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5676 - accuracy: 0.7183 - val_loss: 0.5608 - val_accuracy: 0.7115\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5650 - accuracy: 0.7126 - val_loss: 0.5571 - val_accuracy: 0.7244\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5512 - accuracy: 0.7171 - val_loss: 0.5742 - val_accuracy: 0.7147\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5563 - accuracy: 0.7171 - val_loss: 0.5654 - val_accuracy: 0.7179\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7177 - val_loss: 0.5606 - val_accuracy: 0.7115\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5585 - accuracy: 0.7126 - val_loss: 0.5696 - val_accuracy: 0.7083\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5516 - accuracy: 0.7205 - val_loss: 0.5588 - val_accuracy: 0.7212\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5526 - accuracy: 0.7341 - val_loss: 0.5705 - val_accuracy: 0.6795\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7273 - val_loss: 0.5526 - val_accuracy: 0.7083\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5463 - accuracy: 0.7387 - val_loss: 0.5498 - val_accuracy: 0.7340\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5390 - accuracy: 0.7415 - val_loss: 0.5479 - val_accuracy: 0.7532\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5482 - accuracy: 0.7307 - val_loss: 0.5509 - val_accuracy: 0.7179\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5465 - accuracy: 0.7313 - val_loss: 0.5473 - val_accuracy: 0.7083\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7353 - val_loss: 0.5456 - val_accuracy: 0.7372\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5429 - accuracy: 0.7251 - val_loss: 0.5600 - val_accuracy: 0.6923\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5419 - accuracy: 0.7330 - val_loss: 0.5561 - val_accuracy: 0.7051\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5450 - accuracy: 0.7279 - val_loss: 0.5489 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5393 - accuracy: 0.7307 - val_loss: 0.5483 - val_accuracy: 0.7340\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5398 - accuracy: 0.7353 - val_loss: 0.5434 - val_accuracy: 0.7404\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5352 - accuracy: 0.7353 - val_loss: 0.5420 - val_accuracy: 0.7244\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5313 - accuracy: 0.7336 - val_loss: 0.5432 - val_accuracy: 0.7179\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5360 - accuracy: 0.7409 - val_loss: 0.5417 - val_accuracy: 0.7340\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.7307 - val_loss: 0.5394 - val_accuracy: 0.7660\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7483 - val_loss: 0.5531 - val_accuracy: 0.7340\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5305 - accuracy: 0.7489 - val_loss: 0.5411 - val_accuracy: 0.7276\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.7387 - val_loss: 0.5434 - val_accuracy: 0.7404\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5297 - accuracy: 0.7415 - val_loss: 0.5380 - val_accuracy: 0.7596\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7426 - val_loss: 0.5504 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5321 - accuracy: 0.7336 - val_loss: 0.5564 - val_accuracy: 0.7083\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.7432 - val_loss: 0.5471 - val_accuracy: 0.7340\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7353 - val_loss: 0.5360 - val_accuracy: 0.7276\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5192 - accuracy: 0.7494 - val_loss: 0.6165 - val_accuracy: 0.7212\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5285 - accuracy: 0.7421 - val_loss: 0.5573 - val_accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5231 - accuracy: 0.7421 - val_loss: 0.5445 - val_accuracy: 0.7179\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5191 - accuracy: 0.7511 - val_loss: 0.5500 - val_accuracy: 0.6955\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5264 - accuracy: 0.7330 - val_loss: 0.5378 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7347 - val_loss: 0.5486 - val_accuracy: 0.7340\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5165 - accuracy: 0.7534 - val_loss: 0.5437 - val_accuracy: 0.7244\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.7421 - val_loss: 0.5587 - val_accuracy: 0.7147\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.7375 - val_loss: 0.5418 - val_accuracy: 0.7179\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.7404 - val_loss: 0.5454 - val_accuracy: 0.7436\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7153846153846154\n",
            "Accuracy: 0.7153846153846154\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 7ms/step - loss: 0.6367 - accuracy: 0.6701 - val_loss: 0.6444 - val_accuracy: 0.6346\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6258 - accuracy: 0.6701 - val_loss: 0.6384 - val_accuracy: 0.6346\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6268 - accuracy: 0.6695 - val_loss: 0.6257 - val_accuracy: 0.6346\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6019 - accuracy: 0.6689 - val_loss: 0.5987 - val_accuracy: 0.6410\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5937 - accuracy: 0.6820 - val_loss: 0.5855 - val_accuracy: 0.7019\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5904 - accuracy: 0.6995 - val_loss: 0.5819 - val_accuracy: 0.7083\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5747 - accuracy: 0.7166 - val_loss: 0.6276 - val_accuracy: 0.7019\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5671 - accuracy: 0.7234 - val_loss: 0.5797 - val_accuracy: 0.7115\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5824 - accuracy: 0.7103 - val_loss: 0.5852 - val_accuracy: 0.7083\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5691 - accuracy: 0.7029 - val_loss: 0.5933 - val_accuracy: 0.6731\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5667 - accuracy: 0.7086 - val_loss: 0.5661 - val_accuracy: 0.7212\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5628 - accuracy: 0.7143 - val_loss: 0.5805 - val_accuracy: 0.6955\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5574 - accuracy: 0.7222 - val_loss: 0.5624 - val_accuracy: 0.7212\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5590 - accuracy: 0.7120 - val_loss: 0.5854 - val_accuracy: 0.6891\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5575 - accuracy: 0.7239 - val_loss: 0.5887 - val_accuracy: 0.6667\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5635 - accuracy: 0.7103 - val_loss: 0.5712 - val_accuracy: 0.7147\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5597 - accuracy: 0.7256 - val_loss: 0.5980 - val_accuracy: 0.6731\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.7279 - val_loss: 0.5700 - val_accuracy: 0.7115\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5551 - accuracy: 0.7319 - val_loss: 0.6002 - val_accuracy: 0.6891\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5576 - accuracy: 0.7307 - val_loss: 0.5706 - val_accuracy: 0.7115\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5547 - accuracy: 0.7234 - val_loss: 0.5762 - val_accuracy: 0.6955\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5454 - accuracy: 0.7279 - val_loss: 0.5644 - val_accuracy: 0.7115\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5422 - accuracy: 0.7404 - val_loss: 0.5703 - val_accuracy: 0.7083\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5525 - accuracy: 0.7279 - val_loss: 0.5815 - val_accuracy: 0.6763\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5396 - accuracy: 0.7358 - val_loss: 0.5759 - val_accuracy: 0.6955\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5475 - accuracy: 0.7370 - val_loss: 0.5658 - val_accuracy: 0.7083\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7341 - val_loss: 0.5702 - val_accuracy: 0.7212\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5351 - accuracy: 0.7426 - val_loss: 0.5703 - val_accuracy: 0.7179\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7347 - val_loss: 0.5750 - val_accuracy: 0.7019\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.7443 - val_loss: 0.5658 - val_accuracy: 0.7051\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7455 - val_loss: 0.5749 - val_accuracy: 0.7019\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5375 - accuracy: 0.7500 - val_loss: 0.5734 - val_accuracy: 0.6859\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5282 - accuracy: 0.7421 - val_loss: 0.5701 - val_accuracy: 0.6827\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5344 - accuracy: 0.7387 - val_loss: 0.5745 - val_accuracy: 0.7051\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5224 - accuracy: 0.7545 - val_loss: 0.5642 - val_accuracy: 0.6987\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.7426 - val_loss: 0.5787 - val_accuracy: 0.6955\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.7370 - val_loss: 0.5667 - val_accuracy: 0.7083\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5158 - accuracy: 0.7596 - val_loss: 0.5666 - val_accuracy: 0.7115\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5269 - accuracy: 0.7545 - val_loss: 0.5615 - val_accuracy: 0.7051\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5209 - accuracy: 0.7506 - val_loss: 0.5662 - val_accuracy: 0.7212\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.7528 - val_loss: 0.5696 - val_accuracy: 0.7244\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.7523 - val_loss: 0.5688 - val_accuracy: 0.7083\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5156 - accuracy: 0.7409 - val_loss: 0.5668 - val_accuracy: 0.7244\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5195 - accuracy: 0.7449 - val_loss: 0.5624 - val_accuracy: 0.7179\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5156 - accuracy: 0.7574 - val_loss: 0.5867 - val_accuracy: 0.6827\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.7438 - val_loss: 0.5676 - val_accuracy: 0.7179\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.7579 - val_loss: 0.5530 - val_accuracy: 0.7147\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5165 - accuracy: 0.7528 - val_loss: 0.5622 - val_accuracy: 0.7404\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.7528 - val_loss: 0.5713 - val_accuracy: 0.7083\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5100 - accuracy: 0.7528 - val_loss: 0.5670 - val_accuracy: 0.7147\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7038461538461539\n",
            "Accuracy: 0.7038461538461539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6387 - accuracy: 0.6570 - val_loss: 0.6556 - val_accuracy: 0.6538\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.6576 - val_loss: 0.6126 - val_accuracy: 0.6538\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6081 - accuracy: 0.6604 - val_loss: 0.5974 - val_accuracy: 0.6538\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6016 - accuracy: 0.6763 - val_loss: 0.5949 - val_accuracy: 0.6667\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5951 - accuracy: 0.7007 - val_loss: 0.5897 - val_accuracy: 0.6987\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5804 - accuracy: 0.7245 - val_loss: 0.5740 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5682 - accuracy: 0.7166 - val_loss: 0.5786 - val_accuracy: 0.7179\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5596 - accuracy: 0.7228 - val_loss: 0.5643 - val_accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5833 - accuracy: 0.7103 - val_loss: 0.5627 - val_accuracy: 0.7147\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5669 - accuracy: 0.7228 - val_loss: 0.5783 - val_accuracy: 0.7244\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5574 - accuracy: 0.7324 - val_loss: 0.5605 - val_accuracy: 0.7147\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5561 - accuracy: 0.7160 - val_loss: 0.5729 - val_accuracy: 0.7083\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7262 - val_loss: 0.5643 - val_accuracy: 0.7115\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5524 - accuracy: 0.7336 - val_loss: 0.5649 - val_accuracy: 0.7115\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5573 - accuracy: 0.7251 - val_loss: 0.5664 - val_accuracy: 0.7179\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7132 - val_loss: 0.5582 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5507 - accuracy: 0.7347 - val_loss: 0.5630 - val_accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5609 - accuracy: 0.7234 - val_loss: 0.5585 - val_accuracy: 0.7083\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5573 - accuracy: 0.7183 - val_loss: 0.5598 - val_accuracy: 0.7147\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5563 - accuracy: 0.7290 - val_loss: 0.5667 - val_accuracy: 0.7051\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5507 - accuracy: 0.7324 - val_loss: 0.5620 - val_accuracy: 0.7179\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5488 - accuracy: 0.7273 - val_loss: 0.5625 - val_accuracy: 0.6955\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7222 - val_loss: 0.5586 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5380 - accuracy: 0.7426 - val_loss: 0.5870 - val_accuracy: 0.6923\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5454 - accuracy: 0.7336 - val_loss: 0.5599 - val_accuracy: 0.7083\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.7285 - val_loss: 0.5644 - val_accuracy: 0.7115\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5365 - accuracy: 0.7370 - val_loss: 0.5569 - val_accuracy: 0.7083\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5399 - accuracy: 0.7443 - val_loss: 0.5679 - val_accuracy: 0.7147\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5364 - accuracy: 0.7426 - val_loss: 0.5592 - val_accuracy: 0.7051\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5334 - accuracy: 0.7426 - val_loss: 0.5620 - val_accuracy: 0.7147\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5336 - accuracy: 0.7449 - val_loss: 0.5610 - val_accuracy: 0.7147\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5323 - accuracy: 0.7404 - val_loss: 0.5699 - val_accuracy: 0.7083\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5303 - accuracy: 0.7392 - val_loss: 0.5696 - val_accuracy: 0.7019\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5289 - accuracy: 0.7477 - val_loss: 0.5576 - val_accuracy: 0.7179\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5230 - accuracy: 0.7534 - val_loss: 0.5714 - val_accuracy: 0.6923\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5322 - accuracy: 0.7381 - val_loss: 0.5649 - val_accuracy: 0.7051\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5209 - accuracy: 0.7557 - val_loss: 0.5681 - val_accuracy: 0.7051\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5250 - accuracy: 0.7579 - val_loss: 0.5756 - val_accuracy: 0.7083\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5254 - accuracy: 0.7506 - val_loss: 0.5611 - val_accuracy: 0.7147\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5280 - accuracy: 0.7545 - val_loss: 0.5551 - val_accuracy: 0.7212\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5165 - accuracy: 0.7557 - val_loss: 0.5645 - val_accuracy: 0.7019\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5250 - accuracy: 0.7574 - val_loss: 0.5579 - val_accuracy: 0.7179\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5188 - accuracy: 0.7477 - val_loss: 0.5653 - val_accuracy: 0.7083\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5196 - accuracy: 0.7506 - val_loss: 0.6207 - val_accuracy: 0.7115\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5197 - accuracy: 0.7438 - val_loss: 0.5781 - val_accuracy: 0.7083\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5207 - accuracy: 0.7398 - val_loss: 0.5653 - val_accuracy: 0.7083\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5215 - accuracy: 0.7466 - val_loss: 0.5648 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5196 - accuracy: 0.7534 - val_loss: 0.5792 - val_accuracy: 0.7019\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5117 - accuracy: 0.7636 - val_loss: 0.5639 - val_accuracy: 0.7147\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5120 - accuracy: 0.7619 - val_loss: 0.5642 - val_accuracy: 0.7244\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7096153846153846\n",
            "Accuracy: 0.7096153846153846\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6436 - accuracy: 0.6525 - val_loss: 0.6486 - val_accuracy: 0.6955\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6239 - accuracy: 0.6604 - val_loss: 0.6094 - val_accuracy: 0.6955\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6119 - accuracy: 0.6661 - val_loss: 0.5921 - val_accuracy: 0.7019\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5962 - accuracy: 0.6803 - val_loss: 0.5703 - val_accuracy: 0.7147\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5815 - accuracy: 0.6967 - val_loss: 0.6031 - val_accuracy: 0.6314\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5685 - accuracy: 0.7041 - val_loss: 0.5761 - val_accuracy: 0.7019\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.7177 - val_loss: 0.5634 - val_accuracy: 0.7179\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5484 - accuracy: 0.7307 - val_loss: 0.6473 - val_accuracy: 0.6122\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5587 - accuracy: 0.7222 - val_loss: 0.6336 - val_accuracy: 0.6410\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5659 - accuracy: 0.7137 - val_loss: 0.6150 - val_accuracy: 0.6346\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5451 - accuracy: 0.7398 - val_loss: 0.5709 - val_accuracy: 0.7019\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7398 - val_loss: 0.5878 - val_accuracy: 0.7115\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7387 - val_loss: 0.5655 - val_accuracy: 0.7019\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5441 - accuracy: 0.7392 - val_loss: 0.5969 - val_accuracy: 0.6795\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.7353 - val_loss: 0.5985 - val_accuracy: 0.6506\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5291 - accuracy: 0.7443 - val_loss: 0.5858 - val_accuracy: 0.7115\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5328 - accuracy: 0.7392 - val_loss: 0.5608 - val_accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5313 - accuracy: 0.7460 - val_loss: 0.5984 - val_accuracy: 0.6763\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5329 - accuracy: 0.7443 - val_loss: 0.5618 - val_accuracy: 0.7179\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.7381 - val_loss: 0.5827 - val_accuracy: 0.6506\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5301 - accuracy: 0.7409 - val_loss: 0.5823 - val_accuracy: 0.7115\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5242 - accuracy: 0.7347 - val_loss: 0.5860 - val_accuracy: 0.6603\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5320 - accuracy: 0.7387 - val_loss: 0.5949 - val_accuracy: 0.7115\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5259 - accuracy: 0.7545 - val_loss: 0.5678 - val_accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5276 - accuracy: 0.7489 - val_loss: 0.5725 - val_accuracy: 0.7051\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5242 - accuracy: 0.7483 - val_loss: 0.5716 - val_accuracy: 0.7115\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5166 - accuracy: 0.7500 - val_loss: 0.5785 - val_accuracy: 0.7244\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5194 - accuracy: 0.7557 - val_loss: 0.5614 - val_accuracy: 0.7276\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5084 - accuracy: 0.7574 - val_loss: 0.5629 - val_accuracy: 0.7179\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5194 - accuracy: 0.7494 - val_loss: 0.5805 - val_accuracy: 0.6731\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5132 - accuracy: 0.7562 - val_loss: 0.5629 - val_accuracy: 0.7244\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7466 - val_loss: 0.5752 - val_accuracy: 0.7179\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5113 - accuracy: 0.7460 - val_loss: 0.5703 - val_accuracy: 0.7083\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5154 - accuracy: 0.7494 - val_loss: 0.5828 - val_accuracy: 0.6667\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5065 - accuracy: 0.7574 - val_loss: 0.5749 - val_accuracy: 0.7115\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5090 - accuracy: 0.7517 - val_loss: 0.5604 - val_accuracy: 0.7147\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5048 - accuracy: 0.7534 - val_loss: 0.5722 - val_accuracy: 0.7179\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5121 - accuracy: 0.7562 - val_loss: 0.5591 - val_accuracy: 0.7244\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5101 - accuracy: 0.7636 - val_loss: 0.5715 - val_accuracy: 0.6891\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5007 - accuracy: 0.7534 - val_loss: 0.5901 - val_accuracy: 0.7051\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5053 - accuracy: 0.7596 - val_loss: 0.5642 - val_accuracy: 0.7212\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5052 - accuracy: 0.7630 - val_loss: 0.5808 - val_accuracy: 0.7276\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5087 - accuracy: 0.7608 - val_loss: 0.5650 - val_accuracy: 0.7147\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5052 - accuracy: 0.7557 - val_loss: 0.5763 - val_accuracy: 0.7019\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4985 - accuracy: 0.7602 - val_loss: 0.5772 - val_accuracy: 0.6923\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5026 - accuracy: 0.7625 - val_loss: 0.6057 - val_accuracy: 0.6314\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5045 - accuracy: 0.7664 - val_loss: 0.5689 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5088 - accuracy: 0.7659 - val_loss: 0.5652 - val_accuracy: 0.7276\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5041 - accuracy: 0.7749 - val_loss: 0.5664 - val_accuracy: 0.7115\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5002 - accuracy: 0.7727 - val_loss: 0.5647 - val_accuracy: 0.7019\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7096153846153846\n",
            "Accuracy: 0.7096153846153846\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 8ms/step - loss: 0.6332 - accuracy: 0.6644 - val_loss: 0.6463 - val_accuracy: 0.6346\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6255 - accuracy: 0.6650 - val_loss: 0.6208 - val_accuracy: 0.6571\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6023 - accuracy: 0.6825 - val_loss: 0.6260 - val_accuracy: 0.6346\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5953 - accuracy: 0.6842 - val_loss: 0.6129 - val_accuracy: 0.6635\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5880 - accuracy: 0.7058 - val_loss: 0.6116 - val_accuracy: 0.6859\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5713 - accuracy: 0.7194 - val_loss: 0.6024 - val_accuracy: 0.6859\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5744 - accuracy: 0.7029 - val_loss: 0.6093 - val_accuracy: 0.6923\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5675 - accuracy: 0.7251 - val_loss: 0.6127 - val_accuracy: 0.6603\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5558 - accuracy: 0.7251 - val_loss: 0.6108 - val_accuracy: 0.6827\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5619 - accuracy: 0.7149 - val_loss: 0.5960 - val_accuracy: 0.6795\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5534 - accuracy: 0.7279 - val_loss: 0.5981 - val_accuracy: 0.6987\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5602 - accuracy: 0.7251 - val_loss: 0.5985 - val_accuracy: 0.6603\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5504 - accuracy: 0.7228 - val_loss: 0.6018 - val_accuracy: 0.6891\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5498 - accuracy: 0.7392 - val_loss: 0.5953 - val_accuracy: 0.6923\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5395 - accuracy: 0.7341 - val_loss: 0.5928 - val_accuracy: 0.7019\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5405 - accuracy: 0.7307 - val_loss: 0.6146 - val_accuracy: 0.6506\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7392 - val_loss: 0.5877 - val_accuracy: 0.6955\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5450 - accuracy: 0.7313 - val_loss: 0.5874 - val_accuracy: 0.6955\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.7375 - val_loss: 0.5929 - val_accuracy: 0.6859\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5460 - accuracy: 0.7296 - val_loss: 0.6025 - val_accuracy: 0.6859\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7302 - val_loss: 0.5843 - val_accuracy: 0.6827\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5463 - accuracy: 0.7262 - val_loss: 0.6062 - val_accuracy: 0.6859\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5510 - accuracy: 0.7307 - val_loss: 0.5977 - val_accuracy: 0.6795\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5396 - accuracy: 0.7358 - val_loss: 0.5939 - val_accuracy: 0.6731\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5402 - accuracy: 0.7438 - val_loss: 0.5895 - val_accuracy: 0.6955\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5350 - accuracy: 0.7460 - val_loss: 0.5997 - val_accuracy: 0.6891\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5352 - accuracy: 0.7353 - val_loss: 0.5890 - val_accuracy: 0.6827\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5284 - accuracy: 0.7477 - val_loss: 0.5792 - val_accuracy: 0.7019\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.7364 - val_loss: 0.6361 - val_accuracy: 0.6763\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7313 - val_loss: 0.5864 - val_accuracy: 0.6923\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.7392 - val_loss: 0.5947 - val_accuracy: 0.6763\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5328 - accuracy: 0.7455 - val_loss: 0.5950 - val_accuracy: 0.6987\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5261 - accuracy: 0.7421 - val_loss: 0.6151 - val_accuracy: 0.6859\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.7455 - val_loss: 0.5995 - val_accuracy: 0.6827\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.7579 - val_loss: 0.5863 - val_accuracy: 0.6891\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.7421 - val_loss: 0.6012 - val_accuracy: 0.6827\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.7415 - val_loss: 0.5879 - val_accuracy: 0.6859\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5238 - accuracy: 0.7506 - val_loss: 0.6007 - val_accuracy: 0.6859\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.7477 - val_loss: 0.6254 - val_accuracy: 0.6987\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5176 - accuracy: 0.7506 - val_loss: 0.6149 - val_accuracy: 0.6731\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.7472 - val_loss: 0.5974 - val_accuracy: 0.6859\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5208 - accuracy: 0.7472 - val_loss: 0.5949 - val_accuracy: 0.6891\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5135 - accuracy: 0.7528 - val_loss: 0.6040 - val_accuracy: 0.6891\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5173 - accuracy: 0.7534 - val_loss: 0.6107 - val_accuracy: 0.6859\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5141 - accuracy: 0.7591 - val_loss: 0.6127 - val_accuracy: 0.7115\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5116 - accuracy: 0.7596 - val_loss: 0.6138 - val_accuracy: 0.6987\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.7579 - val_loss: 0.6046 - val_accuracy: 0.7051\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5081 - accuracy: 0.7551 - val_loss: 0.7077 - val_accuracy: 0.6795\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5163 - accuracy: 0.7517 - val_loss: 0.6151 - val_accuracy: 0.6667\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5121 - accuracy: 0.7551 - val_loss: 0.6997 - val_accuracy: 0.6827\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7326923076923076\n",
            "Accuracy: 0.7326923076923076\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 9ms/step - loss: 0.6429 - accuracy: 0.6457 - val_loss: 0.6078 - val_accuracy: 0.6795\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6268 - accuracy: 0.6548 - val_loss: 0.6050 - val_accuracy: 0.6859\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6071 - accuracy: 0.6689 - val_loss: 0.5781 - val_accuracy: 0.7019\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5878 - accuracy: 0.7029 - val_loss: 0.5975 - val_accuracy: 0.7051\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5800 - accuracy: 0.7046 - val_loss: 0.5645 - val_accuracy: 0.7083\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5770 - accuracy: 0.7137 - val_loss: 0.6414 - val_accuracy: 0.6090\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5804 - accuracy: 0.7143 - val_loss: 0.5640 - val_accuracy: 0.7179\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5685 - accuracy: 0.7245 - val_loss: 0.5728 - val_accuracy: 0.6955\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5741 - accuracy: 0.7256 - val_loss: 0.5602 - val_accuracy: 0.7212\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5686 - accuracy: 0.7296 - val_loss: 0.5725 - val_accuracy: 0.7179\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5605 - accuracy: 0.7222 - val_loss: 0.6100 - val_accuracy: 0.6474\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5647 - accuracy: 0.7279 - val_loss: 0.5653 - val_accuracy: 0.7179\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5704 - accuracy: 0.7035 - val_loss: 0.5676 - val_accuracy: 0.7179\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5578 - accuracy: 0.7200 - val_loss: 0.5707 - val_accuracy: 0.7147\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5523 - accuracy: 0.7404 - val_loss: 0.5804 - val_accuracy: 0.7083\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5689 - accuracy: 0.7126 - val_loss: 0.5657 - val_accuracy: 0.7147\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5585 - accuracy: 0.7200 - val_loss: 0.5702 - val_accuracy: 0.7115\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5529 - accuracy: 0.7256 - val_loss: 0.5649 - val_accuracy: 0.7179\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5606 - accuracy: 0.7290 - val_loss: 0.5665 - val_accuracy: 0.7051\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5574 - accuracy: 0.7268 - val_loss: 0.5585 - val_accuracy: 0.7179\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.7443 - val_loss: 0.5884 - val_accuracy: 0.6987\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5504 - accuracy: 0.7324 - val_loss: 0.5911 - val_accuracy: 0.6891\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5470 - accuracy: 0.7307 - val_loss: 0.5665 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5499 - accuracy: 0.7205 - val_loss: 0.5723 - val_accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5391 - accuracy: 0.7404 - val_loss: 0.5853 - val_accuracy: 0.7083\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5461 - accuracy: 0.7370 - val_loss: 0.5877 - val_accuracy: 0.7115\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5371 - accuracy: 0.7421 - val_loss: 0.5666 - val_accuracy: 0.7115\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5448 - accuracy: 0.7347 - val_loss: 0.5936 - val_accuracy: 0.6891\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.7432 - val_loss: 0.5670 - val_accuracy: 0.7212\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5430 - accuracy: 0.7375 - val_loss: 0.5682 - val_accuracy: 0.7083\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5453 - accuracy: 0.7290 - val_loss: 0.5615 - val_accuracy: 0.7147\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5375 - accuracy: 0.7432 - val_loss: 0.5631 - val_accuracy: 0.7147\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5328 - accuracy: 0.7432 - val_loss: 0.5799 - val_accuracy: 0.7244\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7438 - val_loss: 0.5712 - val_accuracy: 0.7308\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.7438 - val_loss: 0.5714 - val_accuracy: 0.7179\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.7460 - val_loss: 0.5625 - val_accuracy: 0.7308\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7398 - val_loss: 0.5595 - val_accuracy: 0.7340\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.7659 - val_loss: 0.5877 - val_accuracy: 0.7083\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5356 - accuracy: 0.7528 - val_loss: 0.5583 - val_accuracy: 0.7276\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5249 - accuracy: 0.7528 - val_loss: 0.5694 - val_accuracy: 0.7340\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5327 - accuracy: 0.7438 - val_loss: 0.5587 - val_accuracy: 0.7340\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7489 - val_loss: 0.5960 - val_accuracy: 0.6891\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.7443 - val_loss: 0.5681 - val_accuracy: 0.7276\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5305 - accuracy: 0.7409 - val_loss: 0.5711 - val_accuracy: 0.7340\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5268 - accuracy: 0.7375 - val_loss: 0.5616 - val_accuracy: 0.7308\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5284 - accuracy: 0.7460 - val_loss: 0.5558 - val_accuracy: 0.7308\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5264 - accuracy: 0.7540 - val_loss: 0.5673 - val_accuracy: 0.7372\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5231 - accuracy: 0.7534 - val_loss: 0.5737 - val_accuracy: 0.7308\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5230 - accuracy: 0.7545 - val_loss: 0.5643 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7421 - val_loss: 0.5761 - val_accuracy: 0.7276\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7153846153846154\n",
            "Accuracy: 0.7153846153846154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6410 - accuracy: 0.6616 - val_loss: 0.6322 - val_accuracy: 0.6410\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6236 - accuracy: 0.6667 - val_loss: 0.6136 - val_accuracy: 0.6410\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.6655 - val_loss: 0.6143 - val_accuracy: 0.6410\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6061 - accuracy: 0.6791 - val_loss: 0.6473 - val_accuracy: 0.6122\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.6718 - val_loss: 0.5913 - val_accuracy: 0.6763\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5895 - accuracy: 0.6990 - val_loss: 0.5733 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5827 - accuracy: 0.7103 - val_loss: 0.6106 - val_accuracy: 0.6763\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5769 - accuracy: 0.7126 - val_loss: 0.5940 - val_accuracy: 0.6538\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5741 - accuracy: 0.7177 - val_loss: 0.5954 - val_accuracy: 0.6827\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5712 - accuracy: 0.7052 - val_loss: 0.5861 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5673 - accuracy: 0.7115 - val_loss: 0.5666 - val_accuracy: 0.7051\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5668 - accuracy: 0.7166 - val_loss: 0.5809 - val_accuracy: 0.7212\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5605 - accuracy: 0.7166 - val_loss: 0.5710 - val_accuracy: 0.6955\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5589 - accuracy: 0.7120 - val_loss: 0.6145 - val_accuracy: 0.6635\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5618 - accuracy: 0.7063 - val_loss: 0.5653 - val_accuracy: 0.7147\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5533 - accuracy: 0.7228 - val_loss: 0.5933 - val_accuracy: 0.6763\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5605 - accuracy: 0.7222 - val_loss: 0.5681 - val_accuracy: 0.7147\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5535 - accuracy: 0.7200 - val_loss: 0.5710 - val_accuracy: 0.7179\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5442 - accuracy: 0.7313 - val_loss: 0.5910 - val_accuracy: 0.6763\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5582 - accuracy: 0.7200 - val_loss: 0.5747 - val_accuracy: 0.6891\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5422 - accuracy: 0.7375 - val_loss: 0.5710 - val_accuracy: 0.7115\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7239 - val_loss: 0.5823 - val_accuracy: 0.7147\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5703 - accuracy: 0.7171 - val_loss: 0.5724 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5456 - accuracy: 0.7217 - val_loss: 0.5737 - val_accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5446 - accuracy: 0.7324 - val_loss: 0.5810 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5509 - accuracy: 0.7245 - val_loss: 0.5731 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.7234 - val_loss: 0.5761 - val_accuracy: 0.7115\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.7324 - val_loss: 0.5735 - val_accuracy: 0.6987\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7296 - val_loss: 0.5745 - val_accuracy: 0.7244\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5385 - accuracy: 0.7347 - val_loss: 0.5757 - val_accuracy: 0.7051\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5394 - accuracy: 0.7347 - val_loss: 0.5804 - val_accuracy: 0.7051\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5344 - accuracy: 0.7387 - val_loss: 0.5709 - val_accuracy: 0.7147\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.7398 - val_loss: 0.5761 - val_accuracy: 0.7115\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5407 - accuracy: 0.7302 - val_loss: 0.5956 - val_accuracy: 0.6891\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5362 - accuracy: 0.7285 - val_loss: 0.5765 - val_accuracy: 0.6891\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5399 - accuracy: 0.7364 - val_loss: 0.5747 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5377 - accuracy: 0.7404 - val_loss: 0.5663 - val_accuracy: 0.7179\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5433 - accuracy: 0.7256 - val_loss: 0.5769 - val_accuracy: 0.7244\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5363 - accuracy: 0.7268 - val_loss: 0.5684 - val_accuracy: 0.7276\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.7336 - val_loss: 0.5757 - val_accuracy: 0.7244\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5305 - accuracy: 0.7336 - val_loss: 0.5798 - val_accuracy: 0.6955\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5272 - accuracy: 0.7415 - val_loss: 0.5820 - val_accuracy: 0.7212\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5422 - accuracy: 0.7239 - val_loss: 0.5785 - val_accuracy: 0.7276\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7375 - val_loss: 0.5952 - val_accuracy: 0.7276\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5209 - accuracy: 0.7392 - val_loss: 0.5949 - val_accuracy: 0.7115\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5306 - accuracy: 0.7375 - val_loss: 0.5802 - val_accuracy: 0.7179\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5268 - accuracy: 0.7347 - val_loss: 0.5833 - val_accuracy: 0.7051\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.7421 - val_loss: 0.5836 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7387 - val_loss: 0.5879 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.7381 - val_loss: 0.5847 - val_accuracy: 0.7212\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7346153846153847\n",
            "Accuracy: 0.7346153846153847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6373 - accuracy: 0.6599 - val_loss: 0.6120 - val_accuracy: 0.6635\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6277 - accuracy: 0.6638 - val_loss: 0.6106 - val_accuracy: 0.6635\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6042 - accuracy: 0.6791 - val_loss: 0.5842 - val_accuracy: 0.6827\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5982 - accuracy: 0.6865 - val_loss: 0.5963 - val_accuracy: 0.7115\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5865 - accuracy: 0.6916 - val_loss: 0.5832 - val_accuracy: 0.7019\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5795 - accuracy: 0.7035 - val_loss: 0.5692 - val_accuracy: 0.7212\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5753 - accuracy: 0.7098 - val_loss: 0.5849 - val_accuracy: 0.7051\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5752 - accuracy: 0.7194 - val_loss: 0.5441 - val_accuracy: 0.7308\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.7262 - val_loss: 0.5837 - val_accuracy: 0.7051\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5680 - accuracy: 0.7120 - val_loss: 0.5714 - val_accuracy: 0.7244\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5635 - accuracy: 0.7251 - val_loss: 0.5579 - val_accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5652 - accuracy: 0.7143 - val_loss: 0.5509 - val_accuracy: 0.7244\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5524 - accuracy: 0.7336 - val_loss: 0.5684 - val_accuracy: 0.7147\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5615 - accuracy: 0.7194 - val_loss: 0.5501 - val_accuracy: 0.7372\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7228 - val_loss: 0.5586 - val_accuracy: 0.7436\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.7347 - val_loss: 0.5481 - val_accuracy: 0.7276\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5497 - accuracy: 0.7211 - val_loss: 0.5669 - val_accuracy: 0.7244\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5467 - accuracy: 0.7313 - val_loss: 0.5449 - val_accuracy: 0.7340\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5396 - accuracy: 0.7330 - val_loss: 0.5485 - val_accuracy: 0.7244\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5395 - accuracy: 0.7375 - val_loss: 0.5761 - val_accuracy: 0.6891\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.7472 - val_loss: 0.5437 - val_accuracy: 0.7276\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.7307 - val_loss: 0.5785 - val_accuracy: 0.7019\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5275 - accuracy: 0.7540 - val_loss: 0.5601 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5458 - accuracy: 0.7330 - val_loss: 0.5629 - val_accuracy: 0.7051\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5384 - accuracy: 0.7477 - val_loss: 0.5692 - val_accuracy: 0.7147\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5311 - accuracy: 0.7466 - val_loss: 0.5641 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5326 - accuracy: 0.7466 - val_loss: 0.5895 - val_accuracy: 0.6859\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5392 - accuracy: 0.7409 - val_loss: 0.5486 - val_accuracy: 0.7340\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7364 - val_loss: 0.5531 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5261 - accuracy: 0.7500 - val_loss: 0.5448 - val_accuracy: 0.7436\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5277 - accuracy: 0.7511 - val_loss: 0.5481 - val_accuracy: 0.7372\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5297 - accuracy: 0.7381 - val_loss: 0.5455 - val_accuracy: 0.7468\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5217 - accuracy: 0.7500 - val_loss: 0.5464 - val_accuracy: 0.7276\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7489 - val_loss: 0.5651 - val_accuracy: 0.7115\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5249 - accuracy: 0.7426 - val_loss: 0.5489 - val_accuracy: 0.7115\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5214 - accuracy: 0.7466 - val_loss: 0.5432 - val_accuracy: 0.7340\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.7449 - val_loss: 0.5498 - val_accuracy: 0.7212\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5229 - accuracy: 0.7460 - val_loss: 0.5628 - val_accuracy: 0.7244\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5243 - accuracy: 0.7466 - val_loss: 0.5685 - val_accuracy: 0.7019\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5174 - accuracy: 0.7551 - val_loss: 0.5607 - val_accuracy: 0.7115\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.7528 - val_loss: 0.5507 - val_accuracy: 0.7179\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5195 - accuracy: 0.7483 - val_loss: 0.5679 - val_accuracy: 0.7244\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5180 - accuracy: 0.7591 - val_loss: 0.5741 - val_accuracy: 0.7115\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5261 - accuracy: 0.7500 - val_loss: 0.5520 - val_accuracy: 0.7212\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.7517 - val_loss: 0.5537 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5173 - accuracy: 0.7432 - val_loss: 0.5509 - val_accuracy: 0.7340\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5226 - accuracy: 0.7494 - val_loss: 0.5796 - val_accuracy: 0.6955\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.7534 - val_loss: 0.5457 - val_accuracy: 0.7404\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5169 - accuracy: 0.7613 - val_loss: 0.5541 - val_accuracy: 0.7276\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5144 - accuracy: 0.7625 - val_loss: 0.5626 - val_accuracy: 0.7340\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7211538461538461\n",
            "Accuracy: 0.7211538461538461\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 10ms/step - loss: 0.6264 - accuracy: 0.6627 - val_loss: 0.6429 - val_accuracy: 0.6442\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6167 - accuracy: 0.6763 - val_loss: 0.6309 - val_accuracy: 0.6442\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6036 - accuracy: 0.6763 - val_loss: 0.6070 - val_accuracy: 0.6442\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6001 - accuracy: 0.6712 - val_loss: 0.6009 - val_accuracy: 0.6442\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6005 - accuracy: 0.6842 - val_loss: 0.5995 - val_accuracy: 0.6699\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5800 - accuracy: 0.7001 - val_loss: 0.5953 - val_accuracy: 0.6891\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5838 - accuracy: 0.7171 - val_loss: 0.5828 - val_accuracy: 0.7147\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5769 - accuracy: 0.7007 - val_loss: 0.5919 - val_accuracy: 0.6859\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5738 - accuracy: 0.7069 - val_loss: 0.6138 - val_accuracy: 0.6474\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5774 - accuracy: 0.7080 - val_loss: 0.5863 - val_accuracy: 0.7019\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5601 - accuracy: 0.7160 - val_loss: 0.5952 - val_accuracy: 0.6795\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5654 - accuracy: 0.7205 - val_loss: 0.5835 - val_accuracy: 0.7115\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5661 - accuracy: 0.7166 - val_loss: 0.5759 - val_accuracy: 0.7147\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7205 - val_loss: 0.6155 - val_accuracy: 0.6859\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5613 - accuracy: 0.7273 - val_loss: 0.5983 - val_accuracy: 0.6891\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5580 - accuracy: 0.7256 - val_loss: 0.6074 - val_accuracy: 0.6795\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5563 - accuracy: 0.7307 - val_loss: 0.5886 - val_accuracy: 0.6859\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5487 - accuracy: 0.7268 - val_loss: 0.5756 - val_accuracy: 0.7244\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5501 - accuracy: 0.7381 - val_loss: 0.5720 - val_accuracy: 0.7147\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.7302 - val_loss: 0.5952 - val_accuracy: 0.6891\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5447 - accuracy: 0.7290 - val_loss: 0.5826 - val_accuracy: 0.7276\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5470 - accuracy: 0.7347 - val_loss: 0.5878 - val_accuracy: 0.6859\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5555 - accuracy: 0.7222 - val_loss: 0.5770 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5396 - accuracy: 0.7358 - val_loss: 0.6183 - val_accuracy: 0.6603\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5451 - accuracy: 0.7341 - val_loss: 0.5823 - val_accuracy: 0.6923\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5392 - accuracy: 0.7387 - val_loss: 0.5765 - val_accuracy: 0.7019\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5394 - accuracy: 0.7375 - val_loss: 0.5943 - val_accuracy: 0.6923\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5405 - accuracy: 0.7358 - val_loss: 0.5808 - val_accuracy: 0.7179\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.7449 - val_loss: 0.5940 - val_accuracy: 0.6923\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5414 - accuracy: 0.7381 - val_loss: 0.5787 - val_accuracy: 0.7083\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7387 - val_loss: 0.5722 - val_accuracy: 0.7308\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5327 - accuracy: 0.7455 - val_loss: 0.5745 - val_accuracy: 0.7212\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7540 - val_loss: 0.5826 - val_accuracy: 0.7051\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.7477 - val_loss: 0.5795 - val_accuracy: 0.7115\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5348 - accuracy: 0.7500 - val_loss: 0.6032 - val_accuracy: 0.6635\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.7398 - val_loss: 0.6073 - val_accuracy: 0.6571\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5372 - accuracy: 0.7364 - val_loss: 0.6121 - val_accuracy: 0.6987\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5225 - accuracy: 0.7511 - val_loss: 0.6164 - val_accuracy: 0.6827\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.7455 - val_loss: 0.5826 - val_accuracy: 0.6891\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7443 - val_loss: 0.5862 - val_accuracy: 0.6763\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5248 - accuracy: 0.7477 - val_loss: 0.5857 - val_accuracy: 0.7019\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5229 - accuracy: 0.7494 - val_loss: 0.5851 - val_accuracy: 0.7179\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5223 - accuracy: 0.7511 - val_loss: 0.5771 - val_accuracy: 0.7083\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5331 - accuracy: 0.7341 - val_loss: 0.5856 - val_accuracy: 0.6923\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5192 - accuracy: 0.7511 - val_loss: 0.5777 - val_accuracy: 0.7244\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5197 - accuracy: 0.7579 - val_loss: 0.5875 - val_accuracy: 0.7115\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5179 - accuracy: 0.7591 - val_loss: 0.5788 - val_accuracy: 0.7276\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5199 - accuracy: 0.7647 - val_loss: 0.5961 - val_accuracy: 0.6923\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5191 - accuracy: 0.7545 - val_loss: 0.5937 - val_accuracy: 0.7019\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5103 - accuracy: 0.7619 - val_loss: 0.5862 - val_accuracy: 0.7179\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7519230769230769\n",
            "Accuracy: 0.7519230769230769\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 8ms/step - loss: 0.6456 - accuracy: 0.6570 - val_loss: 0.6259 - val_accuracy: 0.6699\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6303 - accuracy: 0.6633 - val_loss: 0.6271 - val_accuracy: 0.6699\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6160 - accuracy: 0.6644 - val_loss: 0.5989 - val_accuracy: 0.6763\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6099 - accuracy: 0.6922 - val_loss: 0.5931 - val_accuracy: 0.6763\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5980 - accuracy: 0.6916 - val_loss: 0.5757 - val_accuracy: 0.7051\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5899 - accuracy: 0.6933 - val_loss: 0.5688 - val_accuracy: 0.7051\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5806 - accuracy: 0.7069 - val_loss: 0.5691 - val_accuracy: 0.7179\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5822 - accuracy: 0.7024 - val_loss: 0.5859 - val_accuracy: 0.6955\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5737 - accuracy: 0.7183 - val_loss: 0.5539 - val_accuracy: 0.7083\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5704 - accuracy: 0.7222 - val_loss: 0.5617 - val_accuracy: 0.7051\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5715 - accuracy: 0.7115 - val_loss: 0.5548 - val_accuracy: 0.7212\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5672 - accuracy: 0.7137 - val_loss: 0.5614 - val_accuracy: 0.7179\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5670 - accuracy: 0.7046 - val_loss: 0.5581 - val_accuracy: 0.7083\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5578 - accuracy: 0.7188 - val_loss: 0.5506 - val_accuracy: 0.7115\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5611 - accuracy: 0.7188 - val_loss: 0.5670 - val_accuracy: 0.7115\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5585 - accuracy: 0.7307 - val_loss: 0.5476 - val_accuracy: 0.7115\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5464 - accuracy: 0.7370 - val_loss: 0.5509 - val_accuracy: 0.7179\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5580 - accuracy: 0.7347 - val_loss: 0.5580 - val_accuracy: 0.7212\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5469 - accuracy: 0.7256 - val_loss: 0.5634 - val_accuracy: 0.6987\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5522 - accuracy: 0.7358 - val_loss: 0.5463 - val_accuracy: 0.7212\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5440 - accuracy: 0.7443 - val_loss: 0.5509 - val_accuracy: 0.7179\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5434 - accuracy: 0.7387 - val_loss: 0.5500 - val_accuracy: 0.7147\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5450 - accuracy: 0.7375 - val_loss: 0.5491 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5439 - accuracy: 0.7443 - val_loss: 0.5558 - val_accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7347 - val_loss: 0.5430 - val_accuracy: 0.7083\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5399 - accuracy: 0.7347 - val_loss: 0.5436 - val_accuracy: 0.7308\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5426 - accuracy: 0.7409 - val_loss: 0.5586 - val_accuracy: 0.7115\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.7319 - val_loss: 0.5723 - val_accuracy: 0.7147\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5467 - accuracy: 0.7426 - val_loss: 0.5426 - val_accuracy: 0.7147\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5354 - accuracy: 0.7432 - val_loss: 0.5297 - val_accuracy: 0.7372\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5273 - accuracy: 0.7438 - val_loss: 0.5444 - val_accuracy: 0.7308\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7489 - val_loss: 0.5514 - val_accuracy: 0.7083\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5425 - accuracy: 0.7358 - val_loss: 0.5428 - val_accuracy: 0.7244\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7517 - val_loss: 0.5462 - val_accuracy: 0.7276\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.7245 - val_loss: 0.5529 - val_accuracy: 0.7308\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5354 - accuracy: 0.7438 - val_loss: 0.5429 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5306 - accuracy: 0.7506 - val_loss: 0.5394 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.7438 - val_loss: 0.5453 - val_accuracy: 0.7147\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.7494 - val_loss: 0.5369 - val_accuracy: 0.7276\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5282 - accuracy: 0.7511 - val_loss: 0.5418 - val_accuracy: 0.7147\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.7404 - val_loss: 0.5380 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7511 - val_loss: 0.5397 - val_accuracy: 0.7212\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5342 - accuracy: 0.7455 - val_loss: 0.5492 - val_accuracy: 0.7308\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5318 - accuracy: 0.7511 - val_loss: 0.5394 - val_accuracy: 0.7212\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5270 - accuracy: 0.7489 - val_loss: 0.5449 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5259 - accuracy: 0.7494 - val_loss: 0.5310 - val_accuracy: 0.7340\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5197 - accuracy: 0.7557 - val_loss: 0.5391 - val_accuracy: 0.7436\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5240 - accuracy: 0.7489 - val_loss: 0.5366 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5250 - accuracy: 0.7517 - val_loss: 0.5434 - val_accuracy: 0.7372\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.7472 - val_loss: 0.5333 - val_accuracy: 0.7308\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7192307692307692\n",
            "Accuracy: 0.7192307692307692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 12ms/step - loss: 0.6355 - accuracy: 0.6582 - val_loss: 0.6141 - val_accuracy: 0.6635\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6672 - val_loss: 0.6056 - val_accuracy: 0.6635\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6063 - accuracy: 0.6661 - val_loss: 0.5983 - val_accuracy: 0.6891\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6053 - accuracy: 0.6746 - val_loss: 0.5803 - val_accuracy: 0.6987\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5962 - accuracy: 0.6780 - val_loss: 0.5707 - val_accuracy: 0.7468\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5817 - accuracy: 0.7024 - val_loss: 0.5452 - val_accuracy: 0.7372\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5660 - accuracy: 0.7109 - val_loss: 0.5298 - val_accuracy: 0.7564\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5715 - accuracy: 0.7080 - val_loss: 0.5348 - val_accuracy: 0.7564\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5720 - accuracy: 0.7080 - val_loss: 0.5395 - val_accuracy: 0.7340\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5619 - accuracy: 0.7166 - val_loss: 0.5496 - val_accuracy: 0.7179\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5507 - accuracy: 0.7302 - val_loss: 0.5416 - val_accuracy: 0.7596\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5592 - accuracy: 0.7228 - val_loss: 0.5499 - val_accuracy: 0.7404\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5507 - accuracy: 0.7256 - val_loss: 0.5638 - val_accuracy: 0.7404\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5411 - accuracy: 0.7336 - val_loss: 0.5263 - val_accuracy: 0.7436\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5486 - accuracy: 0.7313 - val_loss: 0.5589 - val_accuracy: 0.7147\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5412 - accuracy: 0.7307 - val_loss: 0.5358 - val_accuracy: 0.7532\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5407 - accuracy: 0.7239 - val_loss: 0.5338 - val_accuracy: 0.7372\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5399 - accuracy: 0.7245 - val_loss: 0.5556 - val_accuracy: 0.7308\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.7188 - val_loss: 0.5633 - val_accuracy: 0.7115\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5380 - accuracy: 0.7273 - val_loss: 0.5340 - val_accuracy: 0.7468\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.7358 - val_loss: 0.5370 - val_accuracy: 0.7596\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5460 - accuracy: 0.7330 - val_loss: 0.5443 - val_accuracy: 0.7436\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7290 - val_loss: 0.5434 - val_accuracy: 0.7564\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.7392 - val_loss: 0.5452 - val_accuracy: 0.7532\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.7319 - val_loss: 0.5548 - val_accuracy: 0.7276\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7483 - val_loss: 0.5559 - val_accuracy: 0.7436\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5371 - accuracy: 0.7364 - val_loss: 0.5936 - val_accuracy: 0.7019\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.7392 - val_loss: 0.5671 - val_accuracy: 0.7340\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7387 - val_loss: 0.5811 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5306 - accuracy: 0.7489 - val_loss: 0.5860 - val_accuracy: 0.7340\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7432 - val_loss: 0.5417 - val_accuracy: 0.7244\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5287 - accuracy: 0.7466 - val_loss: 0.5534 - val_accuracy: 0.7436\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5320 - accuracy: 0.7290 - val_loss: 0.5581 - val_accuracy: 0.7564\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5294 - accuracy: 0.7358 - val_loss: 0.5559 - val_accuracy: 0.7468\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5217 - accuracy: 0.7432 - val_loss: 0.5543 - val_accuracy: 0.7532\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5351 - accuracy: 0.7358 - val_loss: 0.5838 - val_accuracy: 0.6955\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5198 - accuracy: 0.7494 - val_loss: 0.5917 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.7443 - val_loss: 0.5865 - val_accuracy: 0.7212\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5221 - accuracy: 0.7466 - val_loss: 0.6327 - val_accuracy: 0.7468\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5251 - accuracy: 0.7472 - val_loss: 0.5837 - val_accuracy: 0.7308\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.7409 - val_loss: 0.5704 - val_accuracy: 0.7147\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5189 - accuracy: 0.7449 - val_loss: 0.5697 - val_accuracy: 0.7372\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.7477 - val_loss: 0.6024 - val_accuracy: 0.7436\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5301 - accuracy: 0.7307 - val_loss: 0.5865 - val_accuracy: 0.7276\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5195 - accuracy: 0.7523 - val_loss: 0.5756 - val_accuracy: 0.7404\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5194 - accuracy: 0.7511 - val_loss: 0.5951 - val_accuracy: 0.7404\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5201 - accuracy: 0.7500 - val_loss: 0.6035 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5083 - accuracy: 0.7579 - val_loss: 0.5852 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5180 - accuracy: 0.7528 - val_loss: 0.5633 - val_accuracy: 0.6955\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5113 - accuracy: 0.7568 - val_loss: 0.5681 - val_accuracy: 0.7308\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7211538461538461\n",
            "Accuracy: 0.7211538461538461\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6428 - accuracy: 0.6417 - val_loss: 0.5988 - val_accuracy: 0.6891\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.6474 - val_loss: 0.6035 - val_accuracy: 0.6987\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6254 - accuracy: 0.6593 - val_loss: 0.5756 - val_accuracy: 0.7532\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6009 - accuracy: 0.6922 - val_loss: 0.5582 - val_accuracy: 0.7179\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5873 - accuracy: 0.7041 - val_loss: 0.5357 - val_accuracy: 0.7724\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5787 - accuracy: 0.7092 - val_loss: 0.5436 - val_accuracy: 0.7628\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5837 - accuracy: 0.7001 - val_loss: 0.5328 - val_accuracy: 0.7596\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5768 - accuracy: 0.7018 - val_loss: 0.5467 - val_accuracy: 0.7724\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5815 - accuracy: 0.6978 - val_loss: 0.5370 - val_accuracy: 0.7660\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5619 - accuracy: 0.7171 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5676 - accuracy: 0.7188 - val_loss: 0.5258 - val_accuracy: 0.7564\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5701 - accuracy: 0.7149 - val_loss: 0.5301 - val_accuracy: 0.7724\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5582 - accuracy: 0.7160 - val_loss: 0.5368 - val_accuracy: 0.7372\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5605 - accuracy: 0.7285 - val_loss: 0.5149 - val_accuracy: 0.7756\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5478 - accuracy: 0.7239 - val_loss: 0.5396 - val_accuracy: 0.7564\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5520 - accuracy: 0.7285 - val_loss: 0.5700 - val_accuracy: 0.7083\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.7302 - val_loss: 0.5400 - val_accuracy: 0.7788\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5493 - accuracy: 0.7307 - val_loss: 0.5265 - val_accuracy: 0.7596\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5540 - accuracy: 0.7285 - val_loss: 0.5314 - val_accuracy: 0.7628\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5456 - accuracy: 0.7285 - val_loss: 0.5221 - val_accuracy: 0.7532\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5496 - accuracy: 0.7290 - val_loss: 0.5429 - val_accuracy: 0.7532\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5409 - accuracy: 0.7409 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5488 - accuracy: 0.7217 - val_loss: 0.5285 - val_accuracy: 0.7596\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7205 - val_loss: 0.5268 - val_accuracy: 0.7596\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5453 - accuracy: 0.7415 - val_loss: 0.5357 - val_accuracy: 0.7788\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5448 - accuracy: 0.7319 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5375 - accuracy: 0.7404 - val_loss: 0.5169 - val_accuracy: 0.7724\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5401 - accuracy: 0.7438 - val_loss: 0.5194 - val_accuracy: 0.7596\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5343 - accuracy: 0.7381 - val_loss: 0.5362 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5405 - accuracy: 0.7313 - val_loss: 0.5232 - val_accuracy: 0.7628\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7426 - val_loss: 0.5257 - val_accuracy: 0.7756\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5310 - accuracy: 0.7477 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5410 - accuracy: 0.7228 - val_loss: 0.5282 - val_accuracy: 0.7628\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5293 - accuracy: 0.7511 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.7341 - val_loss: 0.5161 - val_accuracy: 0.7692\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5274 - accuracy: 0.7460 - val_loss: 0.5115 - val_accuracy: 0.7660\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7506 - val_loss: 0.5240 - val_accuracy: 0.7564\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5268 - accuracy: 0.7387 - val_loss: 0.5357 - val_accuracy: 0.7340\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.7472 - val_loss: 0.5123 - val_accuracy: 0.7756\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5231 - accuracy: 0.7455 - val_loss: 0.5283 - val_accuracy: 0.7596\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5292 - accuracy: 0.7415 - val_loss: 0.5179 - val_accuracy: 0.7724\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5221 - accuracy: 0.7421 - val_loss: 0.5516 - val_accuracy: 0.7372\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5273 - accuracy: 0.7455 - val_loss: 0.5219 - val_accuracy: 0.7724\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.7506 - val_loss: 0.5403 - val_accuracy: 0.7532\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5306 - accuracy: 0.7472 - val_loss: 0.5251 - val_accuracy: 0.7660\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.7528 - val_loss: 0.5333 - val_accuracy: 0.7596\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5228 - accuracy: 0.7534 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7426 - val_loss: 0.5301 - val_accuracy: 0.7436\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5166 - accuracy: 0.7466 - val_loss: 0.5309 - val_accuracy: 0.7564\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5139 - accuracy: 0.7574 - val_loss: 0.5335 - val_accuracy: 0.7532\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7038461538461539\n",
            "Accuracy: 0.7038461538461539\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6386 - accuracy: 0.6570 - val_loss: 0.6181 - val_accuracy: 0.6474\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6308 - accuracy: 0.6604 - val_loss: 0.6100 - val_accuracy: 0.6474\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6188 - accuracy: 0.6610 - val_loss: 0.5964 - val_accuracy: 0.6506\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6111 - accuracy: 0.6587 - val_loss: 0.6030 - val_accuracy: 0.6474\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5962 - accuracy: 0.6735 - val_loss: 0.5832 - val_accuracy: 0.6795\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5874 - accuracy: 0.6984 - val_loss: 0.5933 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5807 - accuracy: 0.7024 - val_loss: 0.6218 - val_accuracy: 0.6571\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5793 - accuracy: 0.7012 - val_loss: 0.6045 - val_accuracy: 0.6731\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5757 - accuracy: 0.7239 - val_loss: 0.5727 - val_accuracy: 0.7276\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5771 - accuracy: 0.7012 - val_loss: 0.5911 - val_accuracy: 0.6571\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5709 - accuracy: 0.7046 - val_loss: 0.5720 - val_accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5689 - accuracy: 0.7126 - val_loss: 0.5588 - val_accuracy: 0.7179\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5631 - accuracy: 0.7171 - val_loss: 0.5589 - val_accuracy: 0.7212\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5614 - accuracy: 0.7171 - val_loss: 0.5478 - val_accuracy: 0.7244\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5671 - accuracy: 0.7171 - val_loss: 0.5432 - val_accuracy: 0.7436\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5608 - accuracy: 0.7120 - val_loss: 0.5565 - val_accuracy: 0.7436\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5630 - accuracy: 0.7132 - val_loss: 0.5647 - val_accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5615 - accuracy: 0.7126 - val_loss: 0.5736 - val_accuracy: 0.7147\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5545 - accuracy: 0.7262 - val_loss: 0.5590 - val_accuracy: 0.7212\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7166 - val_loss: 0.5647 - val_accuracy: 0.7083\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5577 - accuracy: 0.7103 - val_loss: 0.5541 - val_accuracy: 0.7276\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.7296 - val_loss: 0.5372 - val_accuracy: 0.7404\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5598 - accuracy: 0.7007 - val_loss: 0.5485 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5612 - accuracy: 0.7137 - val_loss: 0.5559 - val_accuracy: 0.7308\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5563 - accuracy: 0.7256 - val_loss: 0.5512 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.7234 - val_loss: 0.5391 - val_accuracy: 0.7340\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5464 - accuracy: 0.7245 - val_loss: 0.5661 - val_accuracy: 0.7051\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5486 - accuracy: 0.7256 - val_loss: 0.5436 - val_accuracy: 0.7468\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5473 - accuracy: 0.7251 - val_loss: 0.5486 - val_accuracy: 0.7212\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5393 - accuracy: 0.7330 - val_loss: 0.5398 - val_accuracy: 0.7372\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5424 - accuracy: 0.7313 - val_loss: 0.5870 - val_accuracy: 0.6667\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5502 - accuracy: 0.7262 - val_loss: 0.5443 - val_accuracy: 0.7372\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5431 - accuracy: 0.7307 - val_loss: 0.5335 - val_accuracy: 0.7404\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7302 - val_loss: 0.5769 - val_accuracy: 0.6699\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7262 - val_loss: 0.5525 - val_accuracy: 0.7147\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5439 - accuracy: 0.7217 - val_loss: 0.5487 - val_accuracy: 0.7244\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5340 - accuracy: 0.7330 - val_loss: 0.5335 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5404 - accuracy: 0.7347 - val_loss: 0.5360 - val_accuracy: 0.7436\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5345 - accuracy: 0.7273 - val_loss: 0.5720 - val_accuracy: 0.7115\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.7268 - val_loss: 0.5465 - val_accuracy: 0.7244\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7381 - val_loss: 0.5387 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7273 - val_loss: 0.5455 - val_accuracy: 0.7244\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.7256 - val_loss: 0.5358 - val_accuracy: 0.7532\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.7460 - val_loss: 0.5340 - val_accuracy: 0.7340\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5227 - accuracy: 0.7404 - val_loss: 0.5294 - val_accuracy: 0.7436\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.7375 - val_loss: 0.5330 - val_accuracy: 0.7404\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5301 - accuracy: 0.7347 - val_loss: 0.5356 - val_accuracy: 0.7628\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5409 - accuracy: 0.7285 - val_loss: 0.5459 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5302 - accuracy: 0.7409 - val_loss: 0.5303 - val_accuracy: 0.7564\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5316 - accuracy: 0.7341 - val_loss: 0.5522 - val_accuracy: 0.7115\n",
            "17/17 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7038461538461539\n",
            "Accuracy: 0.7038461538461539\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6321 - accuracy: 0.6701 - val_loss: 0.6429 - val_accuracy: 0.6603\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.6706 - val_loss: 0.6155 - val_accuracy: 0.6603\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6089 - accuracy: 0.6689 - val_loss: 0.6031 - val_accuracy: 0.6603\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5983 - accuracy: 0.6803 - val_loss: 0.5770 - val_accuracy: 0.7115\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5876 - accuracy: 0.6808 - val_loss: 0.5804 - val_accuracy: 0.7308\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5779 - accuracy: 0.6922 - val_loss: 0.5658 - val_accuracy: 0.7083\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5747 - accuracy: 0.7154 - val_loss: 0.5701 - val_accuracy: 0.7244\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5754 - accuracy: 0.7007 - val_loss: 0.5726 - val_accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5652 - accuracy: 0.7194 - val_loss: 0.5526 - val_accuracy: 0.7340\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5620 - accuracy: 0.7109 - val_loss: 0.5581 - val_accuracy: 0.7179\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5659 - accuracy: 0.7075 - val_loss: 0.5654 - val_accuracy: 0.7051\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5544 - accuracy: 0.7188 - val_loss: 0.5826 - val_accuracy: 0.6891\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5574 - accuracy: 0.7205 - val_loss: 0.5471 - val_accuracy: 0.7532\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5603 - accuracy: 0.7069 - val_loss: 0.5837 - val_accuracy: 0.6859\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5456 - accuracy: 0.7160 - val_loss: 0.5448 - val_accuracy: 0.7372\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5544 - accuracy: 0.7285 - val_loss: 0.5772 - val_accuracy: 0.6827\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5526 - accuracy: 0.7137 - val_loss: 0.5546 - val_accuracy: 0.7564\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5420 - accuracy: 0.7268 - val_loss: 0.6351 - val_accuracy: 0.7179\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5561 - accuracy: 0.7200 - val_loss: 0.5479 - val_accuracy: 0.7468\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5537 - accuracy: 0.7319 - val_loss: 0.5576 - val_accuracy: 0.7179\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.7313 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5424 - accuracy: 0.7324 - val_loss: 0.5666 - val_accuracy: 0.7115\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5424 - accuracy: 0.7341 - val_loss: 0.5597 - val_accuracy: 0.7340\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5472 - accuracy: 0.7273 - val_loss: 0.5782 - val_accuracy: 0.6891\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5444 - accuracy: 0.7205 - val_loss: 0.6001 - val_accuracy: 0.7404\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5484 - accuracy: 0.7353 - val_loss: 0.5773 - val_accuracy: 0.7147\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5407 - accuracy: 0.7194 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.7387 - val_loss: 0.5553 - val_accuracy: 0.7468\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5347 - accuracy: 0.7358 - val_loss: 0.5515 - val_accuracy: 0.7468\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.7324 - val_loss: 0.5485 - val_accuracy: 0.7436\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5347 - accuracy: 0.7421 - val_loss: 0.5513 - val_accuracy: 0.7532\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5385 - accuracy: 0.7341 - val_loss: 0.5522 - val_accuracy: 0.7468\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7347 - val_loss: 0.5589 - val_accuracy: 0.7372\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5308 - accuracy: 0.7432 - val_loss: 0.5648 - val_accuracy: 0.7372\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.7381 - val_loss: 0.5671 - val_accuracy: 0.7212\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5381 - accuracy: 0.7381 - val_loss: 0.5432 - val_accuracy: 0.7564\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5258 - accuracy: 0.7358 - val_loss: 0.5624 - val_accuracy: 0.7308\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5302 - accuracy: 0.7370 - val_loss: 0.5673 - val_accuracy: 0.7372\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5167 - accuracy: 0.7432 - val_loss: 0.5870 - val_accuracy: 0.7051\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5213 - accuracy: 0.7466 - val_loss: 0.5639 - val_accuracy: 0.7436\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5220 - accuracy: 0.7449 - val_loss: 0.5723 - val_accuracy: 0.7147\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7347 - val_loss: 0.5504 - val_accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5142 - accuracy: 0.7534 - val_loss: 0.5612 - val_accuracy: 0.7308\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5227 - accuracy: 0.7392 - val_loss: 0.5715 - val_accuracy: 0.7179\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5165 - accuracy: 0.7455 - val_loss: 0.5652 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5162 - accuracy: 0.7409 - val_loss: 0.5612 - val_accuracy: 0.7340\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5139 - accuracy: 0.7528 - val_loss: 0.5539 - val_accuracy: 0.7436\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5144 - accuracy: 0.7494 - val_loss: 0.5458 - val_accuracy: 0.7532\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5072 - accuracy: 0.7568 - val_loss: 0.5454 - val_accuracy: 0.7564\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5115 - accuracy: 0.7460 - val_loss: 0.5719 - val_accuracy: 0.7468\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7230769230769231\n",
            "Accuracy: 0.7230769230769231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6404 - accuracy: 0.6576 - val_loss: 0.6033 - val_accuracy: 0.6699\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6621 - val_loss: 0.6372 - val_accuracy: 0.6699\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6246 - accuracy: 0.6610 - val_loss: 0.5773 - val_accuracy: 0.6699\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5956 - accuracy: 0.6905 - val_loss: 0.5611 - val_accuracy: 0.7051\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5912 - accuracy: 0.6893 - val_loss: 0.5529 - val_accuracy: 0.7340\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5807 - accuracy: 0.7018 - val_loss: 0.5346 - val_accuracy: 0.7340\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5655 - accuracy: 0.7239 - val_loss: 0.5628 - val_accuracy: 0.6987\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5729 - accuracy: 0.7143 - val_loss: 0.5645 - val_accuracy: 0.7500\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5650 - accuracy: 0.7217 - val_loss: 0.5514 - val_accuracy: 0.7308\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5561 - accuracy: 0.7183 - val_loss: 0.5515 - val_accuracy: 0.7308\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5658 - accuracy: 0.7177 - val_loss: 0.5957 - val_accuracy: 0.6763\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5604 - accuracy: 0.7256 - val_loss: 0.5714 - val_accuracy: 0.6923\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5579 - accuracy: 0.7239 - val_loss: 0.5475 - val_accuracy: 0.7564\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5558 - accuracy: 0.7177 - val_loss: 0.5360 - val_accuracy: 0.7532\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5677 - accuracy: 0.7137 - val_loss: 0.5456 - val_accuracy: 0.7340\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5589 - accuracy: 0.7273 - val_loss: 0.5187 - val_accuracy: 0.7660\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5504 - accuracy: 0.7336 - val_loss: 0.5411 - val_accuracy: 0.7660\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5613 - accuracy: 0.7217 - val_loss: 0.5467 - val_accuracy: 0.7308\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5511 - accuracy: 0.7443 - val_loss: 0.5607 - val_accuracy: 0.6987\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5493 - accuracy: 0.7330 - val_loss: 0.5814 - val_accuracy: 0.6923\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7370 - val_loss: 0.5325 - val_accuracy: 0.7596\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5455 - accuracy: 0.7336 - val_loss: 0.5447 - val_accuracy: 0.7596\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5408 - accuracy: 0.7466 - val_loss: 0.5424 - val_accuracy: 0.7404\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5512 - accuracy: 0.7336 - val_loss: 0.5472 - val_accuracy: 0.7564\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5508 - accuracy: 0.7347 - val_loss: 0.5703 - val_accuracy: 0.7596\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.7296 - val_loss: 0.5826 - val_accuracy: 0.6955\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5472 - accuracy: 0.7387 - val_loss: 0.5391 - val_accuracy: 0.7532\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5388 - accuracy: 0.7347 - val_loss: 0.5476 - val_accuracy: 0.7468\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5379 - accuracy: 0.7370 - val_loss: 0.5318 - val_accuracy: 0.7468\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5480 - accuracy: 0.7177 - val_loss: 0.5579 - val_accuracy: 0.7564\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.7398 - val_loss: 0.5790 - val_accuracy: 0.7468\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5371 - accuracy: 0.7483 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7472 - val_loss: 0.5522 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5338 - accuracy: 0.7477 - val_loss: 0.5532 - val_accuracy: 0.7564\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5337 - accuracy: 0.7494 - val_loss: 0.5390 - val_accuracy: 0.7372\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5362 - accuracy: 0.7432 - val_loss: 0.5540 - val_accuracy: 0.7244\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.7443 - val_loss: 0.5452 - val_accuracy: 0.7564\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5360 - accuracy: 0.7483 - val_loss: 0.5924 - val_accuracy: 0.7083\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5371 - accuracy: 0.7432 - val_loss: 0.5571 - val_accuracy: 0.7147\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7545 - val_loss: 0.5529 - val_accuracy: 0.7147\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5407 - accuracy: 0.7313 - val_loss: 0.5556 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5341 - accuracy: 0.7290 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5283 - accuracy: 0.7460 - val_loss: 0.5587 - val_accuracy: 0.7468\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7506 - val_loss: 0.5377 - val_accuracy: 0.7404\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5301 - accuracy: 0.7523 - val_loss: 0.5540 - val_accuracy: 0.7244\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5277 - accuracy: 0.7511 - val_loss: 0.5916 - val_accuracy: 0.6955\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5229 - accuracy: 0.7489 - val_loss: 0.5640 - val_accuracy: 0.7019\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5245 - accuracy: 0.7472 - val_loss: 0.5637 - val_accuracy: 0.7500\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5220 - accuracy: 0.7477 - val_loss: 0.5541 - val_accuracy: 0.7468\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5334 - accuracy: 0.7472 - val_loss: 0.5510 - val_accuracy: 0.7212\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7288461538461538\n",
            "Accuracy: 0.7288461538461538\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6321 - accuracy: 0.6610 - val_loss: 0.6473 - val_accuracy: 0.6827\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6262 - accuracy: 0.6633 - val_loss: 0.6004 - val_accuracy: 0.6827\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6193 - accuracy: 0.6644 - val_loss: 0.5982 - val_accuracy: 0.6827\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6072 - accuracy: 0.6638 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6068 - accuracy: 0.6814 - val_loss: 0.5656 - val_accuracy: 0.6987\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5876 - accuracy: 0.6854 - val_loss: 0.5520 - val_accuracy: 0.7532\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5778 - accuracy: 0.7035 - val_loss: 0.6016 - val_accuracy: 0.6763\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5748 - accuracy: 0.7194 - val_loss: 0.5336 - val_accuracy: 0.7564\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5668 - accuracy: 0.7194 - val_loss: 0.5471 - val_accuracy: 0.7340\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5633 - accuracy: 0.7205 - val_loss: 0.5373 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5752 - accuracy: 0.7103 - val_loss: 0.5665 - val_accuracy: 0.7340\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5554 - accuracy: 0.7245 - val_loss: 0.5622 - val_accuracy: 0.7051\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5676 - accuracy: 0.7194 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5678 - accuracy: 0.7098 - val_loss: 0.5227 - val_accuracy: 0.7692\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7239 - val_loss: 0.5443 - val_accuracy: 0.7468\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.7341 - val_loss: 0.5481 - val_accuracy: 0.7404\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5534 - accuracy: 0.7234 - val_loss: 0.5307 - val_accuracy: 0.7404\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5462 - accuracy: 0.7279 - val_loss: 0.5097 - val_accuracy: 0.7756\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5504 - accuracy: 0.7307 - val_loss: 0.5287 - val_accuracy: 0.7404\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7370 - val_loss: 0.5254 - val_accuracy: 0.7596\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5478 - accuracy: 0.7313 - val_loss: 0.5318 - val_accuracy: 0.7660\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.7404 - val_loss: 0.5262 - val_accuracy: 0.7628\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5414 - accuracy: 0.7421 - val_loss: 0.5297 - val_accuracy: 0.7596\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5365 - accuracy: 0.7330 - val_loss: 0.5112 - val_accuracy: 0.7692\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5354 - accuracy: 0.7341 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5365 - accuracy: 0.7353 - val_loss: 0.5128 - val_accuracy: 0.7660\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5268 - accuracy: 0.7489 - val_loss: 0.5272 - val_accuracy: 0.7660\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5264 - accuracy: 0.7432 - val_loss: 0.5856 - val_accuracy: 0.6635\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5278 - accuracy: 0.7477 - val_loss: 0.5216 - val_accuracy: 0.7724\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7466 - val_loss: 0.5434 - val_accuracy: 0.7596\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5377 - accuracy: 0.7347 - val_loss: 0.5270 - val_accuracy: 0.7724\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.7460 - val_loss: 0.5334 - val_accuracy: 0.7468\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7358 - val_loss: 0.5446 - val_accuracy: 0.7404\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5289 - accuracy: 0.7336 - val_loss: 0.5227 - val_accuracy: 0.7628\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5223 - accuracy: 0.7455 - val_loss: 0.5291 - val_accuracy: 0.7404\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5256 - accuracy: 0.7489 - val_loss: 0.5523 - val_accuracy: 0.7147\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5229 - accuracy: 0.7551 - val_loss: 0.5093 - val_accuracy: 0.7660\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5261 - accuracy: 0.7511 - val_loss: 0.5346 - val_accuracy: 0.7179\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5203 - accuracy: 0.7579 - val_loss: 0.5113 - val_accuracy: 0.7756\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.7540 - val_loss: 0.5292 - val_accuracy: 0.7660\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.7460 - val_loss: 0.5094 - val_accuracy: 0.7917\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5248 - accuracy: 0.7557 - val_loss: 0.5161 - val_accuracy: 0.7692\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5167 - accuracy: 0.7500 - val_loss: 0.5247 - val_accuracy: 0.7692\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7568 - val_loss: 0.5323 - val_accuracy: 0.7532\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5019 - accuracy: 0.7647 - val_loss: 0.5349 - val_accuracy: 0.7404\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5225 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5263 - accuracy: 0.7370 - val_loss: 0.5373 - val_accuracy: 0.7404\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.7596 - val_loss: 0.5353 - val_accuracy: 0.7692\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5158 - accuracy: 0.7557 - val_loss: 0.5394 - val_accuracy: 0.7436\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.7517 - val_loss: 0.5409 - val_accuracy: 0.7564\n",
            "17/17 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7096153846153846\n",
            "Accuracy: 0.7096153846153846\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6311 - accuracy: 0.6650 - val_loss: 0.6395 - val_accuracy: 0.6218\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6176 - accuracy: 0.6667 - val_loss: 0.6407 - val_accuracy: 0.6346\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.6650 - val_loss: 0.6275 - val_accuracy: 0.6282\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5889 - accuracy: 0.6978 - val_loss: 0.6161 - val_accuracy: 0.6538\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5851 - accuracy: 0.7103 - val_loss: 0.6496 - val_accuracy: 0.5929\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5720 - accuracy: 0.7080 - val_loss: 0.6169 - val_accuracy: 0.6538\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5762 - accuracy: 0.7177 - val_loss: 0.5986 - val_accuracy: 0.6827\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5767 - accuracy: 0.7251 - val_loss: 0.6019 - val_accuracy: 0.6891\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5562 - accuracy: 0.7285 - val_loss: 0.6066 - val_accuracy: 0.6667\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5633 - accuracy: 0.7239 - val_loss: 0.5959 - val_accuracy: 0.6859\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5590 - accuracy: 0.7183 - val_loss: 0.5949 - val_accuracy: 0.6955\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5570 - accuracy: 0.7296 - val_loss: 0.6074 - val_accuracy: 0.6955\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5448 - accuracy: 0.7392 - val_loss: 0.5987 - val_accuracy: 0.6699\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5533 - accuracy: 0.7319 - val_loss: 0.6365 - val_accuracy: 0.6571\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5410 - accuracy: 0.7392 - val_loss: 0.6229 - val_accuracy: 0.6538\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5406 - accuracy: 0.7341 - val_loss: 0.5951 - val_accuracy: 0.6763\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5384 - accuracy: 0.7421 - val_loss: 0.6451 - val_accuracy: 0.6474\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5515 - accuracy: 0.7251 - val_loss: 0.5858 - val_accuracy: 0.6763\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5323 - accuracy: 0.7517 - val_loss: 0.6002 - val_accuracy: 0.6763\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5429 - accuracy: 0.7341 - val_loss: 0.5820 - val_accuracy: 0.6859\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5352 - accuracy: 0.7511 - val_loss: 0.6146 - val_accuracy: 0.6795\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5421 - accuracy: 0.7347 - val_loss: 0.5867 - val_accuracy: 0.6891\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5351 - accuracy: 0.7477 - val_loss: 0.5875 - val_accuracy: 0.6827\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5360 - accuracy: 0.7443 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7562 - val_loss: 0.6041 - val_accuracy: 0.6859\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5349 - accuracy: 0.7517 - val_loss: 0.6031 - val_accuracy: 0.6827\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5326 - accuracy: 0.7472 - val_loss: 0.5850 - val_accuracy: 0.6827\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5328 - accuracy: 0.7534 - val_loss: 0.5947 - val_accuracy: 0.6667\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7506 - val_loss: 0.5834 - val_accuracy: 0.7083\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5274 - accuracy: 0.7534 - val_loss: 0.5977 - val_accuracy: 0.6827\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5182 - accuracy: 0.7477 - val_loss: 0.5840 - val_accuracy: 0.6795\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.7568 - val_loss: 0.6098 - val_accuracy: 0.6635\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7426 - val_loss: 0.6092 - val_accuracy: 0.6731\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.7466 - val_loss: 0.5881 - val_accuracy: 0.6827\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5242 - accuracy: 0.7511 - val_loss: 0.5921 - val_accuracy: 0.6795\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5144 - accuracy: 0.7517 - val_loss: 0.6212 - val_accuracy: 0.6667\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5194 - accuracy: 0.7562 - val_loss: 0.5999 - val_accuracy: 0.7083\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.7540 - val_loss: 0.5987 - val_accuracy: 0.6699\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5148 - accuracy: 0.7602 - val_loss: 0.5921 - val_accuracy: 0.6635\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5149 - accuracy: 0.7540 - val_loss: 0.5965 - val_accuracy: 0.6699\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5118 - accuracy: 0.7568 - val_loss: 0.5893 - val_accuracy: 0.6987\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5149 - accuracy: 0.7608 - val_loss: 0.5801 - val_accuracy: 0.6955\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5125 - accuracy: 0.7562 - val_loss: 0.6055 - val_accuracy: 0.6827\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5093 - accuracy: 0.7642 - val_loss: 0.5827 - val_accuracy: 0.6923\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5142 - accuracy: 0.7602 - val_loss: 0.5960 - val_accuracy: 0.7083\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5158 - accuracy: 0.7596 - val_loss: 0.5944 - val_accuracy: 0.6635\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5083 - accuracy: 0.7557 - val_loss: 0.6090 - val_accuracy: 0.6667\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5174 - accuracy: 0.7591 - val_loss: 0.5806 - val_accuracy: 0.7083\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5172 - accuracy: 0.7523 - val_loss: 0.5849 - val_accuracy: 0.7019\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5087 - accuracy: 0.7579 - val_loss: 0.5904 - val_accuracy: 0.6827\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7230769230769231\n",
            "Accuracy: 0.7230769230769231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6470 - accuracy: 0.6531 - val_loss: 0.5905 - val_accuracy: 0.7019\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6328 - accuracy: 0.6553 - val_loss: 0.5832 - val_accuracy: 0.7019\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6191 - accuracy: 0.6604 - val_loss: 0.5801 - val_accuracy: 0.7179\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5980 - accuracy: 0.6831 - val_loss: 0.5516 - val_accuracy: 0.7212\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5986 - accuracy: 0.6916 - val_loss: 0.5653 - val_accuracy: 0.7404\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5781 - accuracy: 0.7001 - val_loss: 0.5414 - val_accuracy: 0.7244\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5767 - accuracy: 0.7126 - val_loss: 0.5386 - val_accuracy: 0.7308\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5745 - accuracy: 0.7177 - val_loss: 0.5352 - val_accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5694 - accuracy: 0.7069 - val_loss: 0.5809 - val_accuracy: 0.6923\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5655 - accuracy: 0.7200 - val_loss: 0.5390 - val_accuracy: 0.7212\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5638 - accuracy: 0.7228 - val_loss: 0.5465 - val_accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5568 - accuracy: 0.7319 - val_loss: 0.5469 - val_accuracy: 0.6987\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7268 - val_loss: 0.5481 - val_accuracy: 0.7244\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5641 - accuracy: 0.7092 - val_loss: 0.5495 - val_accuracy: 0.7340\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5524 - accuracy: 0.7239 - val_loss: 0.5639 - val_accuracy: 0.6955\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5594 - accuracy: 0.7205 - val_loss: 0.5408 - val_accuracy: 0.6987\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7262 - val_loss: 0.5304 - val_accuracy: 0.7308\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5486 - accuracy: 0.7370 - val_loss: 0.5343 - val_accuracy: 0.7276\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5517 - accuracy: 0.7324 - val_loss: 0.5438 - val_accuracy: 0.7115\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5445 - accuracy: 0.7387 - val_loss: 0.5349 - val_accuracy: 0.7244\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5428 - accuracy: 0.7353 - val_loss: 0.5558 - val_accuracy: 0.7115\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7279 - val_loss: 0.5388 - val_accuracy: 0.7179\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5464 - accuracy: 0.7296 - val_loss: 0.5425 - val_accuracy: 0.7276\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5398 - accuracy: 0.7404 - val_loss: 0.5739 - val_accuracy: 0.7019\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5385 - accuracy: 0.7251 - val_loss: 0.5251 - val_accuracy: 0.7404\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5393 - accuracy: 0.7290 - val_loss: 0.5265 - val_accuracy: 0.7372\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5364 - accuracy: 0.7387 - val_loss: 0.5595 - val_accuracy: 0.7179\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5453 - accuracy: 0.7245 - val_loss: 0.5538 - val_accuracy: 0.6731\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5349 - accuracy: 0.7370 - val_loss: 0.5357 - val_accuracy: 0.7404\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5367 - accuracy: 0.7370 - val_loss: 0.5328 - val_accuracy: 0.7276\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7370 - val_loss: 0.5449 - val_accuracy: 0.7404\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5388 - accuracy: 0.7398 - val_loss: 0.5581 - val_accuracy: 0.7147\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5311 - accuracy: 0.7483 - val_loss: 0.5465 - val_accuracy: 0.7372\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5360 - accuracy: 0.7404 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5317 - accuracy: 0.7387 - val_loss: 0.5348 - val_accuracy: 0.7276\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.7398 - val_loss: 0.5345 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7523 - val_loss: 0.5306 - val_accuracy: 0.7468\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5231 - accuracy: 0.7489 - val_loss: 0.5490 - val_accuracy: 0.7404\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5340 - accuracy: 0.7483 - val_loss: 0.5410 - val_accuracy: 0.7244\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5234 - accuracy: 0.7523 - val_loss: 0.5617 - val_accuracy: 0.7212\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7500 - val_loss: 0.5308 - val_accuracy: 0.7340\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5220 - accuracy: 0.7517 - val_loss: 0.5326 - val_accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5194 - accuracy: 0.7472 - val_loss: 0.5418 - val_accuracy: 0.7436\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5258 - accuracy: 0.7534 - val_loss: 0.5390 - val_accuracy: 0.7372\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5282 - accuracy: 0.7409 - val_loss: 0.5357 - val_accuracy: 0.7372\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.7358 - val_loss: 0.5327 - val_accuracy: 0.7404\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5112 - accuracy: 0.7517 - val_loss: 0.5434 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5157 - accuracy: 0.7489 - val_loss: 0.5395 - val_accuracy: 0.7436\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5134 - accuracy: 0.7608 - val_loss: 0.5460 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5161 - accuracy: 0.7568 - val_loss: 0.5390 - val_accuracy: 0.7436\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7307692307692307\n",
            "Accuracy: 0.7307692307692307\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6364 - accuracy: 0.6689 - val_loss: 0.6465 - val_accuracy: 0.6250\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6200 - accuracy: 0.6723 - val_loss: 0.6391 - val_accuracy: 0.6250\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6075 - accuracy: 0.6712 - val_loss: 0.6360 - val_accuracy: 0.6378\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5983 - accuracy: 0.6831 - val_loss: 0.6134 - val_accuracy: 0.6731\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5846 - accuracy: 0.6859 - val_loss: 0.6102 - val_accuracy: 0.6763\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5744 - accuracy: 0.7058 - val_loss: 0.5902 - val_accuracy: 0.6859\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5665 - accuracy: 0.7160 - val_loss: 0.5953 - val_accuracy: 0.6827\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5603 - accuracy: 0.7234 - val_loss: 0.5773 - val_accuracy: 0.7019\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5565 - accuracy: 0.7222 - val_loss: 0.5879 - val_accuracy: 0.6763\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5637 - accuracy: 0.7200 - val_loss: 0.6141 - val_accuracy: 0.6603\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5538 - accuracy: 0.7290 - val_loss: 0.5846 - val_accuracy: 0.6699\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5493 - accuracy: 0.7353 - val_loss: 0.5834 - val_accuracy: 0.6667\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5567 - accuracy: 0.7154 - val_loss: 0.6020 - val_accuracy: 0.7051\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5509 - accuracy: 0.7217 - val_loss: 0.5754 - val_accuracy: 0.6859\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5549 - accuracy: 0.7205 - val_loss: 0.5784 - val_accuracy: 0.7019\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5450 - accuracy: 0.7200 - val_loss: 0.5907 - val_accuracy: 0.6667\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5505 - accuracy: 0.7313 - val_loss: 0.5716 - val_accuracy: 0.6795\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5389 - accuracy: 0.7398 - val_loss: 0.6029 - val_accuracy: 0.7019\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5512 - accuracy: 0.7228 - val_loss: 0.5718 - val_accuracy: 0.6955\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5456 - accuracy: 0.7353 - val_loss: 0.5679 - val_accuracy: 0.7019\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5408 - accuracy: 0.7341 - val_loss: 0.5705 - val_accuracy: 0.6955\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7404 - val_loss: 0.5804 - val_accuracy: 0.6955\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5351 - accuracy: 0.7449 - val_loss: 0.5897 - val_accuracy: 0.6923\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7279 - val_loss: 0.5702 - val_accuracy: 0.6827\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5473 - accuracy: 0.7177 - val_loss: 0.5791 - val_accuracy: 0.7019\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5338 - accuracy: 0.7330 - val_loss: 0.5758 - val_accuracy: 0.7019\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5285 - accuracy: 0.7483 - val_loss: 0.5646 - val_accuracy: 0.6987\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5379 - accuracy: 0.7296 - val_loss: 0.6126 - val_accuracy: 0.6923\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5367 - accuracy: 0.7494 - val_loss: 0.5626 - val_accuracy: 0.7115\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7477 - val_loss: 0.5612 - val_accuracy: 0.6923\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.7432 - val_loss: 0.5767 - val_accuracy: 0.6891\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7477 - val_loss: 0.5789 - val_accuracy: 0.6891\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5310 - accuracy: 0.7506 - val_loss: 0.5670 - val_accuracy: 0.6987\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.7381 - val_loss: 0.5661 - val_accuracy: 0.6987\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5210 - accuracy: 0.7477 - val_loss: 0.5844 - val_accuracy: 0.6955\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5254 - accuracy: 0.7562 - val_loss: 0.5976 - val_accuracy: 0.6891\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5276 - accuracy: 0.7443 - val_loss: 0.5562 - val_accuracy: 0.7083\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5202 - accuracy: 0.7523 - val_loss: 0.5554 - val_accuracy: 0.6923\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5226 - accuracy: 0.7500 - val_loss: 0.5619 - val_accuracy: 0.6923\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7523 - val_loss: 0.5644 - val_accuracy: 0.6955\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5176 - accuracy: 0.7540 - val_loss: 0.5755 - val_accuracy: 0.6923\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5291 - accuracy: 0.7500 - val_loss: 0.5670 - val_accuracy: 0.6955\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5202 - accuracy: 0.7477 - val_loss: 0.5569 - val_accuracy: 0.7179\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5313 - accuracy: 0.7347 - val_loss: 0.5679 - val_accuracy: 0.7083\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5180 - accuracy: 0.7438 - val_loss: 0.5678 - val_accuracy: 0.6955\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5124 - accuracy: 0.7489 - val_loss: 0.5566 - val_accuracy: 0.6987\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5166 - accuracy: 0.7574 - val_loss: 0.5646 - val_accuracy: 0.6923\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5102 - accuracy: 0.7568 - val_loss: 0.5764 - val_accuracy: 0.7019\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5148 - accuracy: 0.7585 - val_loss: 0.5715 - val_accuracy: 0.7051\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5185 - accuracy: 0.7528 - val_loss: 0.5757 - val_accuracy: 0.6891\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7230769230769231\n",
            "Accuracy: 0.7230769230769231\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 10ms/step - loss: 0.6357 - accuracy: 0.6621 - val_loss: 0.6207 - val_accuracy: 0.6955\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6217 - accuracy: 0.6576 - val_loss: 0.5891 - val_accuracy: 0.6795\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6048 - accuracy: 0.6752 - val_loss: 0.6092 - val_accuracy: 0.7051\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6121 - accuracy: 0.6610 - val_loss: 0.5660 - val_accuracy: 0.7179\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5981 - accuracy: 0.6808 - val_loss: 0.5685 - val_accuracy: 0.7244\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5840 - accuracy: 0.6848 - val_loss: 0.5937 - val_accuracy: 0.6603\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5824 - accuracy: 0.6956 - val_loss: 0.5449 - val_accuracy: 0.7308\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5850 - accuracy: 0.6944 - val_loss: 0.5974 - val_accuracy: 0.6538\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5787 - accuracy: 0.6984 - val_loss: 0.5431 - val_accuracy: 0.7244\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5757 - accuracy: 0.7046 - val_loss: 0.5662 - val_accuracy: 0.6987\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5740 - accuracy: 0.7041 - val_loss: 0.5533 - val_accuracy: 0.7340\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5759 - accuracy: 0.7052 - val_loss: 0.5818 - val_accuracy: 0.6827\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5679 - accuracy: 0.7075 - val_loss: 0.5405 - val_accuracy: 0.7404\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5642 - accuracy: 0.7103 - val_loss: 0.5551 - val_accuracy: 0.7083\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5622 - accuracy: 0.7092 - val_loss: 0.5421 - val_accuracy: 0.7308\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5687 - accuracy: 0.7075 - val_loss: 0.5512 - val_accuracy: 0.7308\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5586 - accuracy: 0.7188 - val_loss: 0.5369 - val_accuracy: 0.7436\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5606 - accuracy: 0.7177 - val_loss: 0.5394 - val_accuracy: 0.7083\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7171 - val_loss: 0.5460 - val_accuracy: 0.7212\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5618 - accuracy: 0.7273 - val_loss: 0.5358 - val_accuracy: 0.7276\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5600 - accuracy: 0.7007 - val_loss: 0.5424 - val_accuracy: 0.7276\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5495 - accuracy: 0.7234 - val_loss: 0.5375 - val_accuracy: 0.7372\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.7103 - val_loss: 0.5548 - val_accuracy: 0.7147\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5523 - accuracy: 0.7154 - val_loss: 0.5563 - val_accuracy: 0.7308\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5684 - accuracy: 0.7120 - val_loss: 0.5431 - val_accuracy: 0.7179\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5499 - accuracy: 0.7268 - val_loss: 0.5440 - val_accuracy: 0.7051\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5519 - accuracy: 0.7171 - val_loss: 0.5399 - val_accuracy: 0.7276\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5607 - accuracy: 0.7132 - val_loss: 0.5747 - val_accuracy: 0.7115\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.7296 - val_loss: 0.5404 - val_accuracy: 0.7244\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.7166 - val_loss: 0.5639 - val_accuracy: 0.6955\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5448 - accuracy: 0.7256 - val_loss: 0.5524 - val_accuracy: 0.7115\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5424 - accuracy: 0.7245 - val_loss: 0.5695 - val_accuracy: 0.7083\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5370 - accuracy: 0.7364 - val_loss: 0.5588 - val_accuracy: 0.7276\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7262 - val_loss: 0.5480 - val_accuracy: 0.7404\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5419 - accuracy: 0.7239 - val_loss: 0.5599 - val_accuracy: 0.7115\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5367 - accuracy: 0.7341 - val_loss: 0.5404 - val_accuracy: 0.7147\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7364 - val_loss: 0.5638 - val_accuracy: 0.6955\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.7364 - val_loss: 0.5413 - val_accuracy: 0.7115\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5303 - accuracy: 0.7426 - val_loss: 0.5562 - val_accuracy: 0.7179\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5405 - accuracy: 0.7375 - val_loss: 0.5508 - val_accuracy: 0.7276\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5366 - accuracy: 0.7324 - val_loss: 0.5644 - val_accuracy: 0.7404\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5225 - accuracy: 0.7528 - val_loss: 0.5546 - val_accuracy: 0.7179\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.7404 - val_loss: 0.5544 - val_accuracy: 0.7276\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5316 - accuracy: 0.7506 - val_loss: 0.5491 - val_accuracy: 0.7147\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5284 - accuracy: 0.7438 - val_loss: 0.5438 - val_accuracy: 0.7372\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5299 - accuracy: 0.7347 - val_loss: 0.5542 - val_accuracy: 0.7308\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5316 - accuracy: 0.7449 - val_loss: 0.5705 - val_accuracy: 0.6891\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5341 - accuracy: 0.7398 - val_loss: 0.5381 - val_accuracy: 0.7244\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5246 - accuracy: 0.7375 - val_loss: 0.5423 - val_accuracy: 0.7212\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5199 - accuracy: 0.7472 - val_loss: 0.5569 - val_accuracy: 0.7340\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7230769230769231\n",
            "Accuracy: 0.7230769230769231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6357 - accuracy: 0.6655 - val_loss: 0.6396 - val_accuracy: 0.6442\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6219 - accuracy: 0.6616 - val_loss: 0.6321 - val_accuracy: 0.6442\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6151 - accuracy: 0.6599 - val_loss: 0.6166 - val_accuracy: 0.6859\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5899 - accuracy: 0.7001 - val_loss: 0.5944 - val_accuracy: 0.6891\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5789 - accuracy: 0.6967 - val_loss: 0.5823 - val_accuracy: 0.7019\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5785 - accuracy: 0.7007 - val_loss: 0.5753 - val_accuracy: 0.7019\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5802 - accuracy: 0.7143 - val_loss: 0.5672 - val_accuracy: 0.7115\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5693 - accuracy: 0.7177 - val_loss: 0.5716 - val_accuracy: 0.7083\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5561 - accuracy: 0.7307 - val_loss: 0.6023 - val_accuracy: 0.6795\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5741 - accuracy: 0.7149 - val_loss: 0.5899 - val_accuracy: 0.6891\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5604 - accuracy: 0.7279 - val_loss: 0.5897 - val_accuracy: 0.6827\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5658 - accuracy: 0.7103 - val_loss: 0.5562 - val_accuracy: 0.7212\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5556 - accuracy: 0.7285 - val_loss: 0.5528 - val_accuracy: 0.7147\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5636 - accuracy: 0.7341 - val_loss: 0.5668 - val_accuracy: 0.7276\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5587 - accuracy: 0.7217 - val_loss: 0.5702 - val_accuracy: 0.6827\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5593 - accuracy: 0.7239 - val_loss: 0.5880 - val_accuracy: 0.6795\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5444 - accuracy: 0.7438 - val_loss: 0.5518 - val_accuracy: 0.7276\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7279 - val_loss: 0.5541 - val_accuracy: 0.7083\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5602 - accuracy: 0.7126 - val_loss: 0.5927 - val_accuracy: 0.6987\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5481 - accuracy: 0.7319 - val_loss: 0.5436 - val_accuracy: 0.7308\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5442 - accuracy: 0.7347 - val_loss: 0.5496 - val_accuracy: 0.7212\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5448 - accuracy: 0.7347 - val_loss: 0.5656 - val_accuracy: 0.7083\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5440 - accuracy: 0.7438 - val_loss: 0.5535 - val_accuracy: 0.7340\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5387 - accuracy: 0.7421 - val_loss: 0.5515 - val_accuracy: 0.7308\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5401 - accuracy: 0.7330 - val_loss: 0.5466 - val_accuracy: 0.7276\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5290 - accuracy: 0.7353 - val_loss: 0.5738 - val_accuracy: 0.7276\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5441 - accuracy: 0.7290 - val_loss: 0.5507 - val_accuracy: 0.7179\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5341 - accuracy: 0.7364 - val_loss: 0.5424 - val_accuracy: 0.7083\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5393 - accuracy: 0.7432 - val_loss: 0.5574 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5373 - accuracy: 0.7347 - val_loss: 0.5467 - val_accuracy: 0.7179\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5377 - accuracy: 0.7353 - val_loss: 0.5745 - val_accuracy: 0.7115\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5324 - accuracy: 0.7455 - val_loss: 0.5460 - val_accuracy: 0.7083\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5310 - accuracy: 0.7285 - val_loss: 0.5558 - val_accuracy: 0.7212\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5284 - accuracy: 0.7375 - val_loss: 0.5451 - val_accuracy: 0.7212\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5294 - accuracy: 0.7409 - val_loss: 0.5654 - val_accuracy: 0.7115\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5233 - accuracy: 0.7404 - val_loss: 0.5414 - val_accuracy: 0.7372\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7387 - val_loss: 0.5640 - val_accuracy: 0.7276\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5303 - accuracy: 0.7477 - val_loss: 0.5398 - val_accuracy: 0.7244\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7585 - val_loss: 0.5427 - val_accuracy: 0.7308\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5205 - accuracy: 0.7506 - val_loss: 0.5461 - val_accuracy: 0.7244\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5198 - accuracy: 0.7568 - val_loss: 0.5453 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5247 - accuracy: 0.7438 - val_loss: 0.6120 - val_accuracy: 0.7147\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5202 - accuracy: 0.7551 - val_loss: 0.5546 - val_accuracy: 0.7244\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5163 - accuracy: 0.7545 - val_loss: 0.5868 - val_accuracy: 0.6987\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5189 - accuracy: 0.7574 - val_loss: 0.5663 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5122 - accuracy: 0.7608 - val_loss: 0.5478 - val_accuracy: 0.7308\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5225 - accuracy: 0.7540 - val_loss: 0.5954 - val_accuracy: 0.7372\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5161 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.7019\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.7562 - val_loss: 0.5534 - val_accuracy: 0.7340\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.7579 - val_loss: 0.5812 - val_accuracy: 0.7244\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7\n",
            "Accuracy: 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 10ms/step - loss: 0.6460 - accuracy: 0.6446 - val_loss: 0.6354 - val_accuracy: 0.6699\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6314 - accuracy: 0.6451 - val_loss: 0.5902 - val_accuracy: 0.7147\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6130 - accuracy: 0.6706 - val_loss: 0.5966 - val_accuracy: 0.6987\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6050 - accuracy: 0.6842 - val_loss: 0.5939 - val_accuracy: 0.6795\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5895 - accuracy: 0.7024 - val_loss: 0.5790 - val_accuracy: 0.7147\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5863 - accuracy: 0.7007 - val_loss: 0.5621 - val_accuracy: 0.7147\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5949 - accuracy: 0.6956 - val_loss: 0.5572 - val_accuracy: 0.7179\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5737 - accuracy: 0.7035 - val_loss: 0.5571 - val_accuracy: 0.7244\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.7052 - val_loss: 0.5559 - val_accuracy: 0.7051\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5700 - accuracy: 0.7149 - val_loss: 0.5712 - val_accuracy: 0.7308\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5699 - accuracy: 0.7069 - val_loss: 0.5480 - val_accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5700 - accuracy: 0.7228 - val_loss: 0.5561 - val_accuracy: 0.7308\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5628 - accuracy: 0.7222 - val_loss: 0.5565 - val_accuracy: 0.7179\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5672 - accuracy: 0.7171 - val_loss: 0.5777 - val_accuracy: 0.7244\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5658 - accuracy: 0.7194 - val_loss: 0.5606 - val_accuracy: 0.7179\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5537 - accuracy: 0.7415 - val_loss: 0.5618 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5686 - accuracy: 0.7228 - val_loss: 0.5444 - val_accuracy: 0.7308\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5569 - accuracy: 0.7239 - val_loss: 0.5642 - val_accuracy: 0.7212\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5564 - accuracy: 0.7239 - val_loss: 0.5543 - val_accuracy: 0.7276\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5554 - accuracy: 0.7171 - val_loss: 0.5836 - val_accuracy: 0.7244\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5607 - accuracy: 0.7256 - val_loss: 0.5542 - val_accuracy: 0.7276\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5488 - accuracy: 0.7319 - val_loss: 0.5583 - val_accuracy: 0.7179\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5471 - accuracy: 0.7381 - val_loss: 0.5629 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5492 - accuracy: 0.7341 - val_loss: 0.5581 - val_accuracy: 0.7244\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5481 - accuracy: 0.7324 - val_loss: 0.5588 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5452 - accuracy: 0.7353 - val_loss: 0.5742 - val_accuracy: 0.7147\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5544 - accuracy: 0.7256 - val_loss: 0.5642 - val_accuracy: 0.7147\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7364 - val_loss: 0.5617 - val_accuracy: 0.7244\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5444 - accuracy: 0.7319 - val_loss: 0.5688 - val_accuracy: 0.7147\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5451 - accuracy: 0.7222 - val_loss: 0.5596 - val_accuracy: 0.7276\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5455 - accuracy: 0.7296 - val_loss: 0.5671 - val_accuracy: 0.7212\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5438 - accuracy: 0.7375 - val_loss: 0.5668 - val_accuracy: 0.7212\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5392 - accuracy: 0.7404 - val_loss: 0.5773 - val_accuracy: 0.7212\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5358 - accuracy: 0.7426 - val_loss: 0.5861 - val_accuracy: 0.6827\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5441 - accuracy: 0.7324 - val_loss: 0.5771 - val_accuracy: 0.7212\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5320 - accuracy: 0.7489 - val_loss: 0.5900 - val_accuracy: 0.7308\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.7432 - val_loss: 0.5729 - val_accuracy: 0.7404\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5450 - accuracy: 0.7398 - val_loss: 0.5838 - val_accuracy: 0.7276\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5496 - accuracy: 0.7307 - val_loss: 0.5761 - val_accuracy: 0.7179\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5363 - accuracy: 0.7460 - val_loss: 0.5933 - val_accuracy: 0.7083\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5367 - accuracy: 0.7370 - val_loss: 0.6062 - val_accuracy: 0.7051\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5339 - accuracy: 0.7330 - val_loss: 0.5741 - val_accuracy: 0.7115\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5380 - accuracy: 0.7415 - val_loss: 0.5702 - val_accuracy: 0.7212\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5322 - accuracy: 0.7511 - val_loss: 0.5876 - val_accuracy: 0.7212\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5254 - accuracy: 0.7472 - val_loss: 0.5988 - val_accuracy: 0.7244\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5395 - accuracy: 0.7409 - val_loss: 0.5902 - val_accuracy: 0.7179\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5209 - accuracy: 0.7568 - val_loss: 0.6059 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5311 - accuracy: 0.7608 - val_loss: 0.6013 - val_accuracy: 0.7147\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5381 - accuracy: 0.7341 - val_loss: 0.5928 - val_accuracy: 0.7179\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5272 - accuracy: 0.7557 - val_loss: 0.6091 - val_accuracy: 0.7212\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7326923076923076\n",
            "Accuracy: 0.7326923076923076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6418 - accuracy: 0.6593 - val_loss: 0.6288 - val_accuracy: 0.6667\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6300 - accuracy: 0.6650 - val_loss: 0.5998 - val_accuracy: 0.6667\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6179 - accuracy: 0.6746 - val_loss: 0.5861 - val_accuracy: 0.6667\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6002 - accuracy: 0.6905 - val_loss: 0.5788 - val_accuracy: 0.7147\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5958 - accuracy: 0.6842 - val_loss: 0.5606 - val_accuracy: 0.6955\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5974 - accuracy: 0.6961 - val_loss: 0.5486 - val_accuracy: 0.7532\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5911 - accuracy: 0.7041 - val_loss: 0.5869 - val_accuracy: 0.7308\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5728 - accuracy: 0.7092 - val_loss: 0.5701 - val_accuracy: 0.7276\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5749 - accuracy: 0.7063 - val_loss: 0.5327 - val_accuracy: 0.7436\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5696 - accuracy: 0.7205 - val_loss: 0.5497 - val_accuracy: 0.7340\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5625 - accuracy: 0.7080 - val_loss: 0.5777 - val_accuracy: 0.7244\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5576 - accuracy: 0.7211 - val_loss: 0.5521 - val_accuracy: 0.7340\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7296 - val_loss: 0.5483 - val_accuracy: 0.6987\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5730 - accuracy: 0.7035 - val_loss: 0.5431 - val_accuracy: 0.7404\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5681 - accuracy: 0.7126 - val_loss: 0.5416 - val_accuracy: 0.7115\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5574 - accuracy: 0.7234 - val_loss: 0.5524 - val_accuracy: 0.7340\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5671 - accuracy: 0.7166 - val_loss: 0.5779 - val_accuracy: 0.7308\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5641 - accuracy: 0.7075 - val_loss: 0.5288 - val_accuracy: 0.7340\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5528 - accuracy: 0.7296 - val_loss: 0.5346 - val_accuracy: 0.7468\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5494 - accuracy: 0.7370 - val_loss: 0.5396 - val_accuracy: 0.7436\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7256 - val_loss: 0.5314 - val_accuracy: 0.7244\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5454 - accuracy: 0.7296 - val_loss: 0.5328 - val_accuracy: 0.7147\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5462 - accuracy: 0.7290 - val_loss: 0.5302 - val_accuracy: 0.7564\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5395 - accuracy: 0.7296 - val_loss: 0.5493 - val_accuracy: 0.7212\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5409 - accuracy: 0.7336 - val_loss: 0.5235 - val_accuracy: 0.7596\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5434 - accuracy: 0.7387 - val_loss: 0.5514 - val_accuracy: 0.7564\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7313 - val_loss: 0.5317 - val_accuracy: 0.7340\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5402 - accuracy: 0.7432 - val_loss: 0.5309 - val_accuracy: 0.7628\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.7336 - val_loss: 0.5465 - val_accuracy: 0.6987\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5348 - accuracy: 0.7432 - val_loss: 0.5484 - val_accuracy: 0.7436\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5337 - accuracy: 0.7477 - val_loss: 0.5192 - val_accuracy: 0.7564\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5339 - accuracy: 0.7443 - val_loss: 0.5657 - val_accuracy: 0.7468\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5385 - accuracy: 0.7381 - val_loss: 0.5473 - val_accuracy: 0.7019\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7540 - val_loss: 0.5313 - val_accuracy: 0.7308\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5291 - accuracy: 0.7443 - val_loss: 0.5202 - val_accuracy: 0.7564\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5335 - accuracy: 0.7432 - val_loss: 0.5332 - val_accuracy: 0.7660\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.7523 - val_loss: 0.5502 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5367 - accuracy: 0.7347 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5321 - accuracy: 0.7415 - val_loss: 0.5196 - val_accuracy: 0.7596\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5321 - accuracy: 0.7302 - val_loss: 0.5596 - val_accuracy: 0.6859\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5397 - accuracy: 0.7398 - val_loss: 0.5496 - val_accuracy: 0.7500\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5199 - accuracy: 0.7574 - val_loss: 0.5382 - val_accuracy: 0.7115\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5349 - accuracy: 0.7483 - val_loss: 0.5509 - val_accuracy: 0.6987\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.7387 - val_loss: 0.5232 - val_accuracy: 0.7564\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.7585 - val_loss: 0.5278 - val_accuracy: 0.7596\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5168 - accuracy: 0.7477 - val_loss: 0.5309 - val_accuracy: 0.7468\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5254 - accuracy: 0.7511 - val_loss: 0.5161 - val_accuracy: 0.7468\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5124 - accuracy: 0.7489 - val_loss: 0.5392 - val_accuracy: 0.7404\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.7591 - val_loss: 0.5329 - val_accuracy: 0.7404\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5112 - accuracy: 0.7636 - val_loss: 0.5665 - val_accuracy: 0.7308\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7115384615384616\n",
            "Accuracy: 0.7115384615384616\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6381 - accuracy: 0.6689 - val_loss: 0.6429 - val_accuracy: 0.6314\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6723 - val_loss: 0.6357 - val_accuracy: 0.6314\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6064 - accuracy: 0.6746 - val_loss: 0.6182 - val_accuracy: 0.6410\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5805 - accuracy: 0.7120 - val_loss: 0.6241 - val_accuracy: 0.6378\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5784 - accuracy: 0.6995 - val_loss: 0.6304 - val_accuracy: 0.6506\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5735 - accuracy: 0.7194 - val_loss: 0.6011 - val_accuracy: 0.6923\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5604 - accuracy: 0.7353 - val_loss: 0.5910 - val_accuracy: 0.7019\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5614 - accuracy: 0.7285 - val_loss: 0.6037 - val_accuracy: 0.6795\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5501 - accuracy: 0.7211 - val_loss: 0.5940 - val_accuracy: 0.6859\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5538 - accuracy: 0.7273 - val_loss: 0.5883 - val_accuracy: 0.6955\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5610 - accuracy: 0.7256 - val_loss: 0.5898 - val_accuracy: 0.6987\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5531 - accuracy: 0.7341 - val_loss: 0.6181 - val_accuracy: 0.6635\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5505 - accuracy: 0.7392 - val_loss: 0.6174 - val_accuracy: 0.6603\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5526 - accuracy: 0.7307 - val_loss: 0.5891 - val_accuracy: 0.6987\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5412 - accuracy: 0.7341 - val_loss: 0.5786 - val_accuracy: 0.7019\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5401 - accuracy: 0.7409 - val_loss: 0.5746 - val_accuracy: 0.7115\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5449 - accuracy: 0.7330 - val_loss: 0.5925 - val_accuracy: 0.7019\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5407 - accuracy: 0.7211 - val_loss: 0.5883 - val_accuracy: 0.6859\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7302 - val_loss: 0.6005 - val_accuracy: 0.6667\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5367 - accuracy: 0.7336 - val_loss: 0.5925 - val_accuracy: 0.7051\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.7443 - val_loss: 0.5838 - val_accuracy: 0.7019\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5409 - accuracy: 0.7426 - val_loss: 0.5782 - val_accuracy: 0.7179\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5321 - accuracy: 0.7477 - val_loss: 0.6125 - val_accuracy: 0.6891\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5352 - accuracy: 0.7404 - val_loss: 0.6222 - val_accuracy: 0.6795\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7290 - val_loss: 0.5905 - val_accuracy: 0.6923\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5295 - accuracy: 0.7421 - val_loss: 0.5752 - val_accuracy: 0.6955\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5315 - accuracy: 0.7483 - val_loss: 0.5794 - val_accuracy: 0.6987\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5281 - accuracy: 0.7494 - val_loss: 0.5903 - val_accuracy: 0.6891\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5234 - accuracy: 0.7472 - val_loss: 0.5821 - val_accuracy: 0.6955\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5331 - accuracy: 0.7353 - val_loss: 0.5796 - val_accuracy: 0.7147\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5203 - accuracy: 0.7494 - val_loss: 0.5829 - val_accuracy: 0.6891\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5296 - accuracy: 0.7404 - val_loss: 0.5841 - val_accuracy: 0.6955\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5263 - accuracy: 0.7404 - val_loss: 0.6362 - val_accuracy: 0.6795\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5225 - accuracy: 0.7506 - val_loss: 0.5803 - val_accuracy: 0.7019\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5231 - accuracy: 0.7477 - val_loss: 0.5802 - val_accuracy: 0.6955\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5228 - accuracy: 0.7494 - val_loss: 0.5780 - val_accuracy: 0.6923\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5167 - accuracy: 0.7528 - val_loss: 0.5782 - val_accuracy: 0.7083\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5213 - accuracy: 0.7432 - val_loss: 0.5849 - val_accuracy: 0.6987\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.7489 - val_loss: 0.5926 - val_accuracy: 0.6859\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5139 - accuracy: 0.7455 - val_loss: 0.5840 - val_accuracy: 0.6987\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5209 - accuracy: 0.7392 - val_loss: 0.5852 - val_accuracy: 0.6891\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5272 - accuracy: 0.7426 - val_loss: 0.5871 - val_accuracy: 0.6763\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5044 - accuracy: 0.7642 - val_loss: 0.6318 - val_accuracy: 0.6891\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5129 - accuracy: 0.7443 - val_loss: 0.6049 - val_accuracy: 0.6731\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5038 - accuracy: 0.7579 - val_loss: 0.5919 - val_accuracy: 0.6667\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5162 - accuracy: 0.7460 - val_loss: 0.5857 - val_accuracy: 0.6955\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5099 - accuracy: 0.7506 - val_loss: 0.5795 - val_accuracy: 0.7051\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5164 - accuracy: 0.7551 - val_loss: 0.5782 - val_accuracy: 0.6987\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5077 - accuracy: 0.7630 - val_loss: 0.5939 - val_accuracy: 0.6923\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5040 - accuracy: 0.7511 - val_loss: 0.5907 - val_accuracy: 0.6859\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7288461538461538\n",
            "Accuracy: 0.7288461538461538\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6367 - accuracy: 0.6627 - val_loss: 0.6060 - val_accuracy: 0.6699\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6190 - accuracy: 0.6616 - val_loss: 0.5893 - val_accuracy: 0.6699\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6046 - accuracy: 0.6706 - val_loss: 0.5810 - val_accuracy: 0.7372\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5922 - accuracy: 0.6990 - val_loss: 0.5602 - val_accuracy: 0.7147\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5749 - accuracy: 0.7035 - val_loss: 0.6377 - val_accuracy: 0.6346\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5789 - accuracy: 0.7058 - val_loss: 0.5593 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5739 - accuracy: 0.7188 - val_loss: 0.5948 - val_accuracy: 0.7340\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5745 - accuracy: 0.7086 - val_loss: 0.6501 - val_accuracy: 0.6603\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5672 - accuracy: 0.7103 - val_loss: 0.5555 - val_accuracy: 0.7212\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5613 - accuracy: 0.7154 - val_loss: 0.5976 - val_accuracy: 0.6667\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5607 - accuracy: 0.7262 - val_loss: 0.5607 - val_accuracy: 0.7212\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5494 - accuracy: 0.7324 - val_loss: 0.5490 - val_accuracy: 0.7340\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5578 - accuracy: 0.7307 - val_loss: 0.5484 - val_accuracy: 0.7115\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5666 - accuracy: 0.7256 - val_loss: 0.5605 - val_accuracy: 0.7179\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5477 - accuracy: 0.7296 - val_loss: 0.5410 - val_accuracy: 0.7083\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5547 - accuracy: 0.7256 - val_loss: 0.5434 - val_accuracy: 0.7340\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5498 - accuracy: 0.7330 - val_loss: 0.5481 - val_accuracy: 0.7340\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5485 - accuracy: 0.7228 - val_loss: 0.5591 - val_accuracy: 0.7115\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7341 - val_loss: 0.5438 - val_accuracy: 0.7276\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5423 - accuracy: 0.7409 - val_loss: 0.5733 - val_accuracy: 0.7147\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5421 - accuracy: 0.7341 - val_loss: 0.5498 - val_accuracy: 0.7212\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5394 - accuracy: 0.7438 - val_loss: 0.5578 - val_accuracy: 0.7147\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5407 - accuracy: 0.7262 - val_loss: 0.5655 - val_accuracy: 0.7244\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.7392 - val_loss: 0.5582 - val_accuracy: 0.7212\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5376 - accuracy: 0.7392 - val_loss: 0.5697 - val_accuracy: 0.7276\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5305 - accuracy: 0.7381 - val_loss: 0.5619 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5327 - accuracy: 0.7426 - val_loss: 0.5647 - val_accuracy: 0.7276\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5285 - accuracy: 0.7426 - val_loss: 0.5556 - val_accuracy: 0.7083\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5203 - accuracy: 0.7540 - val_loss: 0.5393 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5300 - accuracy: 0.7370 - val_loss: 0.5702 - val_accuracy: 0.7404\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5258 - accuracy: 0.7438 - val_loss: 0.6017 - val_accuracy: 0.6923\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.7353 - val_loss: 0.5631 - val_accuracy: 0.7212\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5242 - accuracy: 0.7483 - val_loss: 0.5631 - val_accuracy: 0.7404\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5200 - accuracy: 0.7477 - val_loss: 0.5509 - val_accuracy: 0.7340\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5203 - accuracy: 0.7409 - val_loss: 0.5686 - val_accuracy: 0.7147\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5263 - accuracy: 0.7449 - val_loss: 0.5587 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7545 - val_loss: 0.5707 - val_accuracy: 0.7147\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5194 - accuracy: 0.7540 - val_loss: 0.6051 - val_accuracy: 0.7179\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5221 - accuracy: 0.7489 - val_loss: 0.5604 - val_accuracy: 0.7372\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5239 - accuracy: 0.7415 - val_loss: 0.5685 - val_accuracy: 0.7147\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5348 - accuracy: 0.7466 - val_loss: 0.5627 - val_accuracy: 0.7244\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5165 - accuracy: 0.7494 - val_loss: 0.5735 - val_accuracy: 0.7179\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5374 - accuracy: 0.7381 - val_loss: 0.6061 - val_accuracy: 0.7212\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5228 - accuracy: 0.7455 - val_loss: 0.5944 - val_accuracy: 0.7051\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5179 - accuracy: 0.7511 - val_loss: 0.5537 - val_accuracy: 0.7340\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5101 - accuracy: 0.7602 - val_loss: 0.5719 - val_accuracy: 0.7276\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5089 - accuracy: 0.7500 - val_loss: 0.5589 - val_accuracy: 0.7147\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5046 - accuracy: 0.7619 - val_loss: 0.6158 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5162 - accuracy: 0.7511 - val_loss: 0.5734 - val_accuracy: 0.7147\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5075 - accuracy: 0.7568 - val_loss: 0.5800 - val_accuracy: 0.7212\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7307692307692307\n",
            "Accuracy: 0.7307692307692307\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 0.6343 - accuracy: 0.6559 - val_loss: 0.6130 - val_accuracy: 0.6795\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6260 - accuracy: 0.6644 - val_loss: 0.5980 - val_accuracy: 0.6795\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6109 - accuracy: 0.6712 - val_loss: 0.6077 - val_accuracy: 0.6891\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6061 - accuracy: 0.6757 - val_loss: 0.5960 - val_accuracy: 0.7147\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5900 - accuracy: 0.6956 - val_loss: 0.5652 - val_accuracy: 0.6987\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5879 - accuracy: 0.6939 - val_loss: 0.5579 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5845 - accuracy: 0.6950 - val_loss: 0.5666 - val_accuracy: 0.6859\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5764 - accuracy: 0.7041 - val_loss: 0.5600 - val_accuracy: 0.6923\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5736 - accuracy: 0.7149 - val_loss: 0.5569 - val_accuracy: 0.7212\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5635 - accuracy: 0.7234 - val_loss: 0.5454 - val_accuracy: 0.7404\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5624 - accuracy: 0.7171 - val_loss: 0.5490 - val_accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5653 - accuracy: 0.7256 - val_loss: 0.5702 - val_accuracy: 0.6699\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5631 - accuracy: 0.7177 - val_loss: 0.5436 - val_accuracy: 0.7340\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5630 - accuracy: 0.7217 - val_loss: 0.5835 - val_accuracy: 0.7115\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5630 - accuracy: 0.7262 - val_loss: 0.5449 - val_accuracy: 0.7244\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5554 - accuracy: 0.7256 - val_loss: 0.5408 - val_accuracy: 0.7212\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5529 - accuracy: 0.7375 - val_loss: 0.5407 - val_accuracy: 0.7468\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5603 - accuracy: 0.7200 - val_loss: 0.5436 - val_accuracy: 0.7179\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5465 - accuracy: 0.7375 - val_loss: 0.5464 - val_accuracy: 0.7212\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7251 - val_loss: 0.5458 - val_accuracy: 0.7083\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.7341 - val_loss: 0.5484 - val_accuracy: 0.7404\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5533 - accuracy: 0.7358 - val_loss: 0.5618 - val_accuracy: 0.6859\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5466 - accuracy: 0.7381 - val_loss: 0.5543 - val_accuracy: 0.7147\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5447 - accuracy: 0.7477 - val_loss: 0.5480 - val_accuracy: 0.7212\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5498 - accuracy: 0.7279 - val_loss: 0.5455 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5485 - accuracy: 0.7353 - val_loss: 0.5506 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.7358 - val_loss: 0.5483 - val_accuracy: 0.7244\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7489 - val_loss: 0.5462 - val_accuracy: 0.7115\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5392 - accuracy: 0.7358 - val_loss: 0.5407 - val_accuracy: 0.7244\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5377 - accuracy: 0.7404 - val_loss: 0.5375 - val_accuracy: 0.7436\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5429 - accuracy: 0.7381 - val_loss: 0.5412 - val_accuracy: 0.7340\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5406 - accuracy: 0.7279 - val_loss: 0.5535 - val_accuracy: 0.6859\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5390 - accuracy: 0.7438 - val_loss: 0.5436 - val_accuracy: 0.7308\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5303 - accuracy: 0.7307 - val_loss: 0.5428 - val_accuracy: 0.7244\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5341 - accuracy: 0.7398 - val_loss: 0.5695 - val_accuracy: 0.6827\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5289 - accuracy: 0.7370 - val_loss: 0.5640 - val_accuracy: 0.7372\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5332 - accuracy: 0.7466 - val_loss: 0.5413 - val_accuracy: 0.7340\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5352 - accuracy: 0.7460 - val_loss: 0.5389 - val_accuracy: 0.7244\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5273 - accuracy: 0.7523 - val_loss: 0.5459 - val_accuracy: 0.7340\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5297 - accuracy: 0.7398 - val_loss: 0.5401 - val_accuracy: 0.7372\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5268 - accuracy: 0.7483 - val_loss: 0.5556 - val_accuracy: 0.7276\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5313 - accuracy: 0.7421 - val_loss: 0.5421 - val_accuracy: 0.7244\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5301 - accuracy: 0.7455 - val_loss: 0.5524 - val_accuracy: 0.7276\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7489 - val_loss: 0.5431 - val_accuracy: 0.7372\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5247 - accuracy: 0.7472 - val_loss: 0.5501 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.7483 - val_loss: 0.5666 - val_accuracy: 0.7051\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5209 - accuracy: 0.7466 - val_loss: 0.5671 - val_accuracy: 0.7083\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7483 - val_loss: 0.5474 - val_accuracy: 0.7340\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7370 - val_loss: 0.5541 - val_accuracy: 0.7276\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.7517 - val_loss: 0.5431 - val_accuracy: 0.7212\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7096153846153846\n",
            "Accuracy: 0.7096153846153846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6295 - accuracy: 0.6701 - val_loss: 0.6328 - val_accuracy: 0.6346\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6160 - accuracy: 0.6769 - val_loss: 0.6280 - val_accuracy: 0.6346\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6081 - accuracy: 0.6763 - val_loss: 0.6152 - val_accuracy: 0.6346\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6051 - accuracy: 0.6763 - val_loss: 0.6018 - val_accuracy: 0.6346\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5855 - accuracy: 0.6723 - val_loss: 0.5871 - val_accuracy: 0.6795\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5731 - accuracy: 0.7029 - val_loss: 0.5814 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5781 - accuracy: 0.6967 - val_loss: 0.5666 - val_accuracy: 0.7083\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5765 - accuracy: 0.7092 - val_loss: 0.5653 - val_accuracy: 0.7308\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5661 - accuracy: 0.7086 - val_loss: 0.5713 - val_accuracy: 0.7276\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.7251 - val_loss: 0.5604 - val_accuracy: 0.7308\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5658 - accuracy: 0.7171 - val_loss: 0.5707 - val_accuracy: 0.6955\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5535 - accuracy: 0.7313 - val_loss: 0.5668 - val_accuracy: 0.7372\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5549 - accuracy: 0.7183 - val_loss: 0.5659 - val_accuracy: 0.7308\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5525 - accuracy: 0.7160 - val_loss: 0.5555 - val_accuracy: 0.7340\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5541 - accuracy: 0.7245 - val_loss: 0.5600 - val_accuracy: 0.6955\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5441 - accuracy: 0.7296 - val_loss: 0.5753 - val_accuracy: 0.7083\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5468 - accuracy: 0.7296 - val_loss: 0.5559 - val_accuracy: 0.7308\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5362 - accuracy: 0.7443 - val_loss: 0.5601 - val_accuracy: 0.7019\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.7466 - val_loss: 0.5523 - val_accuracy: 0.7212\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.7245 - val_loss: 0.5580 - val_accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5389 - accuracy: 0.7415 - val_loss: 0.5590 - val_accuracy: 0.6763\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5315 - accuracy: 0.7472 - val_loss: 0.5567 - val_accuracy: 0.6891\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.7426 - val_loss: 0.5565 - val_accuracy: 0.7276\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5437 - accuracy: 0.7443 - val_loss: 0.5727 - val_accuracy: 0.7147\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5343 - accuracy: 0.7330 - val_loss: 0.5609 - val_accuracy: 0.6955\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5264 - accuracy: 0.7370 - val_loss: 0.5494 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5259 - accuracy: 0.7455 - val_loss: 0.5444 - val_accuracy: 0.7308\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5260 - accuracy: 0.7438 - val_loss: 0.5668 - val_accuracy: 0.6891\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5243 - accuracy: 0.7545 - val_loss: 0.5511 - val_accuracy: 0.7308\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5259 - accuracy: 0.7415 - val_loss: 0.5413 - val_accuracy: 0.7340\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5245 - accuracy: 0.7557 - val_loss: 0.5496 - val_accuracy: 0.7212\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5209 - accuracy: 0.7528 - val_loss: 0.5477 - val_accuracy: 0.7244\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5189 - accuracy: 0.7545 - val_loss: 0.5650 - val_accuracy: 0.7115\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5170 - accuracy: 0.7500 - val_loss: 0.5512 - val_accuracy: 0.7179\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.7426 - val_loss: 0.5754 - val_accuracy: 0.7244\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5198 - accuracy: 0.7477 - val_loss: 0.5505 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5157 - accuracy: 0.7528 - val_loss: 0.5538 - val_accuracy: 0.7115\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5117 - accuracy: 0.7557 - val_loss: 0.5495 - val_accuracy: 0.7404\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5211 - accuracy: 0.7392 - val_loss: 0.5622 - val_accuracy: 0.7212\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5111 - accuracy: 0.7483 - val_loss: 0.5640 - val_accuracy: 0.7019\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7477 - val_loss: 0.5542 - val_accuracy: 0.6891\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5093 - accuracy: 0.7494 - val_loss: 0.5524 - val_accuracy: 0.7212\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5124 - accuracy: 0.7528 - val_loss: 0.5565 - val_accuracy: 0.7340\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5119 - accuracy: 0.7506 - val_loss: 0.5671 - val_accuracy: 0.7115\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5072 - accuracy: 0.7596 - val_loss: 0.5873 - val_accuracy: 0.7083\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5132 - accuracy: 0.7602 - val_loss: 0.5633 - val_accuracy: 0.7147\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4995 - accuracy: 0.7625 - val_loss: 0.5539 - val_accuracy: 0.7404\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5105 - accuracy: 0.7489 - val_loss: 0.5564 - val_accuracy: 0.7340\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5051 - accuracy: 0.7636 - val_loss: 0.5741 - val_accuracy: 0.7019\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5043 - accuracy: 0.7528 - val_loss: 0.5908 - val_accuracy: 0.6955\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6942307692307692\n",
            "Accuracy: 0.6942307692307692\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6485 - val_loss: 0.6551 - val_accuracy: 0.7083\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6414 - accuracy: 0.6525 - val_loss: 0.6071 - val_accuracy: 0.7083\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6226 - accuracy: 0.6531 - val_loss: 0.6196 - val_accuracy: 0.7083\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6052 - accuracy: 0.6633 - val_loss: 0.6030 - val_accuracy: 0.6346\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5935 - accuracy: 0.6848 - val_loss: 0.6196 - val_accuracy: 0.5962\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5880 - accuracy: 0.6893 - val_loss: 0.5947 - val_accuracy: 0.6346\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5750 - accuracy: 0.6995 - val_loss: 0.5512 - val_accuracy: 0.7340\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5726 - accuracy: 0.7154 - val_loss: 0.5886 - val_accuracy: 0.6603\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5699 - accuracy: 0.7052 - val_loss: 0.5467 - val_accuracy: 0.7276\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5670 - accuracy: 0.7103 - val_loss: 0.5458 - val_accuracy: 0.7244\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5631 - accuracy: 0.7171 - val_loss: 0.6376 - val_accuracy: 0.6282\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5685 - accuracy: 0.7012 - val_loss: 0.5408 - val_accuracy: 0.7596\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5552 - accuracy: 0.7183 - val_loss: 0.5587 - val_accuracy: 0.7436\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5496 - accuracy: 0.7228 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5503 - accuracy: 0.7211 - val_loss: 0.5530 - val_accuracy: 0.7115\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5458 - accuracy: 0.7268 - val_loss: 0.5320 - val_accuracy: 0.7724\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.7126 - val_loss: 0.5630 - val_accuracy: 0.6987\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5507 - accuracy: 0.7143 - val_loss: 0.5942 - val_accuracy: 0.6635\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5497 - accuracy: 0.7279 - val_loss: 0.5857 - val_accuracy: 0.6571\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5532 - accuracy: 0.7273 - val_loss: 0.5569 - val_accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5381 - accuracy: 0.7392 - val_loss: 0.6056 - val_accuracy: 0.6474\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5394 - accuracy: 0.7302 - val_loss: 0.5545 - val_accuracy: 0.7019\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5363 - accuracy: 0.7336 - val_loss: 0.5531 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7341 - val_loss: 0.5490 - val_accuracy: 0.7147\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5395 - accuracy: 0.7239 - val_loss: 0.5686 - val_accuracy: 0.6763\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5323 - accuracy: 0.7358 - val_loss: 0.5451 - val_accuracy: 0.7340\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5346 - accuracy: 0.7404 - val_loss: 0.5368 - val_accuracy: 0.7468\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5383 - accuracy: 0.7330 - val_loss: 0.5522 - val_accuracy: 0.7340\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5380 - accuracy: 0.7290 - val_loss: 0.5479 - val_accuracy: 0.7404\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5362 - accuracy: 0.7313 - val_loss: 0.5813 - val_accuracy: 0.6987\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7460 - val_loss: 0.5497 - val_accuracy: 0.7468\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5234 - accuracy: 0.7398 - val_loss: 0.5546 - val_accuracy: 0.7340\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.7364 - val_loss: 0.5523 - val_accuracy: 0.7692\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.7336 - val_loss: 0.5928 - val_accuracy: 0.6603\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7217 - val_loss: 0.5481 - val_accuracy: 0.7468\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5234 - accuracy: 0.7387 - val_loss: 0.5424 - val_accuracy: 0.7596\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5313 - accuracy: 0.7381 - val_loss: 0.5528 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5276 - accuracy: 0.7392 - val_loss: 0.5517 - val_accuracy: 0.7372\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5282 - accuracy: 0.7392 - val_loss: 0.5466 - val_accuracy: 0.7564\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5160 - accuracy: 0.7381 - val_loss: 0.5649 - val_accuracy: 0.7404\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5274 - accuracy: 0.7364 - val_loss: 0.5544 - val_accuracy: 0.7468\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5221 - accuracy: 0.7438 - val_loss: 0.5669 - val_accuracy: 0.7628\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.7421 - val_loss: 0.5722 - val_accuracy: 0.6923\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5145 - accuracy: 0.7523 - val_loss: 0.5887 - val_accuracy: 0.7340\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5161 - accuracy: 0.7477 - val_loss: 0.6069 - val_accuracy: 0.6699\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5237 - accuracy: 0.7409 - val_loss: 0.5670 - val_accuracy: 0.7468\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5206 - accuracy: 0.7489 - val_loss: 0.5876 - val_accuracy: 0.6827\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5181 - accuracy: 0.7449 - val_loss: 0.5478 - val_accuracy: 0.7500\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5066 - accuracy: 0.7557 - val_loss: 0.5766 - val_accuracy: 0.7372\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.7562 - val_loss: 0.6087 - val_accuracy: 0.6763\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6961538461538461\n",
            "Accuracy: 0.6961538461538461\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 12ms/step - loss: 0.6420 - accuracy: 0.6587 - val_loss: 0.6026 - val_accuracy: 0.6923\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6315 - accuracy: 0.6570 - val_loss: 0.6181 - val_accuracy: 0.6923\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6258 - accuracy: 0.6542 - val_loss: 0.6180 - val_accuracy: 0.6923\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6156 - accuracy: 0.6712 - val_loss: 0.5761 - val_accuracy: 0.7147\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5988 - accuracy: 0.6820 - val_loss: 0.5809 - val_accuracy: 0.6987\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5949 - accuracy: 0.6865 - val_loss: 0.5927 - val_accuracy: 0.6891\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5902 - accuracy: 0.6961 - val_loss: 0.5590 - val_accuracy: 0.7179\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5842 - accuracy: 0.7086 - val_loss: 0.5385 - val_accuracy: 0.7404\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5786 - accuracy: 0.7041 - val_loss: 0.5642 - val_accuracy: 0.7404\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5699 - accuracy: 0.7132 - val_loss: 0.5532 - val_accuracy: 0.7276\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5763 - accuracy: 0.7024 - val_loss: 0.5667 - val_accuracy: 0.6987\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5762 - accuracy: 0.7154 - val_loss: 0.5587 - val_accuracy: 0.7019\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5603 - accuracy: 0.7211 - val_loss: 0.5516 - val_accuracy: 0.7372\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5599 - accuracy: 0.7234 - val_loss: 0.5588 - val_accuracy: 0.7404\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5637 - accuracy: 0.7302 - val_loss: 0.5600 - val_accuracy: 0.7179\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5479 - accuracy: 0.7211 - val_loss: 0.5600 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5569 - accuracy: 0.7245 - val_loss: 0.5403 - val_accuracy: 0.7276\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5520 - accuracy: 0.7347 - val_loss: 0.5549 - val_accuracy: 0.7212\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5534 - accuracy: 0.7364 - val_loss: 0.5384 - val_accuracy: 0.7244\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5485 - accuracy: 0.7358 - val_loss: 0.5407 - val_accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5519 - accuracy: 0.7341 - val_loss: 0.5824 - val_accuracy: 0.6827\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5461 - accuracy: 0.7239 - val_loss: 0.5359 - val_accuracy: 0.7179\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5487 - accuracy: 0.7251 - val_loss: 0.5602 - val_accuracy: 0.7244\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5464 - accuracy: 0.7324 - val_loss: 0.5561 - val_accuracy: 0.7372\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5453 - accuracy: 0.7426 - val_loss: 0.5503 - val_accuracy: 0.7404\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7426 - val_loss: 0.5413 - val_accuracy: 0.7404\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5424 - accuracy: 0.7375 - val_loss: 0.5694 - val_accuracy: 0.7083\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5407 - accuracy: 0.7370 - val_loss: 0.5441 - val_accuracy: 0.7340\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.7438 - val_loss: 0.5526 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5358 - accuracy: 0.7455 - val_loss: 0.5653 - val_accuracy: 0.7404\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5389 - accuracy: 0.7353 - val_loss: 0.5467 - val_accuracy: 0.7340\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5368 - accuracy: 0.7483 - val_loss: 0.5637 - val_accuracy: 0.7244\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.7370 - val_loss: 0.5523 - val_accuracy: 0.7244\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.7426 - val_loss: 0.5528 - val_accuracy: 0.7372\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5395 - accuracy: 0.7398 - val_loss: 0.5610 - val_accuracy: 0.7244\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7415 - val_loss: 0.5542 - val_accuracy: 0.7244\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5292 - accuracy: 0.7494 - val_loss: 0.5734 - val_accuracy: 0.7404\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7460 - val_loss: 0.5662 - val_accuracy: 0.7276\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7358 - val_loss: 0.5948 - val_accuracy: 0.6955\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7404 - val_loss: 0.5588 - val_accuracy: 0.7372\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7477 - val_loss: 0.5850 - val_accuracy: 0.7404\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5260 - accuracy: 0.7528 - val_loss: 0.5708 - val_accuracy: 0.7436\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7455 - val_loss: 0.5913 - val_accuracy: 0.7212\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5178 - accuracy: 0.7557 - val_loss: 0.5848 - val_accuracy: 0.7372\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5261 - accuracy: 0.7489 - val_loss: 0.6555 - val_accuracy: 0.7244\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5229 - accuracy: 0.7511 - val_loss: 0.6533 - val_accuracy: 0.7372\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5249 - accuracy: 0.7551 - val_loss: 0.5922 - val_accuracy: 0.7340\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5262 - accuracy: 0.7568 - val_loss: 0.6681 - val_accuracy: 0.7212\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5150 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5160 - accuracy: 0.7528 - val_loss: 0.6012 - val_accuracy: 0.7276\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7192307692307692\n",
            "Accuracy: 0.7192307692307692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6274 - accuracy: 0.6672 - val_loss: 0.6248 - val_accuracy: 0.6474\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6111 - accuracy: 0.6752 - val_loss: 0.6000 - val_accuracy: 0.6474\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6092 - accuracy: 0.6746 - val_loss: 0.5968 - val_accuracy: 0.6474\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.6842 - val_loss: 0.5626 - val_accuracy: 0.7372\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5749 - accuracy: 0.7200 - val_loss: 0.5420 - val_accuracy: 0.7404\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5797 - accuracy: 0.7052 - val_loss: 0.5489 - val_accuracy: 0.7468\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5738 - accuracy: 0.7171 - val_loss: 0.5419 - val_accuracy: 0.7372\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5701 - accuracy: 0.7160 - val_loss: 0.5430 - val_accuracy: 0.7500\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5636 - accuracy: 0.7307 - val_loss: 0.5762 - val_accuracy: 0.6923\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5630 - accuracy: 0.7183 - val_loss: 0.5569 - val_accuracy: 0.7212\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5723 - accuracy: 0.7058 - val_loss: 0.5449 - val_accuracy: 0.7564\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5630 - accuracy: 0.7132 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5566 - accuracy: 0.7285 - val_loss: 0.5429 - val_accuracy: 0.7436\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5599 - accuracy: 0.7200 - val_loss: 0.5631 - val_accuracy: 0.6987\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5509 - accuracy: 0.7364 - val_loss: 0.5406 - val_accuracy: 0.7628\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5377 - accuracy: 0.7279 - val_loss: 0.5555 - val_accuracy: 0.7212\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5451 - accuracy: 0.7336 - val_loss: 0.5566 - val_accuracy: 0.7340\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7324 - val_loss: 0.5335 - val_accuracy: 0.7436\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.7353 - val_loss: 0.5346 - val_accuracy: 0.7372\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5394 - accuracy: 0.7358 - val_loss: 0.5499 - val_accuracy: 0.7276\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5390 - accuracy: 0.7449 - val_loss: 0.5472 - val_accuracy: 0.7308\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7353 - val_loss: 0.5381 - val_accuracy: 0.7212\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5373 - accuracy: 0.7392 - val_loss: 0.5512 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5386 - accuracy: 0.7330 - val_loss: 0.5316 - val_accuracy: 0.7468\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.7489 - val_loss: 0.5279 - val_accuracy: 0.7436\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5324 - accuracy: 0.7466 - val_loss: 0.5306 - val_accuracy: 0.7404\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5325 - accuracy: 0.7477 - val_loss: 0.5430 - val_accuracy: 0.7372\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7545 - val_loss: 0.5415 - val_accuracy: 0.7468\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5269 - accuracy: 0.7460 - val_loss: 0.5585 - val_accuracy: 0.6987\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.7398 - val_loss: 0.5395 - val_accuracy: 0.7212\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5275 - accuracy: 0.7585 - val_loss: 0.5465 - val_accuracy: 0.7179\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5288 - accuracy: 0.7387 - val_loss: 0.5311 - val_accuracy: 0.7436\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5233 - accuracy: 0.7489 - val_loss: 0.5368 - val_accuracy: 0.7468\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5298 - accuracy: 0.7517 - val_loss: 0.5342 - val_accuracy: 0.7372\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5257 - accuracy: 0.7517 - val_loss: 0.5363 - val_accuracy: 0.7212\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5252 - accuracy: 0.7511 - val_loss: 0.5379 - val_accuracy: 0.7372\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5322 - accuracy: 0.7460 - val_loss: 0.5437 - val_accuracy: 0.7308\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5196 - accuracy: 0.7551 - val_loss: 0.5322 - val_accuracy: 0.7436\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5289 - accuracy: 0.7460 - val_loss: 0.5396 - val_accuracy: 0.7244\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5107 - accuracy: 0.7591 - val_loss: 0.5482 - val_accuracy: 0.7404\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5188 - accuracy: 0.7596 - val_loss: 0.5463 - val_accuracy: 0.7244\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5240 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.6987\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.7443 - val_loss: 0.5620 - val_accuracy: 0.7147\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.7591 - val_loss: 0.5644 - val_accuracy: 0.7244\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5131 - accuracy: 0.7585 - val_loss: 0.5352 - val_accuracy: 0.7468\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5132 - accuracy: 0.7585 - val_loss: 0.5440 - val_accuracy: 0.7244\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5236 - accuracy: 0.7477 - val_loss: 0.5577 - val_accuracy: 0.7372\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5155 - accuracy: 0.7540 - val_loss: 0.5779 - val_accuracy: 0.7147\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5118 - accuracy: 0.7500 - val_loss: 0.5495 - val_accuracy: 0.7179\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5094 - accuracy: 0.7517 - val_loss: 0.5512 - val_accuracy: 0.7276\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7115384615384616\n",
            "Accuracy: 0.7115384615384616\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6451 - accuracy: 0.6604 - val_loss: 0.6073 - val_accuracy: 0.6923\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6333 - accuracy: 0.6633 - val_loss: 0.5785 - val_accuracy: 0.6923\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6201 - accuracy: 0.6582 - val_loss: 0.5801 - val_accuracy: 0.6923\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6049 - accuracy: 0.6723 - val_loss: 0.5584 - val_accuracy: 0.7244\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6004 - accuracy: 0.6944 - val_loss: 0.5786 - val_accuracy: 0.7115\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5952 - accuracy: 0.6888 - val_loss: 0.5882 - val_accuracy: 0.6955\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5799 - accuracy: 0.7092 - val_loss: 0.5688 - val_accuracy: 0.6891\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5769 - accuracy: 0.7080 - val_loss: 0.5748 - val_accuracy: 0.7115\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5718 - accuracy: 0.7120 - val_loss: 0.5936 - val_accuracy: 0.7051\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5646 - accuracy: 0.7205 - val_loss: 0.5464 - val_accuracy: 0.7244\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5572 - accuracy: 0.7324 - val_loss: 0.5532 - val_accuracy: 0.7212\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5570 - accuracy: 0.7177 - val_loss: 0.5739 - val_accuracy: 0.6955\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5605 - accuracy: 0.7211 - val_loss: 0.5593 - val_accuracy: 0.7147\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5515 - accuracy: 0.7324 - val_loss: 0.5424 - val_accuracy: 0.7276\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.7358 - val_loss: 0.5406 - val_accuracy: 0.7660\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5543 - accuracy: 0.7330 - val_loss: 0.5533 - val_accuracy: 0.7340\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5476 - accuracy: 0.7313 - val_loss: 0.5717 - val_accuracy: 0.7115\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5489 - accuracy: 0.7324 - val_loss: 0.5785 - val_accuracy: 0.6955\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5398 - accuracy: 0.7392 - val_loss: 0.5508 - val_accuracy: 0.7083\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5509 - accuracy: 0.7285 - val_loss: 0.5774 - val_accuracy: 0.6955\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5371 - accuracy: 0.7358 - val_loss: 0.5544 - val_accuracy: 0.7308\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5461 - accuracy: 0.7324 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5475 - accuracy: 0.7341 - val_loss: 0.5511 - val_accuracy: 0.7564\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5422 - accuracy: 0.7460 - val_loss: 0.5451 - val_accuracy: 0.7564\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5339 - accuracy: 0.7426 - val_loss: 0.5488 - val_accuracy: 0.7500\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5347 - accuracy: 0.7381 - val_loss: 0.5724 - val_accuracy: 0.6827\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5330 - accuracy: 0.7409 - val_loss: 0.5978 - val_accuracy: 0.6731\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5500 - accuracy: 0.7432 - val_loss: 0.5486 - val_accuracy: 0.7308\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5364 - accuracy: 0.7370 - val_loss: 0.5652 - val_accuracy: 0.7276\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5336 - accuracy: 0.7398 - val_loss: 0.5536 - val_accuracy: 0.7372\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5362 - accuracy: 0.7336 - val_loss: 0.5579 - val_accuracy: 0.7372\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5340 - accuracy: 0.7398 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5324 - accuracy: 0.7358 - val_loss: 0.5586 - val_accuracy: 0.7115\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5283 - accuracy: 0.7494 - val_loss: 0.5645 - val_accuracy: 0.7340\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5296 - accuracy: 0.7364 - val_loss: 0.5629 - val_accuracy: 0.7532\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5310 - accuracy: 0.7409 - val_loss: 0.5667 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5159 - accuracy: 0.7534 - val_loss: 0.5635 - val_accuracy: 0.7276\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5188 - accuracy: 0.7591 - val_loss: 0.5625 - val_accuracy: 0.7244\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.7421 - val_loss: 0.5583 - val_accuracy: 0.7372\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.7506 - val_loss: 0.5770 - val_accuracy: 0.7212\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5262 - accuracy: 0.7438 - val_loss: 0.5806 - val_accuracy: 0.7404\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5101 - accuracy: 0.7409 - val_loss: 0.6145 - val_accuracy: 0.7019\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5242 - accuracy: 0.7483 - val_loss: 0.5638 - val_accuracy: 0.7147\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5179 - accuracy: 0.7460 - val_loss: 0.5740 - val_accuracy: 0.7340\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7455 - val_loss: 0.5603 - val_accuracy: 0.7372\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5174 - accuracy: 0.7545 - val_loss: 0.5566 - val_accuracy: 0.7372\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5129 - accuracy: 0.7489 - val_loss: 0.5728 - val_accuracy: 0.7276\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5130 - accuracy: 0.7460 - val_loss: 0.5641 - val_accuracy: 0.7404\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5223 - accuracy: 0.7415 - val_loss: 0.5562 - val_accuracy: 0.7436\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5128 - accuracy: 0.7568 - val_loss: 0.5701 - val_accuracy: 0.6827\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7365384615384616\n",
            "Accuracy: 0.7365384615384616\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6385 - accuracy: 0.6599 - val_loss: 0.6496 - val_accuracy: 0.6474\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6297 - accuracy: 0.6667 - val_loss: 0.6066 - val_accuracy: 0.6474\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6142 - accuracy: 0.6695 - val_loss: 0.6018 - val_accuracy: 0.6506\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5991 - accuracy: 0.6842 - val_loss: 0.5907 - val_accuracy: 0.7115\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5991 - accuracy: 0.7052 - val_loss: 0.5905 - val_accuracy: 0.6506\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5910 - accuracy: 0.7001 - val_loss: 0.5614 - val_accuracy: 0.7083\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5648 - accuracy: 0.7166 - val_loss: 0.5861 - val_accuracy: 0.7179\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5787 - accuracy: 0.7103 - val_loss: 0.5841 - val_accuracy: 0.7179\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5596 - accuracy: 0.7234 - val_loss: 0.5701 - val_accuracy: 0.7019\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5543 - accuracy: 0.7313 - val_loss: 0.5709 - val_accuracy: 0.6859\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5591 - accuracy: 0.7268 - val_loss: 0.5519 - val_accuracy: 0.7051\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5579 - accuracy: 0.7211 - val_loss: 0.5576 - val_accuracy: 0.7051\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5542 - accuracy: 0.7387 - val_loss: 0.5573 - val_accuracy: 0.7019\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5555 - accuracy: 0.7381 - val_loss: 0.5551 - val_accuracy: 0.6955\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7426 - val_loss: 0.5641 - val_accuracy: 0.6987\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.7353 - val_loss: 0.5330 - val_accuracy: 0.7308\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5502 - accuracy: 0.7290 - val_loss: 0.5336 - val_accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5468 - accuracy: 0.7438 - val_loss: 0.5440 - val_accuracy: 0.7083\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5527 - accuracy: 0.7302 - val_loss: 0.5359 - val_accuracy: 0.7179\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5467 - accuracy: 0.7392 - val_loss: 0.5440 - val_accuracy: 0.7372\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.7381 - val_loss: 0.5447 - val_accuracy: 0.7212\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5459 - accuracy: 0.7426 - val_loss: 0.5657 - val_accuracy: 0.7244\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5467 - accuracy: 0.7347 - val_loss: 0.5462 - val_accuracy: 0.7308\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5417 - accuracy: 0.7392 - val_loss: 0.5402 - val_accuracy: 0.7244\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7426 - val_loss: 0.5368 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7449 - val_loss: 0.5505 - val_accuracy: 0.7051\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5428 - accuracy: 0.7398 - val_loss: 0.5323 - val_accuracy: 0.7244\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5366 - accuracy: 0.7421 - val_loss: 0.5410 - val_accuracy: 0.7276\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5305 - accuracy: 0.7455 - val_loss: 0.5370 - val_accuracy: 0.7596\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5331 - accuracy: 0.7426 - val_loss: 0.5641 - val_accuracy: 0.6859\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5469 - accuracy: 0.7375 - val_loss: 0.5263 - val_accuracy: 0.7147\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5283 - accuracy: 0.7523 - val_loss: 0.5455 - val_accuracy: 0.7147\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5390 - accuracy: 0.7387 - val_loss: 0.5246 - val_accuracy: 0.7276\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5316 - accuracy: 0.7477 - val_loss: 0.5385 - val_accuracy: 0.7212\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7562 - val_loss: 0.5433 - val_accuracy: 0.7212\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7324 - val_loss: 0.5413 - val_accuracy: 0.7340\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5225 - accuracy: 0.7517 - val_loss: 0.5320 - val_accuracy: 0.7436\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5172 - accuracy: 0.7574 - val_loss: 0.5507 - val_accuracy: 0.6955\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.7449 - val_loss: 0.5211 - val_accuracy: 0.7404\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5265 - accuracy: 0.7517 - val_loss: 0.5300 - val_accuracy: 0.7340\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.7472 - val_loss: 0.5514 - val_accuracy: 0.6987\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.7540 - val_loss: 0.5261 - val_accuracy: 0.7596\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.7517 - val_loss: 0.5395 - val_accuracy: 0.7179\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5199 - accuracy: 0.7477 - val_loss: 0.5534 - val_accuracy: 0.6923\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5299 - accuracy: 0.7483 - val_loss: 0.5312 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5109 - accuracy: 0.7534 - val_loss: 0.5265 - val_accuracy: 0.7147\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5231 - accuracy: 0.7562 - val_loss: 0.5225 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5260 - accuracy: 0.7523 - val_loss: 0.5473 - val_accuracy: 0.7115\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5182 - accuracy: 0.7579 - val_loss: 0.5247 - val_accuracy: 0.7340\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5203 - accuracy: 0.7591 - val_loss: 0.5251 - val_accuracy: 0.7436\n",
            "17/17 [==============================] - 0s 3ms/step\n",
            "0.7230769230769231\n",
            "Accuracy: 0.7230769230769231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6412 - accuracy: 0.6616 - val_loss: 0.6108 - val_accuracy: 0.6731\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6257 - accuracy: 0.6638 - val_loss: 0.6057 - val_accuracy: 0.6731\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.6638 - val_loss: 0.6221 - val_accuracy: 0.6731\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6099 - accuracy: 0.6723 - val_loss: 0.5918 - val_accuracy: 0.6795\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5976 - accuracy: 0.6956 - val_loss: 0.5855 - val_accuracy: 0.6827\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5880 - accuracy: 0.7029 - val_loss: 0.5973 - val_accuracy: 0.6538\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5900 - accuracy: 0.7046 - val_loss: 0.6174 - val_accuracy: 0.6955\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5759 - accuracy: 0.7171 - val_loss: 0.5948 - val_accuracy: 0.6955\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5711 - accuracy: 0.7324 - val_loss: 0.5767 - val_accuracy: 0.6987\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5733 - accuracy: 0.7222 - val_loss: 0.5793 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5675 - accuracy: 0.7217 - val_loss: 0.5879 - val_accuracy: 0.6827\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5678 - accuracy: 0.7228 - val_loss: 0.5728 - val_accuracy: 0.6891\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5638 - accuracy: 0.7200 - val_loss: 0.5928 - val_accuracy: 0.6410\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5587 - accuracy: 0.7290 - val_loss: 0.5776 - val_accuracy: 0.7083\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.7341 - val_loss: 0.6205 - val_accuracy: 0.6795\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5610 - accuracy: 0.7319 - val_loss: 0.5828 - val_accuracy: 0.6859\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5599 - accuracy: 0.7228 - val_loss: 0.5732 - val_accuracy: 0.6987\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5456 - accuracy: 0.7392 - val_loss: 0.5801 - val_accuracy: 0.7019\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5652 - accuracy: 0.7222 - val_loss: 0.5874 - val_accuracy: 0.7051\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5509 - accuracy: 0.7370 - val_loss: 0.5831 - val_accuracy: 0.6827\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5587 - accuracy: 0.7324 - val_loss: 0.5861 - val_accuracy: 0.6635\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5523 - accuracy: 0.7347 - val_loss: 0.6082 - val_accuracy: 0.6442\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5450 - accuracy: 0.7217 - val_loss: 0.5796 - val_accuracy: 0.6763\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5440 - accuracy: 0.7347 - val_loss: 0.5878 - val_accuracy: 0.7051\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5370 - accuracy: 0.7370 - val_loss: 0.5729 - val_accuracy: 0.6923\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5442 - accuracy: 0.7387 - val_loss: 0.5748 - val_accuracy: 0.7147\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5344 - accuracy: 0.7460 - val_loss: 0.5702 - val_accuracy: 0.7179\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7415 - val_loss: 0.6007 - val_accuracy: 0.6346\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.7489 - val_loss: 0.5913 - val_accuracy: 0.6410\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5474 - accuracy: 0.7222 - val_loss: 0.5735 - val_accuracy: 0.6923\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5408 - accuracy: 0.7438 - val_loss: 0.5858 - val_accuracy: 0.6763\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.7415 - val_loss: 0.5827 - val_accuracy: 0.6987\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5400 - accuracy: 0.7455 - val_loss: 0.5740 - val_accuracy: 0.7051\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.7415 - val_loss: 0.5722 - val_accuracy: 0.7212\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5441 - accuracy: 0.7358 - val_loss: 0.6286 - val_accuracy: 0.6474\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.7409 - val_loss: 0.6047 - val_accuracy: 0.6378\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5355 - accuracy: 0.7460 - val_loss: 0.5772 - val_accuracy: 0.6923\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5351 - accuracy: 0.7477 - val_loss: 0.5793 - val_accuracy: 0.6987\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5298 - accuracy: 0.7517 - val_loss: 0.5723 - val_accuracy: 0.7083\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5333 - accuracy: 0.7494 - val_loss: 0.5744 - val_accuracy: 0.7179\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5226 - accuracy: 0.7523 - val_loss: 0.5816 - val_accuracy: 0.7212\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.7494 - val_loss: 0.5755 - val_accuracy: 0.7115\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5249 - accuracy: 0.7500 - val_loss: 0.5857 - val_accuracy: 0.6955\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.7455 - val_loss: 0.5903 - val_accuracy: 0.7019\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5313 - accuracy: 0.7500 - val_loss: 0.5889 - val_accuracy: 0.6955\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5203 - accuracy: 0.7557 - val_loss: 0.5823 - val_accuracy: 0.6891\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5207 - accuracy: 0.7500 - val_loss: 0.6010 - val_accuracy: 0.6538\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5282 - accuracy: 0.7421 - val_loss: 0.5840 - val_accuracy: 0.6827\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5211 - accuracy: 0.7545 - val_loss: 0.5851 - val_accuracy: 0.6859\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7460 - val_loss: 0.5934 - val_accuracy: 0.6699\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7403846153846154\n",
            "Accuracy: 0.7403846153846154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6320 - accuracy: 0.6610 - val_loss: 0.6061 - val_accuracy: 0.7083\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6119 - accuracy: 0.6650 - val_loss: 0.5855 - val_accuracy: 0.7308\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5936 - accuracy: 0.6910 - val_loss: 0.5834 - val_accuracy: 0.6955\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5798 - accuracy: 0.7149 - val_loss: 0.5531 - val_accuracy: 0.7340\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5701 - accuracy: 0.7188 - val_loss: 0.5503 - val_accuracy: 0.7340\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5715 - accuracy: 0.7092 - val_loss: 0.5507 - val_accuracy: 0.7404\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5666 - accuracy: 0.7262 - val_loss: 0.5518 - val_accuracy: 0.7404\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5686 - accuracy: 0.7154 - val_loss: 0.5730 - val_accuracy: 0.7244\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5546 - accuracy: 0.7279 - val_loss: 0.5475 - val_accuracy: 0.7532\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5602 - accuracy: 0.7347 - val_loss: 0.5604 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5507 - accuracy: 0.7330 - val_loss: 0.5516 - val_accuracy: 0.7532\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.7285 - val_loss: 0.5654 - val_accuracy: 0.6891\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5485 - accuracy: 0.7160 - val_loss: 0.5494 - val_accuracy: 0.7436\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5439 - accuracy: 0.7307 - val_loss: 0.5402 - val_accuracy: 0.7628\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5404 - accuracy: 0.7319 - val_loss: 0.5526 - val_accuracy: 0.7276\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5446 - accuracy: 0.7364 - val_loss: 0.5699 - val_accuracy: 0.7436\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7268 - val_loss: 0.5581 - val_accuracy: 0.7564\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5397 - accuracy: 0.7421 - val_loss: 0.5455 - val_accuracy: 0.7404\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5414 - accuracy: 0.7404 - val_loss: 0.5526 - val_accuracy: 0.7276\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.7432 - val_loss: 0.5708 - val_accuracy: 0.6891\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5449 - accuracy: 0.7290 - val_loss: 0.5534 - val_accuracy: 0.7051\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5393 - accuracy: 0.7279 - val_loss: 0.5453 - val_accuracy: 0.7596\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5238 - accuracy: 0.7557 - val_loss: 0.5440 - val_accuracy: 0.7532\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7279 - val_loss: 0.5536 - val_accuracy: 0.7500\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5352 - accuracy: 0.7330 - val_loss: 0.5494 - val_accuracy: 0.7564\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5291 - accuracy: 0.7517 - val_loss: 0.5546 - val_accuracy: 0.7340\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5336 - accuracy: 0.7421 - val_loss: 0.5586 - val_accuracy: 0.7532\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5317 - accuracy: 0.7483 - val_loss: 0.5474 - val_accuracy: 0.7468\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5264 - accuracy: 0.7562 - val_loss: 0.5647 - val_accuracy: 0.7179\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5300 - accuracy: 0.7364 - val_loss: 0.5546 - val_accuracy: 0.7532\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7404 - val_loss: 0.5556 - val_accuracy: 0.7404\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.7511 - val_loss: 0.5561 - val_accuracy: 0.7115\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7364 - val_loss: 0.5497 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7324 - val_loss: 0.5476 - val_accuracy: 0.7692\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7466 - val_loss: 0.5682 - val_accuracy: 0.7083\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5231 - accuracy: 0.7545 - val_loss: 0.5596 - val_accuracy: 0.7179\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5205 - accuracy: 0.7574 - val_loss: 0.5417 - val_accuracy: 0.7564\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7392 - val_loss: 0.5493 - val_accuracy: 0.7468\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7472 - val_loss: 0.5566 - val_accuracy: 0.7468\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.7540 - val_loss: 0.5592 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.7506 - val_loss: 0.5648 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.7477 - val_loss: 0.5522 - val_accuracy: 0.7468\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5113 - accuracy: 0.7625 - val_loss: 0.5561 - val_accuracy: 0.7436\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5098 - accuracy: 0.7636 - val_loss: 0.5754 - val_accuracy: 0.7051\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.7415 - val_loss: 0.5683 - val_accuracy: 0.7532\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5181 - accuracy: 0.7409 - val_loss: 0.5601 - val_accuracy: 0.7596\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5108 - accuracy: 0.7608 - val_loss: 0.5593 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5080 - accuracy: 0.7562 - val_loss: 0.5630 - val_accuracy: 0.7628\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5154 - accuracy: 0.7483 - val_loss: 0.5718 - val_accuracy: 0.7468\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5201 - accuracy: 0.7449 - val_loss: 0.5536 - val_accuracy: 0.7628\n",
            "17/17 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6942307692307692\n",
            "Accuracy: 0.6942307692307692\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6387 - accuracy: 0.6582 - val_loss: 0.6469 - val_accuracy: 0.6635\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6275 - accuracy: 0.6627 - val_loss: 0.6342 - val_accuracy: 0.6635\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.6627 - val_loss: 0.5939 - val_accuracy: 0.6635\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6021 - accuracy: 0.6689 - val_loss: 0.6218 - val_accuracy: 0.7019\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5858 - accuracy: 0.6939 - val_loss: 0.5699 - val_accuracy: 0.7212\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5847 - accuracy: 0.7001 - val_loss: 0.5763 - val_accuracy: 0.7179\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5742 - accuracy: 0.7069 - val_loss: 0.5696 - val_accuracy: 0.7468\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5628 - accuracy: 0.7160 - val_loss: 0.5680 - val_accuracy: 0.7115\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5582 - accuracy: 0.7080 - val_loss: 0.5745 - val_accuracy: 0.7019\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5685 - accuracy: 0.7211 - val_loss: 0.5524 - val_accuracy: 0.7308\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5590 - accuracy: 0.7234 - val_loss: 0.5473 - val_accuracy: 0.7532\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5558 - accuracy: 0.7330 - val_loss: 0.5628 - val_accuracy: 0.7244\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5561 - accuracy: 0.7171 - val_loss: 0.5594 - val_accuracy: 0.7276\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5492 - accuracy: 0.7353 - val_loss: 0.5548 - val_accuracy: 0.7468\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5605 - accuracy: 0.7239 - val_loss: 0.5994 - val_accuracy: 0.6923\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5593 - accuracy: 0.7166 - val_loss: 0.5522 - val_accuracy: 0.7340\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5449 - accuracy: 0.7194 - val_loss: 0.5549 - val_accuracy: 0.7308\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5485 - accuracy: 0.7341 - val_loss: 0.5600 - val_accuracy: 0.7308\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5460 - accuracy: 0.7324 - val_loss: 0.5563 - val_accuracy: 0.7244\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5354 - accuracy: 0.7494 - val_loss: 0.5633 - val_accuracy: 0.7276\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5420 - accuracy: 0.7336 - val_loss: 0.5397 - val_accuracy: 0.7372\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5459 - accuracy: 0.7421 - val_loss: 0.5482 - val_accuracy: 0.7340\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5522 - accuracy: 0.7375 - val_loss: 0.5625 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5371 - accuracy: 0.7392 - val_loss: 0.5608 - val_accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5356 - accuracy: 0.7358 - val_loss: 0.5458 - val_accuracy: 0.7404\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5470 - accuracy: 0.7392 - val_loss: 0.5535 - val_accuracy: 0.7340\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5434 - accuracy: 0.7285 - val_loss: 0.5438 - val_accuracy: 0.7436\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5341 - accuracy: 0.7404 - val_loss: 0.5452 - val_accuracy: 0.7468\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7438 - val_loss: 0.5571 - val_accuracy: 0.7244\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7438 - val_loss: 0.5507 - val_accuracy: 0.7404\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5351 - accuracy: 0.7364 - val_loss: 0.5486 - val_accuracy: 0.7436\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5410 - accuracy: 0.7330 - val_loss: 0.5691 - val_accuracy: 0.7372\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5224 - accuracy: 0.7358 - val_loss: 0.5735 - val_accuracy: 0.7212\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.7404 - val_loss: 0.5567 - val_accuracy: 0.7340\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7404 - val_loss: 0.5560 - val_accuracy: 0.7372\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5171 - accuracy: 0.7483 - val_loss: 0.5644 - val_accuracy: 0.7468\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5177 - accuracy: 0.7494 - val_loss: 0.5733 - val_accuracy: 0.7179\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5266 - accuracy: 0.7409 - val_loss: 0.5649 - val_accuracy: 0.7147\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5194 - accuracy: 0.7517 - val_loss: 0.5565 - val_accuracy: 0.7404\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5153 - accuracy: 0.7545 - val_loss: 0.5650 - val_accuracy: 0.7276\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5229 - accuracy: 0.7517 - val_loss: 0.5742 - val_accuracy: 0.7019\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.7370 - val_loss: 0.5606 - val_accuracy: 0.7436\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5208 - accuracy: 0.7506 - val_loss: 0.5598 - val_accuracy: 0.7276\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5190 - accuracy: 0.7460 - val_loss: 0.5684 - val_accuracy: 0.7468\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5174 - accuracy: 0.7483 - val_loss: 0.5822 - val_accuracy: 0.6987\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5055 - accuracy: 0.7596 - val_loss: 0.5646 - val_accuracy: 0.7404\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5176 - accuracy: 0.7421 - val_loss: 0.5827 - val_accuracy: 0.7147\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5149 - accuracy: 0.7472 - val_loss: 0.5679 - val_accuracy: 0.7372\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5134 - accuracy: 0.7460 - val_loss: 0.5671 - val_accuracy: 0.7340\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5129 - accuracy: 0.7523 - val_loss: 0.5591 - val_accuracy: 0.7372\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7211538461538461\n",
            "Accuracy: 0.7211538461538461\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6493 - accuracy: 0.6474 - val_loss: 0.6162 - val_accuracy: 0.6571\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6326 - accuracy: 0.6565 - val_loss: 0.6010 - val_accuracy: 0.6571\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6207 - accuracy: 0.6593 - val_loss: 0.5875 - val_accuracy: 0.6827\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6091 - accuracy: 0.6689 - val_loss: 0.5680 - val_accuracy: 0.7115\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6046 - accuracy: 0.6865 - val_loss: 0.5412 - val_accuracy: 0.7308\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5916 - accuracy: 0.6859 - val_loss: 0.5720 - val_accuracy: 0.7051\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5834 - accuracy: 0.7058 - val_loss: 0.5617 - val_accuracy: 0.6923\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5714 - accuracy: 0.7103 - val_loss: 0.5491 - val_accuracy: 0.7019\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5746 - accuracy: 0.7018 - val_loss: 0.5461 - val_accuracy: 0.7628\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5715 - accuracy: 0.7126 - val_loss: 0.5284 - val_accuracy: 0.7532\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5810 - accuracy: 0.7069 - val_loss: 0.5305 - val_accuracy: 0.7436\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5683 - accuracy: 0.7194 - val_loss: 0.5471 - val_accuracy: 0.7596\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5786 - accuracy: 0.6973 - val_loss: 0.5450 - val_accuracy: 0.7436\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5721 - accuracy: 0.7251 - val_loss: 0.5436 - val_accuracy: 0.7051\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5654 - accuracy: 0.7063 - val_loss: 0.5541 - val_accuracy: 0.7244\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5616 - accuracy: 0.7132 - val_loss: 0.5359 - val_accuracy: 0.7596\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5634 - accuracy: 0.7200 - val_loss: 0.5318 - val_accuracy: 0.7532\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5659 - accuracy: 0.7069 - val_loss: 0.5500 - val_accuracy: 0.6955\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5582 - accuracy: 0.7149 - val_loss: 0.5738 - val_accuracy: 0.6859\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5555 - accuracy: 0.7222 - val_loss: 0.5318 - val_accuracy: 0.7404\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5509 - accuracy: 0.7302 - val_loss: 0.5369 - val_accuracy: 0.7532\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5613 - accuracy: 0.7200 - val_loss: 0.5508 - val_accuracy: 0.7564\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5536 - accuracy: 0.7222 - val_loss: 0.5718 - val_accuracy: 0.7436\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5525 - accuracy: 0.7222 - val_loss: 0.5606 - val_accuracy: 0.7019\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5501 - accuracy: 0.7262 - val_loss: 0.5327 - val_accuracy: 0.7212\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5447 - accuracy: 0.7290 - val_loss: 0.5464 - val_accuracy: 0.7147\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7228 - val_loss: 0.5395 - val_accuracy: 0.7308\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5418 - accuracy: 0.7279 - val_loss: 0.5260 - val_accuracy: 0.7564\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5474 - accuracy: 0.7268 - val_loss: 0.5463 - val_accuracy: 0.7115\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5414 - accuracy: 0.7256 - val_loss: 0.5282 - val_accuracy: 0.7532\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7336 - val_loss: 0.5313 - val_accuracy: 0.7468\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7313 - val_loss: 0.5531 - val_accuracy: 0.7532\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5491 - accuracy: 0.7228 - val_loss: 0.5219 - val_accuracy: 0.7340\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5443 - accuracy: 0.7268 - val_loss: 0.5311 - val_accuracy: 0.7532\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5478 - accuracy: 0.7341 - val_loss: 0.5387 - val_accuracy: 0.7532\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5362 - accuracy: 0.7449 - val_loss: 0.5262 - val_accuracy: 0.7628\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5451 - accuracy: 0.7279 - val_loss: 0.5298 - val_accuracy: 0.7628\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5481 - accuracy: 0.7217 - val_loss: 0.5475 - val_accuracy: 0.7692\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7358 - val_loss: 0.5280 - val_accuracy: 0.7468\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.7460 - val_loss: 0.5382 - val_accuracy: 0.7660\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.7449 - val_loss: 0.5642 - val_accuracy: 0.7212\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5404 - accuracy: 0.7358 - val_loss: 0.5219 - val_accuracy: 0.7532\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5326 - accuracy: 0.7307 - val_loss: 0.5303 - val_accuracy: 0.7628\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.7279 - val_loss: 0.5419 - val_accuracy: 0.7532\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5332 - accuracy: 0.7381 - val_loss: 0.5747 - val_accuracy: 0.6506\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5452 - accuracy: 0.7296 - val_loss: 0.5354 - val_accuracy: 0.7468\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5329 - accuracy: 0.7398 - val_loss: 0.5372 - val_accuracy: 0.7340\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5360 - accuracy: 0.7421 - val_loss: 0.5509 - val_accuracy: 0.7340\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.7443 - val_loss: 0.5672 - val_accuracy: 0.7468\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5391 - accuracy: 0.7313 - val_loss: 0.5353 - val_accuracy: 0.7468\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7403846153846154\n",
            "Accuracy: 0.7403846153846154\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6419 - accuracy: 0.6548 - val_loss: 0.6075 - val_accuracy: 0.6795\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.6587 - val_loss: 0.6040 - val_accuracy: 0.6859\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.6587 - val_loss: 0.5714 - val_accuracy: 0.6891\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6186 - accuracy: 0.6570 - val_loss: 0.5616 - val_accuracy: 0.6795\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5955 - accuracy: 0.6661 - val_loss: 0.5472 - val_accuracy: 0.7051\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5949 - accuracy: 0.6933 - val_loss: 0.5581 - val_accuracy: 0.7436\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5871 - accuracy: 0.7052 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5850 - accuracy: 0.7046 - val_loss: 0.5447 - val_accuracy: 0.7147\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5812 - accuracy: 0.7109 - val_loss: 0.5444 - val_accuracy: 0.7083\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5819 - accuracy: 0.7046 - val_loss: 0.5364 - val_accuracy: 0.7468\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5797 - accuracy: 0.6967 - val_loss: 0.5316 - val_accuracy: 0.7468\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5682 - accuracy: 0.7171 - val_loss: 0.5417 - val_accuracy: 0.7436\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5741 - accuracy: 0.7103 - val_loss: 0.5469 - val_accuracy: 0.7340\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5654 - accuracy: 0.7160 - val_loss: 0.5461 - val_accuracy: 0.7276\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5634 - accuracy: 0.7194 - val_loss: 0.5369 - val_accuracy: 0.7404\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5640 - accuracy: 0.7171 - val_loss: 0.5666 - val_accuracy: 0.7596\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5607 - accuracy: 0.7268 - val_loss: 0.5369 - val_accuracy: 0.7468\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5655 - accuracy: 0.7302 - val_loss: 0.5287 - val_accuracy: 0.7532\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5586 - accuracy: 0.7268 - val_loss: 0.5465 - val_accuracy: 0.7628\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5496 - accuracy: 0.7285 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.7307 - val_loss: 0.5326 - val_accuracy: 0.7340\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5615 - accuracy: 0.7251 - val_loss: 0.5388 - val_accuracy: 0.7179\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.7381 - val_loss: 0.5311 - val_accuracy: 0.7468\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5554 - accuracy: 0.7217 - val_loss: 0.5368 - val_accuracy: 0.7340\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5394 - accuracy: 0.7398 - val_loss: 0.5671 - val_accuracy: 0.7179\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5502 - accuracy: 0.7398 - val_loss: 0.5360 - val_accuracy: 0.7340\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5443 - accuracy: 0.7415 - val_loss: 0.5511 - val_accuracy: 0.7115\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5479 - accuracy: 0.7330 - val_loss: 0.5266 - val_accuracy: 0.7436\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5443 - accuracy: 0.7341 - val_loss: 0.5444 - val_accuracy: 0.7308\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5408 - accuracy: 0.7307 - val_loss: 0.5365 - val_accuracy: 0.7372\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5393 - accuracy: 0.7290 - val_loss: 0.5390 - val_accuracy: 0.7436\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5357 - accuracy: 0.7438 - val_loss: 0.5195 - val_accuracy: 0.7532\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5402 - accuracy: 0.7358 - val_loss: 0.5354 - val_accuracy: 0.7308\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5321 - accuracy: 0.7449 - val_loss: 0.5409 - val_accuracy: 0.7083\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5352 - accuracy: 0.7404 - val_loss: 0.5205 - val_accuracy: 0.7564\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5317 - accuracy: 0.7500 - val_loss: 0.5505 - val_accuracy: 0.7179\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5349 - accuracy: 0.7409 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5354 - accuracy: 0.7421 - val_loss: 0.5345 - val_accuracy: 0.7532\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5356 - accuracy: 0.7392 - val_loss: 0.5574 - val_accuracy: 0.7019\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5409 - accuracy: 0.7290 - val_loss: 0.5263 - val_accuracy: 0.7692\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7528 - val_loss: 0.5237 - val_accuracy: 0.7692\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5221 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.7308\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5303 - accuracy: 0.7494 - val_loss: 0.5625 - val_accuracy: 0.7468\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5306 - accuracy: 0.7421 - val_loss: 0.5529 - val_accuracy: 0.7051\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7319 - val_loss: 0.5398 - val_accuracy: 0.7692\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5298 - accuracy: 0.7415 - val_loss: 0.5271 - val_accuracy: 0.7468\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5338 - accuracy: 0.7404 - val_loss: 0.5331 - val_accuracy: 0.7468\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.7517 - val_loss: 0.5313 - val_accuracy: 0.7340\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5203 - accuracy: 0.7443 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5142 - accuracy: 0.7477 - val_loss: 0.5353 - val_accuracy: 0.7372\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7557692307692307\n",
            "Accuracy: 0.7557692307692307\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 12ms/step - loss: 0.6353 - accuracy: 0.6655 - val_loss: 0.6345 - val_accuracy: 0.6282\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6695 - val_loss: 0.6220 - val_accuracy: 0.6282\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6034 - accuracy: 0.6746 - val_loss: 0.6259 - val_accuracy: 0.6442\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5890 - accuracy: 0.6990 - val_loss: 0.6022 - val_accuracy: 0.7019\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5669 - accuracy: 0.7137 - val_loss: 0.6262 - val_accuracy: 0.6635\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5758 - accuracy: 0.7018 - val_loss: 0.5987 - val_accuracy: 0.6731\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5619 - accuracy: 0.7228 - val_loss: 0.6018 - val_accuracy: 0.6699\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5574 - accuracy: 0.7262 - val_loss: 0.6065 - val_accuracy: 0.6827\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5472 - accuracy: 0.7370 - val_loss: 0.6458 - val_accuracy: 0.6346\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5637 - accuracy: 0.7132 - val_loss: 0.6004 - val_accuracy: 0.6859\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5468 - accuracy: 0.7313 - val_loss: 0.5975 - val_accuracy: 0.6891\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5412 - accuracy: 0.7211 - val_loss: 0.5966 - val_accuracy: 0.6795\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5447 - accuracy: 0.7319 - val_loss: 0.5946 - val_accuracy: 0.6827\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7364 - val_loss: 0.5970 - val_accuracy: 0.6891\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5367 - accuracy: 0.7449 - val_loss: 0.6124 - val_accuracy: 0.6571\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.7273 - val_loss: 0.6098 - val_accuracy: 0.6699\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5352 - accuracy: 0.7404 - val_loss: 0.6015 - val_accuracy: 0.6859\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7370 - val_loss: 0.5908 - val_accuracy: 0.6891\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5315 - accuracy: 0.7466 - val_loss: 0.5893 - val_accuracy: 0.6987\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7409 - val_loss: 0.6046 - val_accuracy: 0.6859\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5321 - accuracy: 0.7330 - val_loss: 0.5901 - val_accuracy: 0.6955\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5228 - accuracy: 0.7398 - val_loss: 0.5971 - val_accuracy: 0.6763\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5280 - accuracy: 0.7415 - val_loss: 0.5945 - val_accuracy: 0.6731\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5284 - accuracy: 0.7387 - val_loss: 0.5901 - val_accuracy: 0.6827\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.7398 - val_loss: 0.6030 - val_accuracy: 0.6987\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5312 - accuracy: 0.7415 - val_loss: 0.6171 - val_accuracy: 0.6987\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.7613 - val_loss: 0.5957 - val_accuracy: 0.6827\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5164 - accuracy: 0.7375 - val_loss: 0.6010 - val_accuracy: 0.6795\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5152 - accuracy: 0.7449 - val_loss: 0.5907 - val_accuracy: 0.6987\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.7404 - val_loss: 0.5945 - val_accuracy: 0.6667\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5194 - accuracy: 0.7426 - val_loss: 0.5914 - val_accuracy: 0.6731\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.7392 - val_loss: 0.5990 - val_accuracy: 0.6955\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5138 - accuracy: 0.7602 - val_loss: 0.5846 - val_accuracy: 0.7179\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5160 - accuracy: 0.7460 - val_loss: 0.5949 - val_accuracy: 0.6859\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5159 - accuracy: 0.7511 - val_loss: 0.6202 - val_accuracy: 0.6763\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7353 - val_loss: 0.6101 - val_accuracy: 0.6923\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5072 - accuracy: 0.7506 - val_loss: 0.5957 - val_accuracy: 0.6955\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5088 - accuracy: 0.7477 - val_loss: 0.6106 - val_accuracy: 0.6955\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5050 - accuracy: 0.7523 - val_loss: 0.6139 - val_accuracy: 0.6955\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5128 - accuracy: 0.7506 - val_loss: 0.5963 - val_accuracy: 0.6763\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4997 - accuracy: 0.7647 - val_loss: 0.5989 - val_accuracy: 0.6827\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.7659 - val_loss: 0.5869 - val_accuracy: 0.6923\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5011 - accuracy: 0.7642 - val_loss: 0.6210 - val_accuracy: 0.6955\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4976 - accuracy: 0.7477 - val_loss: 0.6202 - val_accuracy: 0.6891\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5059 - accuracy: 0.7562 - val_loss: 0.5963 - val_accuracy: 0.6891\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4972 - accuracy: 0.7574 - val_loss: 0.6023 - val_accuracy: 0.6763\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5012 - accuracy: 0.7585 - val_loss: 0.6401 - val_accuracy: 0.6699\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4934 - accuracy: 0.7534 - val_loss: 0.5968 - val_accuracy: 0.6731\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.4897 - accuracy: 0.7625 - val_loss: 0.6027 - val_accuracy: 0.6891\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.4933 - accuracy: 0.7494 - val_loss: 0.5954 - val_accuracy: 0.6891\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7096153846153846\n",
            "Accuracy: 0.7096153846153846\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6420 - accuracy: 0.6610 - val_loss: 0.5944 - val_accuracy: 0.6891\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6309 - accuracy: 0.6616 - val_loss: 0.6187 - val_accuracy: 0.6891\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6146 - accuracy: 0.6678 - val_loss: 0.5449 - val_accuracy: 0.6923\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5997 - accuracy: 0.6814 - val_loss: 0.5550 - val_accuracy: 0.7147\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5890 - accuracy: 0.6899 - val_loss: 0.5386 - val_accuracy: 0.7532\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5831 - accuracy: 0.7086 - val_loss: 0.5399 - val_accuracy: 0.7372\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5786 - accuracy: 0.7086 - val_loss: 0.5710 - val_accuracy: 0.7115\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5759 - accuracy: 0.7115 - val_loss: 0.5463 - val_accuracy: 0.7340\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5658 - accuracy: 0.7188 - val_loss: 0.5405 - val_accuracy: 0.7179\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7245 - val_loss: 0.5606 - val_accuracy: 0.7115\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5658 - accuracy: 0.7239 - val_loss: 0.5335 - val_accuracy: 0.7340\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5613 - accuracy: 0.7268 - val_loss: 0.5424 - val_accuracy: 0.7308\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5638 - accuracy: 0.7160 - val_loss: 0.5299 - val_accuracy: 0.7436\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5533 - accuracy: 0.7353 - val_loss: 0.5537 - val_accuracy: 0.7244\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7353 - val_loss: 0.5421 - val_accuracy: 0.7372\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5565 - accuracy: 0.7205 - val_loss: 0.5483 - val_accuracy: 0.6987\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5461 - accuracy: 0.7341 - val_loss: 0.5373 - val_accuracy: 0.7468\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5493 - accuracy: 0.7256 - val_loss: 0.5381 - val_accuracy: 0.7436\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5530 - accuracy: 0.7285 - val_loss: 0.5594 - val_accuracy: 0.7244\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5552 - accuracy: 0.7273 - val_loss: 0.5371 - val_accuracy: 0.7468\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5513 - accuracy: 0.7251 - val_loss: 0.5593 - val_accuracy: 0.7340\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5494 - accuracy: 0.7398 - val_loss: 0.5434 - val_accuracy: 0.7276\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5461 - accuracy: 0.7336 - val_loss: 0.5372 - val_accuracy: 0.7372\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5576 - accuracy: 0.7222 - val_loss: 0.5375 - val_accuracy: 0.7500\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5395 - accuracy: 0.7319 - val_loss: 0.5349 - val_accuracy: 0.7468\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5477 - accuracy: 0.7256 - val_loss: 0.5292 - val_accuracy: 0.7628\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5442 - accuracy: 0.7409 - val_loss: 0.5394 - val_accuracy: 0.7404\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5375 - accuracy: 0.7211 - val_loss: 0.5413 - val_accuracy: 0.7404\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.7358 - val_loss: 0.5281 - val_accuracy: 0.7436\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5341 - accuracy: 0.7460 - val_loss: 0.5268 - val_accuracy: 0.7308\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7285 - val_loss: 0.5663 - val_accuracy: 0.7019\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5354 - accuracy: 0.7336 - val_loss: 0.5539 - val_accuracy: 0.7212\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5388 - accuracy: 0.7290 - val_loss: 0.5348 - val_accuracy: 0.7596\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7460 - val_loss: 0.5386 - val_accuracy: 0.7212\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5377 - accuracy: 0.7353 - val_loss: 0.5515 - val_accuracy: 0.7404\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5453 - accuracy: 0.7341 - val_loss: 0.5319 - val_accuracy: 0.7404\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5392 - accuracy: 0.7313 - val_loss: 0.5342 - val_accuracy: 0.7532\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5272 - accuracy: 0.7358 - val_loss: 0.5308 - val_accuracy: 0.7340\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5227 - accuracy: 0.7455 - val_loss: 0.5689 - val_accuracy: 0.7244\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5285 - accuracy: 0.7489 - val_loss: 0.5377 - val_accuracy: 0.7436\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5285 - accuracy: 0.7415 - val_loss: 0.5471 - val_accuracy: 0.7051\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5324 - accuracy: 0.7381 - val_loss: 0.5529 - val_accuracy: 0.7212\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5376 - accuracy: 0.7341 - val_loss: 0.5348 - val_accuracy: 0.7308\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5331 - accuracy: 0.7392 - val_loss: 0.5521 - val_accuracy: 0.7147\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5274 - accuracy: 0.7409 - val_loss: 0.5437 - val_accuracy: 0.7179\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5264 - accuracy: 0.7466 - val_loss: 0.5337 - val_accuracy: 0.7436\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5179 - accuracy: 0.7483 - val_loss: 0.5474 - val_accuracy: 0.7372\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7483 - val_loss: 0.5305 - val_accuracy: 0.7436\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5250 - accuracy: 0.7443 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5238 - accuracy: 0.7528 - val_loss: 0.5547 - val_accuracy: 0.7372\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6903846153846154\n",
            "Accuracy: 0.6903846153846154\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6392 - accuracy: 0.6570 - val_loss: 0.6106 - val_accuracy: 0.6795\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6309 - accuracy: 0.6576 - val_loss: 0.6252 - val_accuracy: 0.6795\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.6610 - val_loss: 0.5967 - val_accuracy: 0.7019\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6065 - accuracy: 0.6559 - val_loss: 0.5735 - val_accuracy: 0.6891\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6015 - accuracy: 0.6695 - val_loss: 0.5751 - val_accuracy: 0.6795\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5787 - accuracy: 0.6933 - val_loss: 0.6124 - val_accuracy: 0.6250\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5805 - accuracy: 0.7012 - val_loss: 0.5795 - val_accuracy: 0.6891\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5791 - accuracy: 0.6961 - val_loss: 0.5822 - val_accuracy: 0.6827\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5723 - accuracy: 0.7115 - val_loss: 0.5751 - val_accuracy: 0.6955\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5572 - accuracy: 0.7381 - val_loss: 0.5713 - val_accuracy: 0.7051\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5605 - accuracy: 0.7177 - val_loss: 0.5668 - val_accuracy: 0.7051\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5593 - accuracy: 0.7188 - val_loss: 0.5789 - val_accuracy: 0.6923\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5594 - accuracy: 0.7313 - val_loss: 0.5661 - val_accuracy: 0.7083\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5560 - accuracy: 0.7273 - val_loss: 0.5636 - val_accuracy: 0.7083\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5501 - accuracy: 0.7381 - val_loss: 0.5744 - val_accuracy: 0.6923\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5561 - accuracy: 0.7302 - val_loss: 0.5750 - val_accuracy: 0.7147\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5527 - accuracy: 0.7421 - val_loss: 0.5815 - val_accuracy: 0.7147\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5456 - accuracy: 0.7313 - val_loss: 0.6022 - val_accuracy: 0.6314\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5580 - accuracy: 0.7183 - val_loss: 0.5703 - val_accuracy: 0.6955\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5338 - accuracy: 0.7460 - val_loss: 0.6327 - val_accuracy: 0.6795\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7370 - val_loss: 0.5801 - val_accuracy: 0.7051\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7392 - val_loss: 0.6001 - val_accuracy: 0.6859\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5470 - accuracy: 0.7341 - val_loss: 0.5812 - val_accuracy: 0.6827\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7392 - val_loss: 0.5917 - val_accuracy: 0.6891\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.7347 - val_loss: 0.5900 - val_accuracy: 0.7115\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5433 - accuracy: 0.7421 - val_loss: 0.5808 - val_accuracy: 0.7083\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5344 - accuracy: 0.7449 - val_loss: 0.5689 - val_accuracy: 0.7115\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5414 - accuracy: 0.7392 - val_loss: 0.5771 - val_accuracy: 0.7115\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5295 - accuracy: 0.7353 - val_loss: 0.5797 - val_accuracy: 0.7019\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5323 - accuracy: 0.7534 - val_loss: 0.5745 - val_accuracy: 0.6891\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5334 - accuracy: 0.7443 - val_loss: 0.5730 - val_accuracy: 0.7179\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7449 - val_loss: 0.6188 - val_accuracy: 0.6955\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5224 - accuracy: 0.7477 - val_loss: 0.5778 - val_accuracy: 0.6987\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5368 - accuracy: 0.7421 - val_loss: 0.5799 - val_accuracy: 0.7051\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5346 - accuracy: 0.7466 - val_loss: 0.5762 - val_accuracy: 0.7083\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5214 - accuracy: 0.7562 - val_loss: 0.6071 - val_accuracy: 0.7051\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5247 - accuracy: 0.7472 - val_loss: 0.5819 - val_accuracy: 0.7115\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5258 - accuracy: 0.7455 - val_loss: 0.5960 - val_accuracy: 0.6891\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5214 - accuracy: 0.7472 - val_loss: 0.5860 - val_accuracy: 0.7115\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7506 - val_loss: 0.5831 - val_accuracy: 0.7212\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5291 - accuracy: 0.7443 - val_loss: 0.5840 - val_accuracy: 0.7019\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5223 - accuracy: 0.7602 - val_loss: 0.5822 - val_accuracy: 0.7051\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.7421 - val_loss: 0.5883 - val_accuracy: 0.7019\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5276 - accuracy: 0.7353 - val_loss: 0.5814 - val_accuracy: 0.6891\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5189 - accuracy: 0.7579 - val_loss: 0.5832 - val_accuracy: 0.7051\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5195 - accuracy: 0.7466 - val_loss: 0.5894 - val_accuracy: 0.7083\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5163 - accuracy: 0.7642 - val_loss: 0.6084 - val_accuracy: 0.6891\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5180 - accuracy: 0.7568 - val_loss: 0.6105 - val_accuracy: 0.7051\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5174 - accuracy: 0.7568 - val_loss: 0.6232 - val_accuracy: 0.7147\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5153 - accuracy: 0.7511 - val_loss: 0.5916 - val_accuracy: 0.6827\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7115384615384616\n",
            "Accuracy: 0.7115384615384616\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6428 - accuracy: 0.6638 - val_loss: 0.6382 - val_accuracy: 0.6859\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6278 - accuracy: 0.6644 - val_loss: 0.6056 - val_accuracy: 0.6859\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6078 - accuracy: 0.6695 - val_loss: 0.5847 - val_accuracy: 0.7308\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6066 - accuracy: 0.6769 - val_loss: 0.6036 - val_accuracy: 0.7308\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5964 - accuracy: 0.6854 - val_loss: 0.5921 - val_accuracy: 0.7276\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5902 - accuracy: 0.7041 - val_loss: 0.5445 - val_accuracy: 0.7147\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5881 - accuracy: 0.7132 - val_loss: 0.5768 - val_accuracy: 0.7115\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5761 - accuracy: 0.7052 - val_loss: 0.5505 - val_accuracy: 0.7115\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5720 - accuracy: 0.7166 - val_loss: 0.5781 - val_accuracy: 0.6891\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5743 - accuracy: 0.7160 - val_loss: 0.5518 - val_accuracy: 0.6859\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5760 - accuracy: 0.7029 - val_loss: 0.5564 - val_accuracy: 0.6987\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5683 - accuracy: 0.7251 - val_loss: 0.5355 - val_accuracy: 0.7340\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5671 - accuracy: 0.7171 - val_loss: 0.5620 - val_accuracy: 0.7340\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5606 - accuracy: 0.7075 - val_loss: 0.5354 - val_accuracy: 0.7436\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5647 - accuracy: 0.7120 - val_loss: 0.6016 - val_accuracy: 0.6442\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5589 - accuracy: 0.7251 - val_loss: 0.5435 - val_accuracy: 0.7212\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5582 - accuracy: 0.7137 - val_loss: 0.5349 - val_accuracy: 0.7340\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5575 - accuracy: 0.7273 - val_loss: 0.5461 - val_accuracy: 0.7276\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5600 - accuracy: 0.7251 - val_loss: 0.5468 - val_accuracy: 0.7244\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5570 - accuracy: 0.7080 - val_loss: 0.5410 - val_accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5485 - accuracy: 0.7353 - val_loss: 0.5478 - val_accuracy: 0.7179\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5556 - accuracy: 0.7268 - val_loss: 0.5385 - val_accuracy: 0.7436\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5463 - accuracy: 0.7279 - val_loss: 0.5397 - val_accuracy: 0.7019\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7341 - val_loss: 0.5510 - val_accuracy: 0.7051\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5399 - accuracy: 0.7347 - val_loss: 0.5610 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5560 - accuracy: 0.7205 - val_loss: 0.5559 - val_accuracy: 0.6827\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5488 - accuracy: 0.7092 - val_loss: 0.5474 - val_accuracy: 0.7147\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5507 - accuracy: 0.7330 - val_loss: 0.5344 - val_accuracy: 0.7372\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5399 - accuracy: 0.7426 - val_loss: 0.5370 - val_accuracy: 0.7372\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5419 - accuracy: 0.7290 - val_loss: 0.5277 - val_accuracy: 0.7436\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5411 - accuracy: 0.7443 - val_loss: 0.5514 - val_accuracy: 0.7276\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.7392 - val_loss: 0.5425 - val_accuracy: 0.7115\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5401 - accuracy: 0.7443 - val_loss: 0.5443 - val_accuracy: 0.7179\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.7409 - val_loss: 0.5408 - val_accuracy: 0.7340\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5408 - accuracy: 0.7415 - val_loss: 0.5413 - val_accuracy: 0.7468\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7387 - val_loss: 0.5381 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5457 - accuracy: 0.7160 - val_loss: 0.5388 - val_accuracy: 0.7468\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5298 - accuracy: 0.7415 - val_loss: 0.5816 - val_accuracy: 0.6731\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5329 - accuracy: 0.7336 - val_loss: 0.5721 - val_accuracy: 0.7019\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5302 - accuracy: 0.7336 - val_loss: 0.5309 - val_accuracy: 0.7308\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5252 - accuracy: 0.7432 - val_loss: 0.5445 - val_accuracy: 0.7179\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.7375 - val_loss: 0.5525 - val_accuracy: 0.6859\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5262 - accuracy: 0.7449 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5242 - accuracy: 0.7517 - val_loss: 0.5331 - val_accuracy: 0.7212\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5161 - accuracy: 0.7477 - val_loss: 0.5690 - val_accuracy: 0.6795\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5267 - accuracy: 0.7358 - val_loss: 0.5297 - val_accuracy: 0.7276\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5228 - accuracy: 0.7443 - val_loss: 0.5496 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5170 - accuracy: 0.7528 - val_loss: 0.5500 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5185 - accuracy: 0.7466 - val_loss: 0.5289 - val_accuracy: 0.7308\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5176 - accuracy: 0.7602 - val_loss: 0.5458 - val_accuracy: 0.7147\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7076923076923077\n",
            "Accuracy: 0.7076923076923077\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6371 - accuracy: 0.6610 - val_loss: 0.6227 - val_accuracy: 0.6795\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6276 - accuracy: 0.6650 - val_loss: 0.6119 - val_accuracy: 0.6795\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6108 - accuracy: 0.6695 - val_loss: 0.5986 - val_accuracy: 0.6859\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6139 - accuracy: 0.6706 - val_loss: 0.6047 - val_accuracy: 0.6891\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5980 - accuracy: 0.6927 - val_loss: 0.5809 - val_accuracy: 0.7147\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5805 - accuracy: 0.7012 - val_loss: 0.6107 - val_accuracy: 0.6571\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5748 - accuracy: 0.7171 - val_loss: 0.5779 - val_accuracy: 0.7276\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5717 - accuracy: 0.7018 - val_loss: 0.5825 - val_accuracy: 0.7051\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5683 - accuracy: 0.7086 - val_loss: 0.5611 - val_accuracy: 0.7308\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5610 - accuracy: 0.7273 - val_loss: 0.5636 - val_accuracy: 0.7340\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5675 - accuracy: 0.7149 - val_loss: 0.5878 - val_accuracy: 0.6795\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5688 - accuracy: 0.7115 - val_loss: 0.5712 - val_accuracy: 0.7372\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5639 - accuracy: 0.7183 - val_loss: 0.6018 - val_accuracy: 0.6731\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5573 - accuracy: 0.7188 - val_loss: 0.5785 - val_accuracy: 0.7115\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5597 - accuracy: 0.7245 - val_loss: 0.5649 - val_accuracy: 0.7404\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5593 - accuracy: 0.7217 - val_loss: 0.5689 - val_accuracy: 0.7212\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5486 - accuracy: 0.7336 - val_loss: 0.5894 - val_accuracy: 0.7083\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5505 - accuracy: 0.7296 - val_loss: 0.5644 - val_accuracy: 0.7436\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.7302 - val_loss: 0.5740 - val_accuracy: 0.7244\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7409 - val_loss: 0.5603 - val_accuracy: 0.7468\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5516 - accuracy: 0.7302 - val_loss: 0.5786 - val_accuracy: 0.7115\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7307 - val_loss: 0.5969 - val_accuracy: 0.7115\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7285 - val_loss: 0.5774 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5500 - accuracy: 0.7296 - val_loss: 0.5783 - val_accuracy: 0.7083\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5425 - accuracy: 0.7307 - val_loss: 0.5804 - val_accuracy: 0.7308\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5360 - accuracy: 0.7330 - val_loss: 0.5754 - val_accuracy: 0.7115\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5391 - accuracy: 0.7262 - val_loss: 0.5971 - val_accuracy: 0.6987\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5331 - accuracy: 0.7375 - val_loss: 0.6032 - val_accuracy: 0.6987\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5328 - accuracy: 0.7415 - val_loss: 0.5833 - val_accuracy: 0.7115\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5456 - accuracy: 0.7222 - val_loss: 0.5777 - val_accuracy: 0.7244\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5288 - accuracy: 0.7375 - val_loss: 0.5955 - val_accuracy: 0.6955\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5344 - accuracy: 0.7375 - val_loss: 0.5871 - val_accuracy: 0.6923\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5351 - accuracy: 0.7421 - val_loss: 0.5943 - val_accuracy: 0.6923\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.7404 - val_loss: 0.5958 - val_accuracy: 0.7244\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5317 - accuracy: 0.7381 - val_loss: 0.5852 - val_accuracy: 0.7083\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.7432 - val_loss: 0.5825 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5254 - accuracy: 0.7455 - val_loss: 0.5760 - val_accuracy: 0.7083\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5272 - accuracy: 0.7358 - val_loss: 0.5995 - val_accuracy: 0.6891\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7375 - val_loss: 0.5977 - val_accuracy: 0.7019\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5219 - accuracy: 0.7477 - val_loss: 0.5863 - val_accuracy: 0.7115\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5232 - accuracy: 0.7534 - val_loss: 0.6068 - val_accuracy: 0.6987\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5341 - accuracy: 0.7319 - val_loss: 0.5889 - val_accuracy: 0.6987\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5219 - accuracy: 0.7483 - val_loss: 0.5853 - val_accuracy: 0.7083\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5238 - accuracy: 0.7455 - val_loss: 0.6140 - val_accuracy: 0.7051\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5177 - accuracy: 0.7443 - val_loss: 0.5959 - val_accuracy: 0.7212\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5212 - accuracy: 0.7534 - val_loss: 0.5933 - val_accuracy: 0.7115\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5150 - accuracy: 0.7466 - val_loss: 0.5847 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5116 - accuracy: 0.7500 - val_loss: 0.5899 - val_accuracy: 0.7051\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5157 - accuracy: 0.7545 - val_loss: 0.5946 - val_accuracy: 0.7212\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5190 - accuracy: 0.7506 - val_loss: 0.5969 - val_accuracy: 0.7083\n",
            "17/17 [==============================] - 0s 3ms/step\n",
            "0.7134615384615385\n",
            "Accuracy: 0.7134615384615385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6432 - accuracy: 0.6525 - val_loss: 0.6255 - val_accuracy: 0.6474\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6347 - accuracy: 0.6542 - val_loss: 0.6075 - val_accuracy: 0.6474\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6217 - accuracy: 0.6593 - val_loss: 0.6153 - val_accuracy: 0.6763\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6124 - accuracy: 0.6644 - val_loss: 0.6588 - val_accuracy: 0.5962\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6058 - accuracy: 0.6859 - val_loss: 0.5632 - val_accuracy: 0.7179\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5893 - accuracy: 0.6893 - val_loss: 0.5772 - val_accuracy: 0.7179\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5920 - accuracy: 0.6910 - val_loss: 0.5551 - val_accuracy: 0.7404\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5868 - accuracy: 0.7024 - val_loss: 0.5430 - val_accuracy: 0.7372\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5777 - accuracy: 0.6967 - val_loss: 0.5545 - val_accuracy: 0.7532\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5743 - accuracy: 0.7035 - val_loss: 0.5260 - val_accuracy: 0.7212\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5788 - accuracy: 0.6990 - val_loss: 0.5570 - val_accuracy: 0.7147\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5690 - accuracy: 0.7211 - val_loss: 0.5290 - val_accuracy: 0.7596\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5716 - accuracy: 0.7080 - val_loss: 0.5778 - val_accuracy: 0.7468\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5572 - accuracy: 0.7222 - val_loss: 0.5257 - val_accuracy: 0.7372\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5639 - accuracy: 0.7205 - val_loss: 0.5244 - val_accuracy: 0.7660\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5560 - accuracy: 0.7256 - val_loss: 0.5536 - val_accuracy: 0.7564\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5628 - accuracy: 0.7239 - val_loss: 0.5308 - val_accuracy: 0.7404\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5634 - accuracy: 0.7086 - val_loss: 0.5375 - val_accuracy: 0.7212\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5600 - accuracy: 0.7228 - val_loss: 0.5188 - val_accuracy: 0.7564\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5558 - accuracy: 0.7313 - val_loss: 0.5539 - val_accuracy: 0.7500\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5545 - accuracy: 0.7296 - val_loss: 0.5326 - val_accuracy: 0.7404\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5545 - accuracy: 0.7268 - val_loss: 0.5264 - val_accuracy: 0.7404\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5543 - accuracy: 0.7279 - val_loss: 0.5309 - val_accuracy: 0.7372\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5501 - accuracy: 0.7268 - val_loss: 0.5200 - val_accuracy: 0.7436\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5560 - accuracy: 0.7217 - val_loss: 0.5221 - val_accuracy: 0.7308\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5496 - accuracy: 0.7307 - val_loss: 0.5269 - val_accuracy: 0.7468\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5489 - accuracy: 0.7256 - val_loss: 0.5579 - val_accuracy: 0.6859\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5505 - accuracy: 0.7324 - val_loss: 0.5202 - val_accuracy: 0.7340\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5506 - accuracy: 0.7353 - val_loss: 0.5622 - val_accuracy: 0.7212\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5460 - accuracy: 0.7364 - val_loss: 0.5078 - val_accuracy: 0.7404\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5411 - accuracy: 0.7381 - val_loss: 0.5282 - val_accuracy: 0.7724\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5414 - accuracy: 0.7353 - val_loss: 0.5245 - val_accuracy: 0.7436\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5472 - accuracy: 0.7341 - val_loss: 0.5324 - val_accuracy: 0.7308\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5472 - accuracy: 0.7313 - val_loss: 0.5186 - val_accuracy: 0.7532\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7370 - val_loss: 0.5337 - val_accuracy: 0.7244\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7239 - val_loss: 0.5223 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5434 - accuracy: 0.7387 - val_loss: 0.5238 - val_accuracy: 0.7308\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5367 - accuracy: 0.7477 - val_loss: 0.5330 - val_accuracy: 0.7404\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5419 - accuracy: 0.7290 - val_loss: 0.5522 - val_accuracy: 0.6923\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5440 - accuracy: 0.7256 - val_loss: 0.5279 - val_accuracy: 0.7468\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7432 - val_loss: 0.5358 - val_accuracy: 0.7276\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5420 - accuracy: 0.7336 - val_loss: 0.5448 - val_accuracy: 0.7051\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5323 - accuracy: 0.7364 - val_loss: 0.5492 - val_accuracy: 0.6987\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5408 - accuracy: 0.7398 - val_loss: 0.5338 - val_accuracy: 0.7276\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5269 - accuracy: 0.7506 - val_loss: 0.5238 - val_accuracy: 0.7436\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5300 - accuracy: 0.7358 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5420 - accuracy: 0.7313 - val_loss: 0.5363 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.7285 - val_loss: 0.5244 - val_accuracy: 0.7340\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5225 - accuracy: 0.7483 - val_loss: 0.5149 - val_accuracy: 0.7436\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7557 - val_loss: 0.5357 - val_accuracy: 0.7115\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7307692307692307\n",
            "Accuracy: 0.7307692307692307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 8ms/step - loss: 0.6398 - accuracy: 0.6565 - val_loss: 0.6094 - val_accuracy: 0.7212\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6319 - accuracy: 0.6519 - val_loss: 0.5743 - val_accuracy: 0.6987\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6136 - accuracy: 0.6650 - val_loss: 0.5867 - val_accuracy: 0.7404\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6041 - accuracy: 0.6876 - val_loss: 0.5385 - val_accuracy: 0.7276\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5936 - accuracy: 0.7041 - val_loss: 0.5594 - val_accuracy: 0.7179\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5874 - accuracy: 0.7035 - val_loss: 0.5456 - val_accuracy: 0.7308\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5779 - accuracy: 0.7012 - val_loss: 0.5349 - val_accuracy: 0.7372\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5719 - accuracy: 0.7171 - val_loss: 0.5378 - val_accuracy: 0.7308\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5713 - accuracy: 0.7239 - val_loss: 0.5881 - val_accuracy: 0.6795\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5723 - accuracy: 0.7188 - val_loss: 0.5503 - val_accuracy: 0.7436\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5609 - accuracy: 0.7177 - val_loss: 0.5471 - val_accuracy: 0.7340\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5646 - accuracy: 0.7279 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5591 - accuracy: 0.7245 - val_loss: 0.5295 - val_accuracy: 0.7596\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5545 - accuracy: 0.7330 - val_loss: 0.5400 - val_accuracy: 0.7404\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5502 - accuracy: 0.7392 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5699 - accuracy: 0.7166 - val_loss: 0.5366 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5509 - accuracy: 0.7392 - val_loss: 0.5310 - val_accuracy: 0.7468\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5501 - accuracy: 0.7409 - val_loss: 0.5414 - val_accuracy: 0.7436\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5477 - accuracy: 0.7290 - val_loss: 0.5265 - val_accuracy: 0.7372\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5505 - accuracy: 0.7296 - val_loss: 0.5323 - val_accuracy: 0.7212\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.7432 - val_loss: 0.5380 - val_accuracy: 0.7308\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5516 - accuracy: 0.7307 - val_loss: 0.5525 - val_accuracy: 0.7404\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5408 - accuracy: 0.7438 - val_loss: 0.5326 - val_accuracy: 0.7404\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5381 - accuracy: 0.7353 - val_loss: 0.5393 - val_accuracy: 0.7436\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5341 - accuracy: 0.7472 - val_loss: 0.5387 - val_accuracy: 0.7372\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.7392 - val_loss: 0.5477 - val_accuracy: 0.7051\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5357 - accuracy: 0.7489 - val_loss: 0.5440 - val_accuracy: 0.7404\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5411 - accuracy: 0.7375 - val_loss: 0.5627 - val_accuracy: 0.7308\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.7534 - val_loss: 0.5477 - val_accuracy: 0.7340\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5399 - accuracy: 0.7347 - val_loss: 0.5561 - val_accuracy: 0.7019\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5275 - accuracy: 0.7426 - val_loss: 0.5798 - val_accuracy: 0.6955\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5269 - accuracy: 0.7455 - val_loss: 0.5961 - val_accuracy: 0.7019\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.7375 - val_loss: 0.5244 - val_accuracy: 0.7468\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5388 - accuracy: 0.7483 - val_loss: 0.5441 - val_accuracy: 0.7308\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5291 - accuracy: 0.7489 - val_loss: 0.5393 - val_accuracy: 0.7308\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5254 - accuracy: 0.7477 - val_loss: 0.5398 - val_accuracy: 0.7372\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5283 - accuracy: 0.7523 - val_loss: 0.5578 - val_accuracy: 0.7372\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7613 - val_loss: 0.5607 - val_accuracy: 0.7147\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7489 - val_loss: 0.5484 - val_accuracy: 0.7115\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5323 - accuracy: 0.7494 - val_loss: 0.5532 - val_accuracy: 0.7372\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5277 - accuracy: 0.7517 - val_loss: 0.5391 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7472 - val_loss: 0.5474 - val_accuracy: 0.7276\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.7517 - val_loss: 0.5829 - val_accuracy: 0.7083\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5211 - accuracy: 0.7534 - val_loss: 0.5714 - val_accuracy: 0.7083\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5258 - accuracy: 0.7551 - val_loss: 0.5787 - val_accuracy: 0.7212\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5172 - accuracy: 0.7642 - val_loss: 0.5613 - val_accuracy: 0.7340\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5136 - accuracy: 0.7579 - val_loss: 0.5595 - val_accuracy: 0.7244\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5089 - accuracy: 0.7545 - val_loss: 0.5887 - val_accuracy: 0.6987\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5290 - accuracy: 0.7472 - val_loss: 0.5611 - val_accuracy: 0.7340\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5164 - accuracy: 0.7545 - val_loss: 0.6176 - val_accuracy: 0.7179\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7288461538461538\n",
            "Accuracy: 0.7288461538461538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6319 - accuracy: 0.6706 - val_loss: 0.6130 - val_accuracy: 0.6506\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6203 - accuracy: 0.6701 - val_loss: 0.6135 - val_accuracy: 0.6506\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6044 - accuracy: 0.6621 - val_loss: 0.5766 - val_accuracy: 0.6506\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5989 - accuracy: 0.6757 - val_loss: 0.5838 - val_accuracy: 0.7179\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5887 - accuracy: 0.6893 - val_loss: 0.5678 - val_accuracy: 0.7276\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5702 - accuracy: 0.7132 - val_loss: 0.5400 - val_accuracy: 0.7468\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5716 - accuracy: 0.7132 - val_loss: 0.5510 - val_accuracy: 0.7372\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5700 - accuracy: 0.7132 - val_loss: 0.5536 - val_accuracy: 0.7340\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5683 - accuracy: 0.7211 - val_loss: 0.5348 - val_accuracy: 0.7468\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5612 - accuracy: 0.7171 - val_loss: 0.5441 - val_accuracy: 0.7372\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5620 - accuracy: 0.7200 - val_loss: 0.5664 - val_accuracy: 0.6731\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5584 - accuracy: 0.7234 - val_loss: 0.5427 - val_accuracy: 0.7404\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5507 - accuracy: 0.7330 - val_loss: 0.5682 - val_accuracy: 0.6795\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5474 - accuracy: 0.7268 - val_loss: 0.5523 - val_accuracy: 0.7436\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5504 - accuracy: 0.7296 - val_loss: 0.5278 - val_accuracy: 0.7532\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5576 - accuracy: 0.7217 - val_loss: 0.5255 - val_accuracy: 0.7468\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5501 - accuracy: 0.7341 - val_loss: 0.5458 - val_accuracy: 0.7404\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5546 - accuracy: 0.7330 - val_loss: 0.5357 - val_accuracy: 0.7404\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5502 - accuracy: 0.7330 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5578 - accuracy: 0.7330 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5487 - accuracy: 0.7234 - val_loss: 0.5726 - val_accuracy: 0.7051\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5523 - accuracy: 0.7353 - val_loss: 0.5302 - val_accuracy: 0.7660\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5470 - accuracy: 0.7358 - val_loss: 0.5253 - val_accuracy: 0.7628\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5467 - accuracy: 0.7273 - val_loss: 0.5266 - val_accuracy: 0.7628\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.7358 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5394 - accuracy: 0.7392 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5448 - accuracy: 0.7341 - val_loss: 0.5502 - val_accuracy: 0.7147\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5347 - accuracy: 0.7438 - val_loss: 0.5317 - val_accuracy: 0.7596\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5517 - accuracy: 0.7222 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7409 - val_loss: 0.5412 - val_accuracy: 0.7468\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5370 - accuracy: 0.7438 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5293 - accuracy: 0.7370 - val_loss: 0.5265 - val_accuracy: 0.7532\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5329 - accuracy: 0.7336 - val_loss: 0.5237 - val_accuracy: 0.7564\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5395 - accuracy: 0.7296 - val_loss: 0.5362 - val_accuracy: 0.7628\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5289 - accuracy: 0.7421 - val_loss: 0.5474 - val_accuracy: 0.7340\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5393 - accuracy: 0.7205 - val_loss: 0.5380 - val_accuracy: 0.7564\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5383 - accuracy: 0.7392 - val_loss: 0.5325 - val_accuracy: 0.7628\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5232 - accuracy: 0.7545 - val_loss: 0.5464 - val_accuracy: 0.7564\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.7455 - val_loss: 0.5462 - val_accuracy: 0.7276\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5317 - accuracy: 0.7528 - val_loss: 0.5691 - val_accuracy: 0.7147\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5263 - accuracy: 0.7415 - val_loss: 0.5459 - val_accuracy: 0.7436\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5212 - accuracy: 0.7523 - val_loss: 0.5324 - val_accuracy: 0.7564\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5251 - accuracy: 0.7494 - val_loss: 0.5323 - val_accuracy: 0.7564\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5194 - accuracy: 0.7404 - val_loss: 0.5313 - val_accuracy: 0.7596\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5163 - accuracy: 0.7545 - val_loss: 0.5330 - val_accuracy: 0.7372\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5218 - accuracy: 0.7472 - val_loss: 0.5509 - val_accuracy: 0.7244\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5150 - accuracy: 0.7483 - val_loss: 0.5380 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5189 - accuracy: 0.7545 - val_loss: 0.5557 - val_accuracy: 0.7212\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5148 - accuracy: 0.7472 - val_loss: 0.5499 - val_accuracy: 0.7468\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5227 - accuracy: 0.7557 - val_loss: 0.5488 - val_accuracy: 0.7340\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7134615384615385\n",
            "Accuracy: 0.7134615384615385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 9ms/step - loss: 0.6471 - accuracy: 0.6576 - val_loss: 0.6148 - val_accuracy: 0.6635\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6296 - accuracy: 0.6587 - val_loss: 0.5809 - val_accuracy: 0.6635\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6294 - accuracy: 0.6599 - val_loss: 0.5848 - val_accuracy: 0.6635\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6057 - accuracy: 0.6740 - val_loss: 0.5837 - val_accuracy: 0.7340\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.6984 - val_loss: 0.5715 - val_accuracy: 0.6795\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5962 - accuracy: 0.6842 - val_loss: 0.5653 - val_accuracy: 0.7372\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5839 - accuracy: 0.7092 - val_loss: 0.5985 - val_accuracy: 0.6827\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5735 - accuracy: 0.6933 - val_loss: 0.6110 - val_accuracy: 0.6891\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5674 - accuracy: 0.7154 - val_loss: 0.5742 - val_accuracy: 0.7019\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5782 - accuracy: 0.7092 - val_loss: 0.5521 - val_accuracy: 0.7244\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5577 - accuracy: 0.7217 - val_loss: 0.5499 - val_accuracy: 0.7276\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5585 - accuracy: 0.7126 - val_loss: 0.5502 - val_accuracy: 0.7244\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5536 - accuracy: 0.7245 - val_loss: 0.5517 - val_accuracy: 0.7372\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5617 - accuracy: 0.7251 - val_loss: 0.5547 - val_accuracy: 0.7147\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5570 - accuracy: 0.7166 - val_loss: 0.5577 - val_accuracy: 0.7212\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5504 - accuracy: 0.7273 - val_loss: 0.5508 - val_accuracy: 0.7372\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5515 - accuracy: 0.7307 - val_loss: 0.5542 - val_accuracy: 0.7372\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5409 - accuracy: 0.7302 - val_loss: 0.5564 - val_accuracy: 0.7244\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5439 - accuracy: 0.7228 - val_loss: 0.5673 - val_accuracy: 0.7340\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5565 - accuracy: 0.7200 - val_loss: 0.6133 - val_accuracy: 0.7051\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5453 - accuracy: 0.7347 - val_loss: 0.5627 - val_accuracy: 0.7212\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5420 - accuracy: 0.7330 - val_loss: 0.5536 - val_accuracy: 0.7244\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5353 - accuracy: 0.7324 - val_loss: 0.5857 - val_accuracy: 0.7051\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5339 - accuracy: 0.7319 - val_loss: 0.5603 - val_accuracy: 0.7308\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5335 - accuracy: 0.7330 - val_loss: 0.5646 - val_accuracy: 0.7276\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5262 - accuracy: 0.7528 - val_loss: 0.5728 - val_accuracy: 0.7051\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7347 - val_loss: 0.5562 - val_accuracy: 0.7404\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7455 - val_loss: 0.5692 - val_accuracy: 0.7019\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.7421 - val_loss: 0.5804 - val_accuracy: 0.7276\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5409 - accuracy: 0.7370 - val_loss: 0.5673 - val_accuracy: 0.7340\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5229 - accuracy: 0.7404 - val_loss: 0.6086 - val_accuracy: 0.7244\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5328 - accuracy: 0.7353 - val_loss: 0.5628 - val_accuracy: 0.7147\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5220 - accuracy: 0.7460 - val_loss: 0.5812 - val_accuracy: 0.7244\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.7426 - val_loss: 0.5727 - val_accuracy: 0.7083\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5354 - accuracy: 0.7443 - val_loss: 0.5545 - val_accuracy: 0.7340\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5295 - accuracy: 0.7432 - val_loss: 0.5505 - val_accuracy: 0.7372\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5165 - accuracy: 0.7534 - val_loss: 0.5590 - val_accuracy: 0.7212\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5269 - accuracy: 0.7466 - val_loss: 0.5654 - val_accuracy: 0.7019\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5240 - accuracy: 0.7336 - val_loss: 0.5761 - val_accuracy: 0.6731\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5145 - accuracy: 0.7545 - val_loss: 0.5820 - val_accuracy: 0.7147\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5243 - accuracy: 0.7421 - val_loss: 0.5512 - val_accuracy: 0.7115\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5194 - accuracy: 0.7421 - val_loss: 0.5544 - val_accuracy: 0.7372\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5106 - accuracy: 0.7472 - val_loss: 0.5629 - val_accuracy: 0.7244\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5225 - accuracy: 0.7483 - val_loss: 0.5574 - val_accuracy: 0.7179\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5160 - accuracy: 0.7562 - val_loss: 0.5767 - val_accuracy: 0.7147\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5123 - accuracy: 0.7460 - val_loss: 0.5668 - val_accuracy: 0.7147\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5119 - accuracy: 0.7449 - val_loss: 0.5867 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.7579 - val_loss: 0.5920 - val_accuracy: 0.7244\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5141 - accuracy: 0.7466 - val_loss: 0.5822 - val_accuracy: 0.7179\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5142 - accuracy: 0.7494 - val_loss: 0.5908 - val_accuracy: 0.7147\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7365384615384616\n",
            "Accuracy: 0.7365384615384616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6396 - accuracy: 0.6536 - val_loss: 0.6102 - val_accuracy: 0.6955\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6263 - accuracy: 0.6536 - val_loss: 0.6313 - val_accuracy: 0.7212\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6136 - accuracy: 0.6525 - val_loss: 0.5998 - val_accuracy: 0.7276\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5958 - accuracy: 0.6791 - val_loss: 0.6335 - val_accuracy: 0.6250\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6002 - accuracy: 0.6893 - val_loss: 0.5839 - val_accuracy: 0.7179\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5807 - accuracy: 0.7052 - val_loss: 0.5710 - val_accuracy: 0.7147\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5677 - accuracy: 0.7166 - val_loss: 0.5852 - val_accuracy: 0.6955\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5651 - accuracy: 0.7115 - val_loss: 0.5643 - val_accuracy: 0.7340\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5681 - accuracy: 0.7115 - val_loss: 0.5738 - val_accuracy: 0.7179\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5667 - accuracy: 0.7222 - val_loss: 0.5673 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5579 - accuracy: 0.7290 - val_loss: 0.5673 - val_accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5593 - accuracy: 0.7188 - val_loss: 0.5699 - val_accuracy: 0.6987\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5498 - accuracy: 0.7268 - val_loss: 0.6097 - val_accuracy: 0.6667\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5538 - accuracy: 0.7251 - val_loss: 0.6100 - val_accuracy: 0.6635\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5497 - accuracy: 0.7313 - val_loss: 0.5584 - val_accuracy: 0.7212\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5464 - accuracy: 0.7375 - val_loss: 0.5629 - val_accuracy: 0.7340\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5579 - accuracy: 0.7160 - val_loss: 0.5845 - val_accuracy: 0.7083\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5470 - accuracy: 0.7307 - val_loss: 0.5567 - val_accuracy: 0.7372\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5388 - accuracy: 0.7398 - val_loss: 0.5604 - val_accuracy: 0.7212\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5370 - accuracy: 0.7381 - val_loss: 0.5419 - val_accuracy: 0.7532\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5482 - accuracy: 0.7251 - val_loss: 0.5478 - val_accuracy: 0.7596\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5502 - accuracy: 0.7381 - val_loss: 0.5534 - val_accuracy: 0.7468\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5351 - accuracy: 0.7472 - val_loss: 0.6056 - val_accuracy: 0.6955\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5405 - accuracy: 0.7421 - val_loss: 0.5593 - val_accuracy: 0.7340\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5494 - accuracy: 0.7336 - val_loss: 0.5645 - val_accuracy: 0.7308\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.7460 - val_loss: 0.5380 - val_accuracy: 0.7564\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5350 - accuracy: 0.7398 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.7568 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5324 - accuracy: 0.7466 - val_loss: 0.5920 - val_accuracy: 0.7051\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5340 - accuracy: 0.7449 - val_loss: 0.5790 - val_accuracy: 0.7276\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5335 - accuracy: 0.7449 - val_loss: 0.5696 - val_accuracy: 0.7179\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5226 - accuracy: 0.7523 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5191 - accuracy: 0.7489 - val_loss: 0.5601 - val_accuracy: 0.7308\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5217 - accuracy: 0.7545 - val_loss: 0.5745 - val_accuracy: 0.7564\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5303 - accuracy: 0.7387 - val_loss: 0.5612 - val_accuracy: 0.7276\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5298 - accuracy: 0.7415 - val_loss: 0.5714 - val_accuracy: 0.7244\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7483 - val_loss: 0.5558 - val_accuracy: 0.7532\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5171 - accuracy: 0.7500 - val_loss: 0.5638 - val_accuracy: 0.7340\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.7489 - val_loss: 0.5643 - val_accuracy: 0.7564\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.7562 - val_loss: 0.5524 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7426 - val_loss: 0.5900 - val_accuracy: 0.7051\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5194 - accuracy: 0.7472 - val_loss: 0.5734 - val_accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5217 - accuracy: 0.7426 - val_loss: 0.6129 - val_accuracy: 0.7147\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7506 - val_loss: 0.5948 - val_accuracy: 0.7179\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5317 - accuracy: 0.7336 - val_loss: 0.5568 - val_accuracy: 0.7532\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.7483 - val_loss: 0.6077 - val_accuracy: 0.7051\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.7506 - val_loss: 0.5687 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5177 - accuracy: 0.7534 - val_loss: 0.5720 - val_accuracy: 0.7436\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5067 - accuracy: 0.7574 - val_loss: 0.5988 - val_accuracy: 0.7051\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5144 - accuracy: 0.7500 - val_loss: 0.5787 - val_accuracy: 0.7404\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7423076923076923\n",
            "Accuracy: 0.7423076923076923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6387 - accuracy: 0.6604 - val_loss: 0.6352 - val_accuracy: 0.6731\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6263 - accuracy: 0.6650 - val_loss: 0.6362 - val_accuracy: 0.6731\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.6678 - val_loss: 0.6147 - val_accuracy: 0.6667\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6036 - accuracy: 0.6718 - val_loss: 0.5916 - val_accuracy: 0.6955\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5960 - accuracy: 0.6905 - val_loss: 0.6258 - val_accuracy: 0.6571\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5884 - accuracy: 0.6905 - val_loss: 0.5896 - val_accuracy: 0.6923\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5736 - accuracy: 0.7052 - val_loss: 0.6135 - val_accuracy: 0.6763\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5611 - accuracy: 0.7228 - val_loss: 0.5873 - val_accuracy: 0.6955\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5688 - accuracy: 0.7166 - val_loss: 0.6069 - val_accuracy: 0.6763\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5718 - accuracy: 0.7029 - val_loss: 0.5867 - val_accuracy: 0.7147\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5632 - accuracy: 0.7251 - val_loss: 0.5898 - val_accuracy: 0.7019\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5625 - accuracy: 0.7211 - val_loss: 0.5804 - val_accuracy: 0.7147\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5543 - accuracy: 0.7313 - val_loss: 0.5870 - val_accuracy: 0.7019\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5509 - accuracy: 0.7364 - val_loss: 0.5821 - val_accuracy: 0.7179\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7188 - val_loss: 0.6002 - val_accuracy: 0.7019\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5550 - accuracy: 0.7063 - val_loss: 0.5801 - val_accuracy: 0.7340\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5381 - accuracy: 0.7296 - val_loss: 0.6234 - val_accuracy: 0.6859\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5518 - accuracy: 0.7302 - val_loss: 0.5870 - val_accuracy: 0.7179\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5430 - accuracy: 0.7262 - val_loss: 0.6235 - val_accuracy: 0.6506\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5538 - accuracy: 0.7262 - val_loss: 0.6041 - val_accuracy: 0.6987\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5417 - accuracy: 0.7421 - val_loss: 0.6035 - val_accuracy: 0.7179\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.7319 - val_loss: 0.5944 - val_accuracy: 0.7147\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5380 - accuracy: 0.7341 - val_loss: 0.5825 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5362 - accuracy: 0.7313 - val_loss: 0.6185 - val_accuracy: 0.6731\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5285 - accuracy: 0.7302 - val_loss: 0.5868 - val_accuracy: 0.7212\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5259 - accuracy: 0.7421 - val_loss: 0.5845 - val_accuracy: 0.7147\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5238 - accuracy: 0.7483 - val_loss: 0.6685 - val_accuracy: 0.6410\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5306 - accuracy: 0.7409 - val_loss: 0.6338 - val_accuracy: 0.6538\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5242 - accuracy: 0.7523 - val_loss: 0.5943 - val_accuracy: 0.7147\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5346 - accuracy: 0.7494 - val_loss: 0.5909 - val_accuracy: 0.7115\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5334 - accuracy: 0.7336 - val_loss: 0.6074 - val_accuracy: 0.7019\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5257 - accuracy: 0.7443 - val_loss: 0.5904 - val_accuracy: 0.7308\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.7477 - val_loss: 0.5862 - val_accuracy: 0.7147\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5219 - accuracy: 0.7426 - val_loss: 0.6031 - val_accuracy: 0.7308\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5170 - accuracy: 0.7540 - val_loss: 0.5908 - val_accuracy: 0.7147\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5111 - accuracy: 0.7568 - val_loss: 0.6077 - val_accuracy: 0.7244\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5152 - accuracy: 0.7591 - val_loss: 0.5962 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7438 - val_loss: 0.5890 - val_accuracy: 0.7340\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7438 - val_loss: 0.6341 - val_accuracy: 0.6410\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.7494 - val_loss: 0.5952 - val_accuracy: 0.7115\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5261 - accuracy: 0.7517 - val_loss: 0.6180 - val_accuracy: 0.6795\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5191 - accuracy: 0.7534 - val_loss: 0.5979 - val_accuracy: 0.7276\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5194 - accuracy: 0.7460 - val_loss: 0.6022 - val_accuracy: 0.7212\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.7500 - val_loss: 0.6098 - val_accuracy: 0.7115\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5086 - accuracy: 0.7500 - val_loss: 0.6182 - val_accuracy: 0.7019\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.7579 - val_loss: 0.6545 - val_accuracy: 0.7212\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5086 - accuracy: 0.7557 - val_loss: 0.6058 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5163 - accuracy: 0.7540 - val_loss: 0.6024 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.7528 - val_loss: 0.6897 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.7551 - val_loss: 0.6191 - val_accuracy: 0.7179\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7192307692307692\n",
            "Accuracy: 0.7192307692307692\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6451 - accuracy: 0.6531 - val_loss: 0.6599 - val_accuracy: 0.6474\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6349 - accuracy: 0.6565 - val_loss: 0.6234 - val_accuracy: 0.6474\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6260 - accuracy: 0.6570 - val_loss: 0.6228 - val_accuracy: 0.6474\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6236 - accuracy: 0.6604 - val_loss: 0.5920 - val_accuracy: 0.6859\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6028 - accuracy: 0.6893 - val_loss: 0.6175 - val_accuracy: 0.6731\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5857 - accuracy: 0.7075 - val_loss: 0.5851 - val_accuracy: 0.7051\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5744 - accuracy: 0.7154 - val_loss: 0.5804 - val_accuracy: 0.6763\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5734 - accuracy: 0.7177 - val_loss: 0.5908 - val_accuracy: 0.7083\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5656 - accuracy: 0.7234 - val_loss: 0.5999 - val_accuracy: 0.6603\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5681 - accuracy: 0.7137 - val_loss: 0.5716 - val_accuracy: 0.6795\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5650 - accuracy: 0.7319 - val_loss: 0.5892 - val_accuracy: 0.6763\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5567 - accuracy: 0.7262 - val_loss: 0.5849 - val_accuracy: 0.7051\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.7268 - val_loss: 0.5908 - val_accuracy: 0.6795\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5606 - accuracy: 0.7290 - val_loss: 0.5722 - val_accuracy: 0.7115\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5479 - accuracy: 0.7290 - val_loss: 0.5708 - val_accuracy: 0.6891\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5441 - accuracy: 0.7455 - val_loss: 0.5846 - val_accuracy: 0.7019\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5481 - accuracy: 0.7273 - val_loss: 0.5877 - val_accuracy: 0.7083\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5443 - accuracy: 0.7341 - val_loss: 0.5801 - val_accuracy: 0.6923\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5398 - accuracy: 0.7392 - val_loss: 0.5794 - val_accuracy: 0.6827\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5516 - accuracy: 0.7217 - val_loss: 0.5861 - val_accuracy: 0.7051\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5414 - accuracy: 0.7353 - val_loss: 0.5760 - val_accuracy: 0.6859\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5302 - accuracy: 0.7540 - val_loss: 0.5843 - val_accuracy: 0.6763\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5349 - accuracy: 0.7443 - val_loss: 0.6175 - val_accuracy: 0.6603\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5375 - accuracy: 0.7409 - val_loss: 0.5816 - val_accuracy: 0.6987\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5299 - accuracy: 0.7517 - val_loss: 0.5830 - val_accuracy: 0.6923\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5373 - accuracy: 0.7438 - val_loss: 0.6010 - val_accuracy: 0.7051\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5386 - accuracy: 0.7245 - val_loss: 0.6108 - val_accuracy: 0.6859\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5307 - accuracy: 0.7415 - val_loss: 0.5988 - val_accuracy: 0.7051\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5291 - accuracy: 0.7426 - val_loss: 0.5954 - val_accuracy: 0.7019\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5318 - accuracy: 0.7426 - val_loss: 0.5877 - val_accuracy: 0.7019\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5325 - accuracy: 0.7375 - val_loss: 0.5857 - val_accuracy: 0.6763\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5255 - accuracy: 0.7534 - val_loss: 0.5836 - val_accuracy: 0.7179\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5294 - accuracy: 0.7455 - val_loss: 0.5982 - val_accuracy: 0.6923\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5287 - accuracy: 0.7460 - val_loss: 0.6082 - val_accuracy: 0.7083\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5208 - accuracy: 0.7523 - val_loss: 0.5996 - val_accuracy: 0.6859\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5228 - accuracy: 0.7545 - val_loss: 0.5910 - val_accuracy: 0.6859\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5198 - accuracy: 0.7472 - val_loss: 0.6017 - val_accuracy: 0.7083\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7540 - val_loss: 0.6713 - val_accuracy: 0.7051\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5162 - accuracy: 0.7517 - val_loss: 0.5980 - val_accuracy: 0.7147\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5233 - accuracy: 0.7517 - val_loss: 0.6067 - val_accuracy: 0.6987\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5142 - accuracy: 0.7647 - val_loss: 0.6349 - val_accuracy: 0.7115\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5190 - accuracy: 0.7455 - val_loss: 0.5875 - val_accuracy: 0.7051\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5082 - accuracy: 0.7574 - val_loss: 0.6167 - val_accuracy: 0.7019\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.7613 - val_loss: 0.5890 - val_accuracy: 0.7147\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5141 - accuracy: 0.7557 - val_loss: 0.5956 - val_accuracy: 0.7147\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5269 - accuracy: 0.7511 - val_loss: 0.5865 - val_accuracy: 0.6987\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5020 - accuracy: 0.7642 - val_loss: 0.6013 - val_accuracy: 0.7083\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5050 - accuracy: 0.7698 - val_loss: 0.6012 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5059 - accuracy: 0.7608 - val_loss: 0.6108 - val_accuracy: 0.6923\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5117 - accuracy: 0.7579 - val_loss: 0.6051 - val_accuracy: 0.7083\n",
            "17/17 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7346153846153847\n",
            "Accuracy: 0.7346153846153847\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6372 - accuracy: 0.6525 - val_loss: 0.6279 - val_accuracy: 0.6731\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.6616 - val_loss: 0.5954 - val_accuracy: 0.6795\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6192 - accuracy: 0.6587 - val_loss: 0.6177 - val_accuracy: 0.6506\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5920 - accuracy: 0.7024 - val_loss: 0.5785 - val_accuracy: 0.7019\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5893 - accuracy: 0.6967 - val_loss: 0.5980 - val_accuracy: 0.7212\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5853 - accuracy: 0.6973 - val_loss: 0.5635 - val_accuracy: 0.7340\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5978 - accuracy: 0.6950 - val_loss: 0.5653 - val_accuracy: 0.7244\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5700 - accuracy: 0.7132 - val_loss: 0.5699 - val_accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5732 - accuracy: 0.6995 - val_loss: 0.5662 - val_accuracy: 0.7212\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5660 - accuracy: 0.7183 - val_loss: 0.5762 - val_accuracy: 0.7179\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5676 - accuracy: 0.7154 - val_loss: 0.5637 - val_accuracy: 0.7468\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5518 - accuracy: 0.7234 - val_loss: 0.5651 - val_accuracy: 0.7340\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5517 - accuracy: 0.7302 - val_loss: 0.5626 - val_accuracy: 0.7051\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5644 - accuracy: 0.7183 - val_loss: 0.5679 - val_accuracy: 0.7244\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5533 - accuracy: 0.7336 - val_loss: 0.5637 - val_accuracy: 0.7340\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5557 - accuracy: 0.7256 - val_loss: 0.5585 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5530 - accuracy: 0.7290 - val_loss: 0.5683 - val_accuracy: 0.7051\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5491 - accuracy: 0.7296 - val_loss: 0.5574 - val_accuracy: 0.7308\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7296 - val_loss: 0.5512 - val_accuracy: 0.7372\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5506 - accuracy: 0.7268 - val_loss: 0.5654 - val_accuracy: 0.7308\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5489 - accuracy: 0.7239 - val_loss: 0.5691 - val_accuracy: 0.7212\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5450 - accuracy: 0.7347 - val_loss: 0.5565 - val_accuracy: 0.7404\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7460 - val_loss: 0.5712 - val_accuracy: 0.7019\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5410 - accuracy: 0.7364 - val_loss: 0.5496 - val_accuracy: 0.7436\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5384 - accuracy: 0.7324 - val_loss: 0.5641 - val_accuracy: 0.7147\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5321 - accuracy: 0.7460 - val_loss: 0.5588 - val_accuracy: 0.7276\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5326 - accuracy: 0.7319 - val_loss: 0.5891 - val_accuracy: 0.6731\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5390 - accuracy: 0.7347 - val_loss: 0.5570 - val_accuracy: 0.7372\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5252 - accuracy: 0.7449 - val_loss: 0.5709 - val_accuracy: 0.7147\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5312 - accuracy: 0.7494 - val_loss: 0.5565 - val_accuracy: 0.7244\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5275 - accuracy: 0.7557 - val_loss: 0.5625 - val_accuracy: 0.7308\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5335 - accuracy: 0.7443 - val_loss: 0.5742 - val_accuracy: 0.7179\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5338 - accuracy: 0.7477 - val_loss: 0.5669 - val_accuracy: 0.7212\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7415 - val_loss: 0.5773 - val_accuracy: 0.6795\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7545 - val_loss: 0.5653 - val_accuracy: 0.7115\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5249 - accuracy: 0.7483 - val_loss: 0.5711 - val_accuracy: 0.7083\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5196 - accuracy: 0.7562 - val_loss: 0.5607 - val_accuracy: 0.7276\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5273 - accuracy: 0.7500 - val_loss: 0.5586 - val_accuracy: 0.7276\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5273 - accuracy: 0.7409 - val_loss: 0.5613 - val_accuracy: 0.7308\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.7596 - val_loss: 0.5950 - val_accuracy: 0.6955\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7477 - val_loss: 0.5780 - val_accuracy: 0.7276\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5150 - accuracy: 0.7585 - val_loss: 0.6015 - val_accuracy: 0.6955\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5282 - accuracy: 0.7364 - val_loss: 0.5663 - val_accuracy: 0.7340\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5163 - accuracy: 0.7591 - val_loss: 0.5526 - val_accuracy: 0.7372\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5134 - accuracy: 0.7534 - val_loss: 0.5595 - val_accuracy: 0.7212\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5197 - accuracy: 0.7517 - val_loss: 0.5722 - val_accuracy: 0.7147\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5068 - accuracy: 0.7551 - val_loss: 0.5704 - val_accuracy: 0.7115\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.7477 - val_loss: 0.5910 - val_accuracy: 0.7212\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5111 - accuracy: 0.7579 - val_loss: 0.5738 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5205 - accuracy: 0.7449 - val_loss: 0.5598 - val_accuracy: 0.7212\n",
            "17/17 [==============================] - 0s 3ms/step\n",
            "0.7230769230769231\n",
            "Accuracy: 0.7230769230769231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6413 - accuracy: 0.6497 - val_loss: 0.6173 - val_accuracy: 0.6795\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6131 - accuracy: 0.6786 - val_loss: 0.5959 - val_accuracy: 0.6987\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6003 - accuracy: 0.6859 - val_loss: 0.5750 - val_accuracy: 0.7340\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6017 - accuracy: 0.6848 - val_loss: 0.5926 - val_accuracy: 0.6731\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5957 - accuracy: 0.6740 - val_loss: 0.5766 - val_accuracy: 0.7308\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5797 - accuracy: 0.6995 - val_loss: 0.6150 - val_accuracy: 0.6987\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5866 - accuracy: 0.6961 - val_loss: 0.5563 - val_accuracy: 0.7468\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5688 - accuracy: 0.7109 - val_loss: 0.5889 - val_accuracy: 0.6571\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5674 - accuracy: 0.7177 - val_loss: 0.5714 - val_accuracy: 0.6987\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5681 - accuracy: 0.7205 - val_loss: 0.5520 - val_accuracy: 0.7468\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5680 - accuracy: 0.7063 - val_loss: 0.5636 - val_accuracy: 0.7436\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5638 - accuracy: 0.7109 - val_loss: 0.5522 - val_accuracy: 0.7340\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5652 - accuracy: 0.7166 - val_loss: 0.5521 - val_accuracy: 0.7404\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5567 - accuracy: 0.7228 - val_loss: 0.5608 - val_accuracy: 0.7244\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5556 - accuracy: 0.7200 - val_loss: 0.5490 - val_accuracy: 0.7532\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5552 - accuracy: 0.7200 - val_loss: 0.5704 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5569 - accuracy: 0.7115 - val_loss: 0.5536 - val_accuracy: 0.7372\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5530 - accuracy: 0.7211 - val_loss: 0.5491 - val_accuracy: 0.7628\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5522 - accuracy: 0.7194 - val_loss: 0.5565 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.7268 - val_loss: 0.5532 - val_accuracy: 0.7468\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.7222 - val_loss: 0.5585 - val_accuracy: 0.7468\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5514 - accuracy: 0.7290 - val_loss: 0.5466 - val_accuracy: 0.7596\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5396 - accuracy: 0.7313 - val_loss: 0.5548 - val_accuracy: 0.7596\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5487 - accuracy: 0.7285 - val_loss: 0.5473 - val_accuracy: 0.7564\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5462 - accuracy: 0.7347 - val_loss: 0.5580 - val_accuracy: 0.7147\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5462 - accuracy: 0.7239 - val_loss: 0.5549 - val_accuracy: 0.7212\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5434 - accuracy: 0.7358 - val_loss: 0.5532 - val_accuracy: 0.7628\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.7290 - val_loss: 0.5668 - val_accuracy: 0.6859\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.7336 - val_loss: 0.5532 - val_accuracy: 0.7500\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5484 - accuracy: 0.7222 - val_loss: 0.5538 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5461 - accuracy: 0.7302 - val_loss: 0.5556 - val_accuracy: 0.7372\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.7353 - val_loss: 0.5840 - val_accuracy: 0.6603\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5414 - accuracy: 0.7324 - val_loss: 0.5599 - val_accuracy: 0.7340\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7358 - val_loss: 0.5480 - val_accuracy: 0.7724\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5369 - accuracy: 0.7285 - val_loss: 0.5662 - val_accuracy: 0.7596\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5408 - accuracy: 0.7387 - val_loss: 0.5609 - val_accuracy: 0.7596\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5419 - accuracy: 0.7279 - val_loss: 0.5450 - val_accuracy: 0.7564\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5320 - accuracy: 0.7358 - val_loss: 0.5703 - val_accuracy: 0.7051\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5364 - accuracy: 0.7319 - val_loss: 0.5498 - val_accuracy: 0.7500\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5400 - accuracy: 0.7324 - val_loss: 0.5655 - val_accuracy: 0.7340\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.7330 - val_loss: 0.6262 - val_accuracy: 0.6346\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.7256 - val_loss: 0.5578 - val_accuracy: 0.7532\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5309 - accuracy: 0.7392 - val_loss: 0.5546 - val_accuracy: 0.7372\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5390 - accuracy: 0.7415 - val_loss: 0.5717 - val_accuracy: 0.7276\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5282 - accuracy: 0.7364 - val_loss: 0.5464 - val_accuracy: 0.7596\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5357 - accuracy: 0.7262 - val_loss: 0.5529 - val_accuracy: 0.7532\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5270 - accuracy: 0.7387 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5208 - accuracy: 0.7421 - val_loss: 0.5876 - val_accuracy: 0.7308\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5391 - accuracy: 0.7358 - val_loss: 0.5526 - val_accuracy: 0.7500\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.7449 - val_loss: 0.5556 - val_accuracy: 0.7212\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7230769230769231\n",
            "Accuracy: 0.7230769230769231\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6440 - accuracy: 0.6536 - val_loss: 0.6106 - val_accuracy: 0.6731\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6207 - accuracy: 0.6655 - val_loss: 0.6281 - val_accuracy: 0.6538\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6142 - accuracy: 0.6808 - val_loss: 0.5545 - val_accuracy: 0.7244\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6027 - accuracy: 0.6961 - val_loss: 0.5647 - val_accuracy: 0.6859\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5802 - accuracy: 0.7012 - val_loss: 0.5413 - val_accuracy: 0.7372\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5739 - accuracy: 0.7109 - val_loss: 0.5599 - val_accuracy: 0.6827\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5761 - accuracy: 0.7120 - val_loss: 0.5554 - val_accuracy: 0.7404\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5671 - accuracy: 0.7222 - val_loss: 0.5526 - val_accuracy: 0.7308\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5801 - accuracy: 0.7063 - val_loss: 0.5461 - val_accuracy: 0.7436\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5555 - accuracy: 0.7256 - val_loss: 0.5386 - val_accuracy: 0.7468\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5668 - accuracy: 0.7194 - val_loss: 0.5463 - val_accuracy: 0.7404\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5675 - accuracy: 0.7285 - val_loss: 0.5799 - val_accuracy: 0.6891\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5619 - accuracy: 0.7364 - val_loss: 0.5431 - val_accuracy: 0.7404\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5528 - accuracy: 0.7183 - val_loss: 0.5354 - val_accuracy: 0.7532\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5590 - accuracy: 0.7285 - val_loss: 0.5329 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5522 - accuracy: 0.7364 - val_loss: 0.5600 - val_accuracy: 0.7276\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5504 - accuracy: 0.7375 - val_loss: 0.5552 - val_accuracy: 0.7404\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5461 - accuracy: 0.7489 - val_loss: 0.5702 - val_accuracy: 0.7051\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5548 - accuracy: 0.7307 - val_loss: 0.5516 - val_accuracy: 0.7404\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5479 - accuracy: 0.7296 - val_loss: 0.5448 - val_accuracy: 0.7372\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5425 - accuracy: 0.7387 - val_loss: 0.5357 - val_accuracy: 0.7372\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5434 - accuracy: 0.7387 - val_loss: 0.5412 - val_accuracy: 0.7340\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5363 - accuracy: 0.7375 - val_loss: 0.5679 - val_accuracy: 0.6827\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5499 - accuracy: 0.7296 - val_loss: 0.5422 - val_accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5437 - accuracy: 0.7455 - val_loss: 0.5449 - val_accuracy: 0.7436\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5385 - accuracy: 0.7324 - val_loss: 0.5329 - val_accuracy: 0.7468\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5390 - accuracy: 0.7341 - val_loss: 0.5612 - val_accuracy: 0.7147\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5442 - accuracy: 0.7415 - val_loss: 0.5511 - val_accuracy: 0.7468\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5435 - accuracy: 0.7500 - val_loss: 0.5568 - val_accuracy: 0.7468\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5368 - accuracy: 0.7415 - val_loss: 0.5346 - val_accuracy: 0.7468\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5397 - accuracy: 0.7341 - val_loss: 0.5330 - val_accuracy: 0.7404\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5395 - accuracy: 0.7449 - val_loss: 0.5464 - val_accuracy: 0.7276\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5258 - accuracy: 0.7438 - val_loss: 0.5542 - val_accuracy: 0.7019\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5406 - accuracy: 0.7392 - val_loss: 0.5410 - val_accuracy: 0.7179\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5268 - accuracy: 0.7438 - val_loss: 0.5597 - val_accuracy: 0.7244\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5329 - accuracy: 0.7438 - val_loss: 0.5476 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5229 - accuracy: 0.7438 - val_loss: 0.5548 - val_accuracy: 0.7436\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5354 - accuracy: 0.7455 - val_loss: 0.5443 - val_accuracy: 0.7147\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.7455 - val_loss: 0.5471 - val_accuracy: 0.7212\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5251 - accuracy: 0.7449 - val_loss: 0.5422 - val_accuracy: 0.7532\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.7472 - val_loss: 0.5600 - val_accuracy: 0.7468\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5317 - accuracy: 0.7500 - val_loss: 0.5771 - val_accuracy: 0.6987\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.7551 - val_loss: 0.5426 - val_accuracy: 0.7276\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5267 - accuracy: 0.7449 - val_loss: 0.5576 - val_accuracy: 0.7019\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5220 - accuracy: 0.7500 - val_loss: 0.5562 - val_accuracy: 0.7340\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5223 - accuracy: 0.7449 - val_loss: 0.5346 - val_accuracy: 0.7340\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5295 - accuracy: 0.7506 - val_loss: 0.5516 - val_accuracy: 0.7596\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5254 - accuracy: 0.7500 - val_loss: 0.5302 - val_accuracy: 0.7660\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5186 - accuracy: 0.7557 - val_loss: 0.5475 - val_accuracy: 0.7596\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5154 - accuracy: 0.7534 - val_loss: 0.6082 - val_accuracy: 0.7308\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7076923076923077\n",
            "Accuracy: 0.7076923076923077\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6397 - accuracy: 0.6570 - val_loss: 0.6391 - val_accuracy: 0.6538\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6238 - accuracy: 0.6576 - val_loss: 0.6162 - val_accuracy: 0.6538\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6231 - accuracy: 0.6576 - val_loss: 0.5900 - val_accuracy: 0.6538\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6050 - accuracy: 0.6746 - val_loss: 0.5791 - val_accuracy: 0.7115\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5979 - accuracy: 0.6944 - val_loss: 0.5561 - val_accuracy: 0.7628\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5874 - accuracy: 0.6961 - val_loss: 0.5799 - val_accuracy: 0.6891\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5938 - accuracy: 0.6746 - val_loss: 0.5496 - val_accuracy: 0.7628\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5742 - accuracy: 0.6944 - val_loss: 0.5559 - val_accuracy: 0.7436\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5819 - accuracy: 0.7098 - val_loss: 0.5693 - val_accuracy: 0.7179\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5623 - accuracy: 0.7092 - val_loss: 0.5558 - val_accuracy: 0.7019\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5832 - accuracy: 0.6973 - val_loss: 0.5625 - val_accuracy: 0.7212\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5594 - accuracy: 0.7183 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5682 - accuracy: 0.6967 - val_loss: 0.5693 - val_accuracy: 0.6987\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5575 - accuracy: 0.7177 - val_loss: 0.5393 - val_accuracy: 0.7596\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5650 - accuracy: 0.7132 - val_loss: 0.5717 - val_accuracy: 0.6955\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5556 - accuracy: 0.7205 - val_loss: 0.5372 - val_accuracy: 0.7500\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5564 - accuracy: 0.7126 - val_loss: 0.5503 - val_accuracy: 0.7500\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5519 - accuracy: 0.7217 - val_loss: 0.5408 - val_accuracy: 0.7532\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5595 - accuracy: 0.7069 - val_loss: 0.5508 - val_accuracy: 0.7628\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5495 - accuracy: 0.7217 - val_loss: 0.5441 - val_accuracy: 0.7724\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5550 - accuracy: 0.7222 - val_loss: 0.5551 - val_accuracy: 0.7628\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5388 - accuracy: 0.7285 - val_loss: 0.5710 - val_accuracy: 0.7244\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5560 - accuracy: 0.7194 - val_loss: 0.5774 - val_accuracy: 0.7564\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5413 - accuracy: 0.7307 - val_loss: 0.5386 - val_accuracy: 0.7596\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5515 - accuracy: 0.7375 - val_loss: 0.5426 - val_accuracy: 0.7788\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5412 - accuracy: 0.7319 - val_loss: 0.5527 - val_accuracy: 0.7660\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5402 - accuracy: 0.7347 - val_loss: 0.5542 - val_accuracy: 0.7468\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5398 - accuracy: 0.7341 - val_loss: 0.5519 - val_accuracy: 0.7340\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5497 - accuracy: 0.7217 - val_loss: 0.5657 - val_accuracy: 0.7212\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5426 - accuracy: 0.7279 - val_loss: 0.5598 - val_accuracy: 0.7051\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5332 - accuracy: 0.7409 - val_loss: 0.5731 - val_accuracy: 0.7276\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5466 - accuracy: 0.7228 - val_loss: 0.5644 - val_accuracy: 0.7596\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5412 - accuracy: 0.7290 - val_loss: 0.5492 - val_accuracy: 0.7468\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5375 - accuracy: 0.7375 - val_loss: 0.5554 - val_accuracy: 0.7724\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5288 - accuracy: 0.7449 - val_loss: 0.5753 - val_accuracy: 0.7340\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5282 - accuracy: 0.7466 - val_loss: 0.5742 - val_accuracy: 0.7372\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7319 - val_loss: 0.5612 - val_accuracy: 0.7436\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5379 - accuracy: 0.7285 - val_loss: 0.5507 - val_accuracy: 0.7660\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5303 - accuracy: 0.7409 - val_loss: 0.5632 - val_accuracy: 0.6923\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5245 - accuracy: 0.7455 - val_loss: 0.5868 - val_accuracy: 0.6891\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5292 - accuracy: 0.7279 - val_loss: 0.5654 - val_accuracy: 0.7083\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5293 - accuracy: 0.7449 - val_loss: 0.5597 - val_accuracy: 0.7308\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5274 - accuracy: 0.7449 - val_loss: 0.5506 - val_accuracy: 0.7660\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7421 - val_loss: 0.5640 - val_accuracy: 0.7596\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5203 - accuracy: 0.7477 - val_loss: 0.5671 - val_accuracy: 0.7179\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5241 - accuracy: 0.7511 - val_loss: 0.5621 - val_accuracy: 0.7564\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5201 - accuracy: 0.7494 - val_loss: 0.5486 - val_accuracy: 0.7596\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5230 - accuracy: 0.7483 - val_loss: 0.5638 - val_accuracy: 0.7564\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5233 - accuracy: 0.7466 - val_loss: 0.5629 - val_accuracy: 0.7468\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.7500 - val_loss: 0.5611 - val_accuracy: 0.7532\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7442307692307693\n",
            "Accuracy: 0.7442307692307693\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6237 - accuracy: 0.6689 - val_loss: 0.6520 - val_accuracy: 0.6442\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5994 - accuracy: 0.6808 - val_loss: 0.6261 - val_accuracy: 0.6378\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5926 - accuracy: 0.6910 - val_loss: 0.6624 - val_accuracy: 0.6442\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5834 - accuracy: 0.6871 - val_loss: 0.6148 - val_accuracy: 0.6763\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5640 - accuracy: 0.7149 - val_loss: 0.6111 - val_accuracy: 0.6699\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5575 - accuracy: 0.7166 - val_loss: 0.6021 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5674 - accuracy: 0.7222 - val_loss: 0.6034 - val_accuracy: 0.6859\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5625 - accuracy: 0.7217 - val_loss: 0.6022 - val_accuracy: 0.6827\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5531 - accuracy: 0.7239 - val_loss: 0.6109 - val_accuracy: 0.6667\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5502 - accuracy: 0.7245 - val_loss: 0.5979 - val_accuracy: 0.6635\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5342 - accuracy: 0.7381 - val_loss: 0.6588 - val_accuracy: 0.6571\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5705 - accuracy: 0.7171 - val_loss: 0.6156 - val_accuracy: 0.6731\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5470 - accuracy: 0.7273 - val_loss: 0.5891 - val_accuracy: 0.7019\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5409 - accuracy: 0.7358 - val_loss: 0.6500 - val_accuracy: 0.6731\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5451 - accuracy: 0.7285 - val_loss: 0.6132 - val_accuracy: 0.6859\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5378 - accuracy: 0.7449 - val_loss: 0.6073 - val_accuracy: 0.6731\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5446 - accuracy: 0.7364 - val_loss: 0.5972 - val_accuracy: 0.7051\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7511 - val_loss: 0.6040 - val_accuracy: 0.6635\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5356 - accuracy: 0.7375 - val_loss: 0.6071 - val_accuracy: 0.6955\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7404 - val_loss: 0.5986 - val_accuracy: 0.6571\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.7285 - val_loss: 0.5961 - val_accuracy: 0.6827\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.7494 - val_loss: 0.6012 - val_accuracy: 0.6955\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.7426 - val_loss: 0.5837 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5270 - accuracy: 0.7540 - val_loss: 0.5799 - val_accuracy: 0.7212\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7438 - val_loss: 0.5839 - val_accuracy: 0.7051\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5290 - accuracy: 0.7438 - val_loss: 0.5858 - val_accuracy: 0.7051\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5263 - accuracy: 0.7392 - val_loss: 0.5823 - val_accuracy: 0.7147\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5238 - accuracy: 0.7483 - val_loss: 0.5945 - val_accuracy: 0.6923\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5221 - accuracy: 0.7528 - val_loss: 0.5793 - val_accuracy: 0.7051\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5208 - accuracy: 0.7449 - val_loss: 0.5813 - val_accuracy: 0.7083\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5281 - accuracy: 0.7421 - val_loss: 0.6036 - val_accuracy: 0.6859\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.7500 - val_loss: 0.5838 - val_accuracy: 0.6955\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5160 - accuracy: 0.7472 - val_loss: 0.5947 - val_accuracy: 0.7019\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5199 - accuracy: 0.7443 - val_loss: 0.5921 - val_accuracy: 0.7019\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5180 - accuracy: 0.7528 - val_loss: 0.5899 - val_accuracy: 0.6923\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7489 - val_loss: 0.6073 - val_accuracy: 0.6763\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5145 - accuracy: 0.7562 - val_loss: 0.5827 - val_accuracy: 0.6891\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5173 - accuracy: 0.7557 - val_loss: 0.6048 - val_accuracy: 0.6731\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5178 - accuracy: 0.7517 - val_loss: 0.6042 - val_accuracy: 0.6731\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5107 - accuracy: 0.7647 - val_loss: 0.5961 - val_accuracy: 0.7179\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5145 - accuracy: 0.7557 - val_loss: 0.5871 - val_accuracy: 0.7051\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5129 - accuracy: 0.7506 - val_loss: 0.5749 - val_accuracy: 0.7019\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5064 - accuracy: 0.7619 - val_loss: 0.6126 - val_accuracy: 0.6891\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5070 - accuracy: 0.7698 - val_loss: 0.5774 - val_accuracy: 0.6987\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5156 - accuracy: 0.7579 - val_loss: 0.5958 - val_accuracy: 0.6955\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5046 - accuracy: 0.7596 - val_loss: 0.6010 - val_accuracy: 0.7019\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5103 - accuracy: 0.7619 - val_loss: 0.5816 - val_accuracy: 0.7147\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4970 - accuracy: 0.7715 - val_loss: 0.5922 - val_accuracy: 0.7019\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5113 - accuracy: 0.7540 - val_loss: 0.6075 - val_accuracy: 0.7051\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5019 - accuracy: 0.7653 - val_loss: 0.6155 - val_accuracy: 0.6987\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7134615384615385\n",
            "Accuracy: 0.7134615384615385\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6312 - accuracy: 0.6689 - val_loss: 0.6455 - val_accuracy: 0.6154\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6127 - accuracy: 0.6752 - val_loss: 0.6541 - val_accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.6752 - val_loss: 0.6509 - val_accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5887 - accuracy: 0.6797 - val_loss: 0.6611 - val_accuracy: 0.6122\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5810 - accuracy: 0.7086 - val_loss: 0.6126 - val_accuracy: 0.6442\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5817 - accuracy: 0.7001 - val_loss: 0.5926 - val_accuracy: 0.7244\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5684 - accuracy: 0.7086 - val_loss: 0.5866 - val_accuracy: 0.6955\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5627 - accuracy: 0.7245 - val_loss: 0.5802 - val_accuracy: 0.7115\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5559 - accuracy: 0.7171 - val_loss: 0.5831 - val_accuracy: 0.6923\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5577 - accuracy: 0.7256 - val_loss: 0.5716 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5515 - accuracy: 0.7324 - val_loss: 0.5827 - val_accuracy: 0.6987\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5509 - accuracy: 0.7302 - val_loss: 0.5656 - val_accuracy: 0.7083\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7375 - val_loss: 0.5901 - val_accuracy: 0.6859\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5488 - accuracy: 0.7268 - val_loss: 0.5753 - val_accuracy: 0.7019\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5305 - accuracy: 0.7438 - val_loss: 0.5750 - val_accuracy: 0.7212\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5395 - accuracy: 0.7347 - val_loss: 0.5678 - val_accuracy: 0.7212\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7466 - val_loss: 0.5756 - val_accuracy: 0.7019\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5344 - accuracy: 0.7398 - val_loss: 0.5648 - val_accuracy: 0.7179\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7404 - val_loss: 0.6066 - val_accuracy: 0.7083\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5217 - accuracy: 0.7506 - val_loss: 0.5746 - val_accuracy: 0.7083\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.7494 - val_loss: 0.5538 - val_accuracy: 0.7212\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5338 - accuracy: 0.7313 - val_loss: 0.5823 - val_accuracy: 0.6955\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5226 - accuracy: 0.7579 - val_loss: 0.5708 - val_accuracy: 0.7147\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7426 - val_loss: 0.5635 - val_accuracy: 0.7308\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5171 - accuracy: 0.7562 - val_loss: 0.5730 - val_accuracy: 0.7179\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5219 - accuracy: 0.7506 - val_loss: 0.6020 - val_accuracy: 0.6795\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5190 - accuracy: 0.7591 - val_loss: 0.5582 - val_accuracy: 0.7276\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5195 - accuracy: 0.7494 - val_loss: 0.5769 - val_accuracy: 0.7276\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5131 - accuracy: 0.7591 - val_loss: 0.5653 - val_accuracy: 0.7244\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5172 - accuracy: 0.7466 - val_loss: 0.5931 - val_accuracy: 0.6731\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5200 - accuracy: 0.7579 - val_loss: 0.5592 - val_accuracy: 0.7404\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5218 - accuracy: 0.7415 - val_loss: 0.6197 - val_accuracy: 0.6506\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5099 - accuracy: 0.7528 - val_loss: 0.5651 - val_accuracy: 0.7308\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5197 - accuracy: 0.7528 - val_loss: 0.5754 - val_accuracy: 0.7115\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5163 - accuracy: 0.7591 - val_loss: 0.5876 - val_accuracy: 0.7115\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5136 - accuracy: 0.7568 - val_loss: 0.5691 - val_accuracy: 0.7179\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5157 - accuracy: 0.7585 - val_loss: 0.5743 - val_accuracy: 0.6923\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5188 - accuracy: 0.7489 - val_loss: 0.5632 - val_accuracy: 0.7179\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5086 - accuracy: 0.7585 - val_loss: 0.5966 - val_accuracy: 0.6635\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5042 - accuracy: 0.7630 - val_loss: 0.5737 - val_accuracy: 0.7244\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.7585 - val_loss: 0.5704 - val_accuracy: 0.7147\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5040 - accuracy: 0.7619 - val_loss: 0.5796 - val_accuracy: 0.7083\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5031 - accuracy: 0.7676 - val_loss: 0.5655 - val_accuracy: 0.7372\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.7545 - val_loss: 0.5769 - val_accuracy: 0.7083\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4989 - accuracy: 0.7693 - val_loss: 0.5719 - val_accuracy: 0.7212\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5025 - accuracy: 0.7642 - val_loss: 0.6212 - val_accuracy: 0.7051\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4972 - accuracy: 0.7687 - val_loss: 0.6545 - val_accuracy: 0.6987\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5092 - accuracy: 0.7568 - val_loss: 0.5754 - val_accuracy: 0.7308\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4986 - accuracy: 0.7693 - val_loss: 0.6284 - val_accuracy: 0.6603\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.4942 - accuracy: 0.7687 - val_loss: 0.6134 - val_accuracy: 0.6571\n",
            "17/17 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7076923076923077\n",
            "Accuracy: 0.7076923076923077\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 7ms/step - loss: 0.6356 - accuracy: 0.6604 - val_loss: 0.6334 - val_accuracy: 0.6763\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6254 - accuracy: 0.6621 - val_loss: 0.5968 - val_accuracy: 0.6763\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6008 - accuracy: 0.6718 - val_loss: 0.6545 - val_accuracy: 0.5577\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5909 - accuracy: 0.6922 - val_loss: 0.5920 - val_accuracy: 0.7083\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5877 - accuracy: 0.6973 - val_loss: 0.5730 - val_accuracy: 0.7308\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5852 - accuracy: 0.7001 - val_loss: 0.5648 - val_accuracy: 0.7308\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5788 - accuracy: 0.7007 - val_loss: 0.5660 - val_accuracy: 0.7532\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5786 - accuracy: 0.7001 - val_loss: 0.5670 - val_accuracy: 0.7276\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5680 - accuracy: 0.6956 - val_loss: 0.5673 - val_accuracy: 0.7372\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5601 - accuracy: 0.7296 - val_loss: 0.5606 - val_accuracy: 0.7436\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5614 - accuracy: 0.7092 - val_loss: 0.5601 - val_accuracy: 0.7276\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5603 - accuracy: 0.7143 - val_loss: 0.5554 - val_accuracy: 0.7276\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5589 - accuracy: 0.7336 - val_loss: 0.5565 - val_accuracy: 0.7468\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5468 - accuracy: 0.7256 - val_loss: 0.5601 - val_accuracy: 0.7436\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5498 - accuracy: 0.7222 - val_loss: 0.5618 - val_accuracy: 0.7404\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5453 - accuracy: 0.7409 - val_loss: 0.5580 - val_accuracy: 0.7468\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5483 - accuracy: 0.7319 - val_loss: 0.5561 - val_accuracy: 0.7244\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5562 - accuracy: 0.7273 - val_loss: 0.5566 - val_accuracy: 0.7468\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5483 - accuracy: 0.7364 - val_loss: 0.5565 - val_accuracy: 0.7308\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5544 - accuracy: 0.7279 - val_loss: 0.5565 - val_accuracy: 0.7372\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5541 - accuracy: 0.7239 - val_loss: 0.5874 - val_accuracy: 0.6859\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5539 - accuracy: 0.7245 - val_loss: 0.5597 - val_accuracy: 0.7179\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5459 - accuracy: 0.7319 - val_loss: 0.5627 - val_accuracy: 0.7276\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5462 - accuracy: 0.7358 - val_loss: 0.5526 - val_accuracy: 0.7276\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5452 - accuracy: 0.7279 - val_loss: 0.5634 - val_accuracy: 0.6923\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5385 - accuracy: 0.7313 - val_loss: 0.5517 - val_accuracy: 0.7308\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5389 - accuracy: 0.7517 - val_loss: 0.6072 - val_accuracy: 0.6346\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5447 - accuracy: 0.7290 - val_loss: 0.5471 - val_accuracy: 0.7276\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5343 - accuracy: 0.7449 - val_loss: 0.5492 - val_accuracy: 0.7468\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5392 - accuracy: 0.7415 - val_loss: 0.5530 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5291 - accuracy: 0.7432 - val_loss: 0.5680 - val_accuracy: 0.6955\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7409 - val_loss: 0.5724 - val_accuracy: 0.7532\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5356 - accuracy: 0.7460 - val_loss: 0.5695 - val_accuracy: 0.6795\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7313 - val_loss: 0.5520 - val_accuracy: 0.7051\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5318 - accuracy: 0.7443 - val_loss: 0.5504 - val_accuracy: 0.7212\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.7494 - val_loss: 0.5651 - val_accuracy: 0.7244\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5212 - accuracy: 0.7472 - val_loss: 0.5508 - val_accuracy: 0.7468\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5257 - accuracy: 0.7426 - val_loss: 0.5844 - val_accuracy: 0.6635\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5269 - accuracy: 0.7438 - val_loss: 0.5597 - val_accuracy: 0.7340\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.7449 - val_loss: 0.5663 - val_accuracy: 0.7244\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5267 - accuracy: 0.7534 - val_loss: 0.5623 - val_accuracy: 0.7468\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5280 - accuracy: 0.7494 - val_loss: 0.5647 - val_accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5181 - accuracy: 0.7517 - val_loss: 0.5827 - val_accuracy: 0.6891\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5230 - accuracy: 0.7500 - val_loss: 0.5637 - val_accuracy: 0.7468\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5215 - accuracy: 0.7585 - val_loss: 0.5697 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5329 - accuracy: 0.7341 - val_loss: 0.5529 - val_accuracy: 0.7468\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7455 - val_loss: 0.5851 - val_accuracy: 0.6795\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.7483 - val_loss: 0.5701 - val_accuracy: 0.7340\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.7596 - val_loss: 0.5858 - val_accuracy: 0.6859\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5277 - accuracy: 0.7438 - val_loss: 0.5786 - val_accuracy: 0.6891\n",
            "17/17 [==============================] - 0s 4ms/step\n",
            "0.7173076923076923\n",
            "Accuracy: 0.7173076923076923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6373 - accuracy: 0.6610 - val_loss: 0.6266 - val_accuracy: 0.6635\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6173 - accuracy: 0.6638 - val_loss: 0.5789 - val_accuracy: 0.6635\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6117 - accuracy: 0.6548 - val_loss: 0.5621 - val_accuracy: 0.7212\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6146 - accuracy: 0.6746 - val_loss: 0.5743 - val_accuracy: 0.6731\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5950 - accuracy: 0.6876 - val_loss: 0.5648 - val_accuracy: 0.7596\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5860 - accuracy: 0.7126 - val_loss: 0.5700 - val_accuracy: 0.6827\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5778 - accuracy: 0.7029 - val_loss: 0.5396 - val_accuracy: 0.7692\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5689 - accuracy: 0.7166 - val_loss: 0.5862 - val_accuracy: 0.6987\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5866 - accuracy: 0.7018 - val_loss: 0.5767 - val_accuracy: 0.6763\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5687 - accuracy: 0.7211 - val_loss: 0.5336 - val_accuracy: 0.7436\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5641 - accuracy: 0.7194 - val_loss: 0.5443 - val_accuracy: 0.7372\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5694 - accuracy: 0.7024 - val_loss: 0.5412 - val_accuracy: 0.7404\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5573 - accuracy: 0.7302 - val_loss: 0.5518 - val_accuracy: 0.7340\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5615 - accuracy: 0.7273 - val_loss: 0.5444 - val_accuracy: 0.7436\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5563 - accuracy: 0.7279 - val_loss: 0.5435 - val_accuracy: 0.7308\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5654 - accuracy: 0.7120 - val_loss: 0.5479 - val_accuracy: 0.7436\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5621 - accuracy: 0.7166 - val_loss: 0.5466 - val_accuracy: 0.7147\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5515 - accuracy: 0.7188 - val_loss: 0.5332 - val_accuracy: 0.7404\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.7234 - val_loss: 0.5292 - val_accuracy: 0.7564\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5529 - accuracy: 0.7239 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5535 - accuracy: 0.7211 - val_loss: 0.5406 - val_accuracy: 0.7468\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5580 - accuracy: 0.7330 - val_loss: 0.5483 - val_accuracy: 0.7308\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7421 - val_loss: 0.5847 - val_accuracy: 0.6987\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5512 - accuracy: 0.7273 - val_loss: 0.5572 - val_accuracy: 0.6891\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5512 - accuracy: 0.7211 - val_loss: 0.5389 - val_accuracy: 0.7372\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5479 - accuracy: 0.7341 - val_loss: 0.5337 - val_accuracy: 0.7660\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5433 - accuracy: 0.7200 - val_loss: 0.5472 - val_accuracy: 0.7468\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5503 - accuracy: 0.7392 - val_loss: 0.5735 - val_accuracy: 0.6763\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5441 - accuracy: 0.7319 - val_loss: 0.5303 - val_accuracy: 0.7532\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5410 - accuracy: 0.7387 - val_loss: 0.5424 - val_accuracy: 0.7532\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5398 - accuracy: 0.7347 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5349 - accuracy: 0.7370 - val_loss: 0.5458 - val_accuracy: 0.7596\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5451 - accuracy: 0.7336 - val_loss: 0.5367 - val_accuracy: 0.7468\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7251 - val_loss: 0.5450 - val_accuracy: 0.7532\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5345 - accuracy: 0.7426 - val_loss: 0.5419 - val_accuracy: 0.7532\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7460 - val_loss: 0.5365 - val_accuracy: 0.7596\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5282 - accuracy: 0.7426 - val_loss: 0.5389 - val_accuracy: 0.7564\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5295 - accuracy: 0.7341 - val_loss: 0.5433 - val_accuracy: 0.7340\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5344 - accuracy: 0.7273 - val_loss: 0.5442 - val_accuracy: 0.7596\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5289 - accuracy: 0.7313 - val_loss: 0.5587 - val_accuracy: 0.6891\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5263 - accuracy: 0.7443 - val_loss: 0.5632 - val_accuracy: 0.7019\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5261 - accuracy: 0.7489 - val_loss: 0.5389 - val_accuracy: 0.7308\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5180 - accuracy: 0.7483 - val_loss: 0.5503 - val_accuracy: 0.7532\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.7432 - val_loss: 0.5692 - val_accuracy: 0.7436\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.7347 - val_loss: 0.5287 - val_accuracy: 0.7660\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5315 - accuracy: 0.7392 - val_loss: 0.5699 - val_accuracy: 0.7340\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5290 - accuracy: 0.7421 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5272 - accuracy: 0.7472 - val_loss: 0.5847 - val_accuracy: 0.6731\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5222 - accuracy: 0.7415 - val_loss: 0.5442 - val_accuracy: 0.7564\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5201 - accuracy: 0.7545 - val_loss: 0.5976 - val_accuracy: 0.6859\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6865384615384615\n",
            "Accuracy: 0.6865384615384615\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6354 - accuracy: 0.6638 - val_loss: 0.6196 - val_accuracy: 0.6506\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6255 - accuracy: 0.6650 - val_loss: 0.6075 - val_accuracy: 0.6506\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6073 - accuracy: 0.6706 - val_loss: 0.5828 - val_accuracy: 0.6635\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6012 - accuracy: 0.6871 - val_loss: 0.5699 - val_accuracy: 0.7372\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5913 - accuracy: 0.6797 - val_loss: 0.6352 - val_accuracy: 0.6058\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5849 - accuracy: 0.6973 - val_loss: 0.5671 - val_accuracy: 0.7404\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5806 - accuracy: 0.7086 - val_loss: 0.5934 - val_accuracy: 0.6571\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5788 - accuracy: 0.7143 - val_loss: 0.5599 - val_accuracy: 0.7436\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5740 - accuracy: 0.7137 - val_loss: 0.5881 - val_accuracy: 0.6699\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5736 - accuracy: 0.7035 - val_loss: 0.5648 - val_accuracy: 0.7372\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5728 - accuracy: 0.7063 - val_loss: 0.5748 - val_accuracy: 0.7179\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5635 - accuracy: 0.7188 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5608 - accuracy: 0.7217 - val_loss: 0.5462 - val_accuracy: 0.7468\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5645 - accuracy: 0.7154 - val_loss: 0.5675 - val_accuracy: 0.6955\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5589 - accuracy: 0.7239 - val_loss: 0.5641 - val_accuracy: 0.7340\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5535 - accuracy: 0.7228 - val_loss: 0.5613 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5600 - accuracy: 0.7188 - val_loss: 0.5561 - val_accuracy: 0.7532\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5606 - accuracy: 0.7166 - val_loss: 0.5575 - val_accuracy: 0.7404\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5498 - accuracy: 0.7285 - val_loss: 0.5611 - val_accuracy: 0.7051\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5480 - accuracy: 0.7194 - val_loss: 0.5630 - val_accuracy: 0.7436\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5443 - accuracy: 0.7302 - val_loss: 0.5610 - val_accuracy: 0.7179\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5515 - accuracy: 0.7183 - val_loss: 0.5594 - val_accuracy: 0.7500\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5461 - accuracy: 0.7234 - val_loss: 0.5442 - val_accuracy: 0.7596\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5445 - accuracy: 0.7296 - val_loss: 0.5768 - val_accuracy: 0.6859\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5405 - accuracy: 0.7296 - val_loss: 0.5681 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5440 - accuracy: 0.7251 - val_loss: 0.5564 - val_accuracy: 0.7372\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5359 - accuracy: 0.7409 - val_loss: 0.5466 - val_accuracy: 0.7404\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5392 - accuracy: 0.7370 - val_loss: 0.5613 - val_accuracy: 0.7372\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5397 - accuracy: 0.7279 - val_loss: 0.5457 - val_accuracy: 0.7436\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5325 - accuracy: 0.7392 - val_loss: 0.5592 - val_accuracy: 0.7212\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5373 - accuracy: 0.7177 - val_loss: 0.5612 - val_accuracy: 0.7179\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5353 - accuracy: 0.7160 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5313 - accuracy: 0.7353 - val_loss: 0.5665 - val_accuracy: 0.7308\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5277 - accuracy: 0.7398 - val_loss: 0.5927 - val_accuracy: 0.6891\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5297 - accuracy: 0.7421 - val_loss: 0.5657 - val_accuracy: 0.7404\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5325 - accuracy: 0.7302 - val_loss: 0.5665 - val_accuracy: 0.7212\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7438 - val_loss: 0.5662 - val_accuracy: 0.7308\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5231 - accuracy: 0.7409 - val_loss: 0.5638 - val_accuracy: 0.7115\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.7432 - val_loss: 0.5694 - val_accuracy: 0.7179\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.7438 - val_loss: 0.5641 - val_accuracy: 0.7436\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7336 - val_loss: 0.5686 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5333 - accuracy: 0.7375 - val_loss: 0.5672 - val_accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.7364 - val_loss: 0.5731 - val_accuracy: 0.7436\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.7511 - val_loss: 0.5877 - val_accuracy: 0.7276\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5165 - accuracy: 0.7387 - val_loss: 0.5711 - val_accuracy: 0.7212\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.7466 - val_loss: 0.5765 - val_accuracy: 0.7436\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5213 - accuracy: 0.7404 - val_loss: 0.5836 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5187 - accuracy: 0.7426 - val_loss: 0.5621 - val_accuracy: 0.7436\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5181 - accuracy: 0.7409 - val_loss: 0.5882 - val_accuracy: 0.7212\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.7347 - val_loss: 0.5609 - val_accuracy: 0.7500\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7538461538461538\n",
            "Accuracy: 0.7538461538461538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 10ms/step - loss: 0.6369 - accuracy: 0.6672 - val_loss: 0.6490 - val_accuracy: 0.6667\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.6184 - accuracy: 0.6735 - val_loss: 0.6144 - val_accuracy: 0.6667\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6070 - accuracy: 0.6735 - val_loss: 0.6072 - val_accuracy: 0.6667\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6060 - accuracy: 0.6723 - val_loss: 0.5999 - val_accuracy: 0.6667\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5899 - accuracy: 0.6899 - val_loss: 0.5794 - val_accuracy: 0.7276\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5865 - accuracy: 0.6990 - val_loss: 0.5673 - val_accuracy: 0.7308\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5832 - accuracy: 0.7035 - val_loss: 0.5605 - val_accuracy: 0.7404\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5784 - accuracy: 0.7239 - val_loss: 0.5692 - val_accuracy: 0.7179\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5700 - accuracy: 0.7228 - val_loss: 0.5653 - val_accuracy: 0.7340\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5550 - accuracy: 0.7234 - val_loss: 0.5566 - val_accuracy: 0.7436\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5639 - accuracy: 0.7222 - val_loss: 0.5604 - val_accuracy: 0.7436\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5542 - accuracy: 0.7273 - val_loss: 0.5655 - val_accuracy: 0.7179\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5516 - accuracy: 0.7307 - val_loss: 0.5500 - val_accuracy: 0.7532\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5462 - accuracy: 0.7290 - val_loss: 0.5636 - val_accuracy: 0.7340\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5463 - accuracy: 0.7330 - val_loss: 0.5602 - val_accuracy: 0.7276\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5513 - accuracy: 0.7358 - val_loss: 0.5678 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5519 - accuracy: 0.7313 - val_loss: 0.5684 - val_accuracy: 0.7179\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5404 - accuracy: 0.7426 - val_loss: 0.5609 - val_accuracy: 0.7244\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5469 - accuracy: 0.7364 - val_loss: 0.5595 - val_accuracy: 0.7308\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5391 - accuracy: 0.7341 - val_loss: 0.5527 - val_accuracy: 0.7468\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5389 - accuracy: 0.7443 - val_loss: 0.5574 - val_accuracy: 0.7340\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5372 - accuracy: 0.7415 - val_loss: 0.5692 - val_accuracy: 0.7372\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5379 - accuracy: 0.7381 - val_loss: 0.5511 - val_accuracy: 0.7532\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5245 - accuracy: 0.7404 - val_loss: 0.5849 - val_accuracy: 0.7147\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5297 - accuracy: 0.7506 - val_loss: 0.5676 - val_accuracy: 0.7436\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7364 - val_loss: 0.5573 - val_accuracy: 0.7404\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5280 - accuracy: 0.7443 - val_loss: 0.5586 - val_accuracy: 0.7404\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5257 - accuracy: 0.7398 - val_loss: 0.5723 - val_accuracy: 0.7212\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.7426 - val_loss: 0.5552 - val_accuracy: 0.7500\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5165 - accuracy: 0.7517 - val_loss: 0.5731 - val_accuracy: 0.7212\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5258 - accuracy: 0.7455 - val_loss: 0.5651 - val_accuracy: 0.7372\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7551 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7387 - val_loss: 0.5606 - val_accuracy: 0.7596\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7568 - val_loss: 0.5756 - val_accuracy: 0.7308\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.7545 - val_loss: 0.5850 - val_accuracy: 0.7436\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5134 - accuracy: 0.7534 - val_loss: 0.5789 - val_accuracy: 0.7276\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5103 - accuracy: 0.7545 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5136 - accuracy: 0.7466 - val_loss: 0.5713 - val_accuracy: 0.7404\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5148 - accuracy: 0.7494 - val_loss: 0.5846 - val_accuracy: 0.7179\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5092 - accuracy: 0.7528 - val_loss: 0.5812 - val_accuracy: 0.7276\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5138 - accuracy: 0.7477 - val_loss: 0.5988 - val_accuracy: 0.7276\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5094 - accuracy: 0.7596 - val_loss: 0.5863 - val_accuracy: 0.7212\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5045 - accuracy: 0.7608 - val_loss: 0.5987 - val_accuracy: 0.7212\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.4994 - accuracy: 0.7613 - val_loss: 0.6182 - val_accuracy: 0.7308\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5165 - accuracy: 0.7596 - val_loss: 0.6017 - val_accuracy: 0.7115\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5089 - accuracy: 0.7625 - val_loss: 0.6022 - val_accuracy: 0.7244\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5111 - accuracy: 0.7472 - val_loss: 0.5857 - val_accuracy: 0.7115\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.4967 - accuracy: 0.7670 - val_loss: 0.7004 - val_accuracy: 0.6635\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5127 - accuracy: 0.7455 - val_loss: 0.5814 - val_accuracy: 0.7212\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5052 - accuracy: 0.7596 - val_loss: 0.5961 - val_accuracy: 0.7340\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7\n",
            "Accuracy: 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6220 - accuracy: 0.6638 - val_loss: 0.5972 - val_accuracy: 0.6474\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6185 - accuracy: 0.6695 - val_loss: 0.6117 - val_accuracy: 0.6474\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6009 - accuracy: 0.6780 - val_loss: 0.5804 - val_accuracy: 0.6795\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5973 - accuracy: 0.6774 - val_loss: 0.5708 - val_accuracy: 0.6891\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5780 - accuracy: 0.7092 - val_loss: 0.5670 - val_accuracy: 0.6859\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5727 - accuracy: 0.7120 - val_loss: 0.5421 - val_accuracy: 0.7147\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5716 - accuracy: 0.7194 - val_loss: 0.5614 - val_accuracy: 0.7436\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5725 - accuracy: 0.7109 - val_loss: 0.5594 - val_accuracy: 0.7276\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5676 - accuracy: 0.7177 - val_loss: 0.5515 - val_accuracy: 0.7147\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5573 - accuracy: 0.7268 - val_loss: 0.5512 - val_accuracy: 0.7276\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5593 - accuracy: 0.7273 - val_loss: 0.5836 - val_accuracy: 0.6827\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5568 - accuracy: 0.7285 - val_loss: 0.5656 - val_accuracy: 0.7019\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5479 - accuracy: 0.7307 - val_loss: 0.5571 - val_accuracy: 0.7115\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5491 - accuracy: 0.7358 - val_loss: 0.5713 - val_accuracy: 0.7083\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5466 - accuracy: 0.7347 - val_loss: 0.5656 - val_accuracy: 0.7051\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5484 - accuracy: 0.7358 - val_loss: 0.5595 - val_accuracy: 0.7179\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5541 - accuracy: 0.7330 - val_loss: 0.5893 - val_accuracy: 0.6763\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5434 - accuracy: 0.7438 - val_loss: 0.5539 - val_accuracy: 0.7276\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5475 - accuracy: 0.7324 - val_loss: 0.5692 - val_accuracy: 0.6795\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5435 - accuracy: 0.7364 - val_loss: 0.5788 - val_accuracy: 0.6923\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5436 - accuracy: 0.7415 - val_loss: 0.5593 - val_accuracy: 0.7115\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5418 - accuracy: 0.7273 - val_loss: 0.5617 - val_accuracy: 0.7115\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5395 - accuracy: 0.7443 - val_loss: 0.5629 - val_accuracy: 0.7340\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5390 - accuracy: 0.7398 - val_loss: 0.5620 - val_accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5353 - accuracy: 0.7466 - val_loss: 0.5644 - val_accuracy: 0.6987\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.7483 - val_loss: 0.5733 - val_accuracy: 0.6987\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5385 - accuracy: 0.7449 - val_loss: 0.5822 - val_accuracy: 0.7019\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5368 - accuracy: 0.7392 - val_loss: 0.5559 - val_accuracy: 0.7147\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5311 - accuracy: 0.7460 - val_loss: 0.5655 - val_accuracy: 0.6987\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5278 - accuracy: 0.7466 - val_loss: 0.5781 - val_accuracy: 0.6891\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5300 - accuracy: 0.7421 - val_loss: 0.5894 - val_accuracy: 0.6699\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5313 - accuracy: 0.7438 - val_loss: 0.5640 - val_accuracy: 0.7308\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5281 - accuracy: 0.7460 - val_loss: 0.5635 - val_accuracy: 0.7244\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5341 - accuracy: 0.7528 - val_loss: 0.5541 - val_accuracy: 0.7244\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7557 - val_loss: 0.5853 - val_accuracy: 0.7019\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5292 - accuracy: 0.7449 - val_loss: 0.5840 - val_accuracy: 0.6987\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5297 - accuracy: 0.7398 - val_loss: 0.5621 - val_accuracy: 0.7083\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5194 - accuracy: 0.7517 - val_loss: 0.5894 - val_accuracy: 0.7147\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5202 - accuracy: 0.7523 - val_loss: 0.5732 - val_accuracy: 0.7340\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5241 - accuracy: 0.7568 - val_loss: 0.5844 - val_accuracy: 0.7276\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5213 - accuracy: 0.7511 - val_loss: 0.5900 - val_accuracy: 0.7051\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5212 - accuracy: 0.7523 - val_loss: 0.6014 - val_accuracy: 0.7115\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5251 - accuracy: 0.7375 - val_loss: 0.5845 - val_accuracy: 0.7147\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5183 - accuracy: 0.7528 - val_loss: 0.5916 - val_accuracy: 0.7019\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5242 - accuracy: 0.7438 - val_loss: 0.5855 - val_accuracy: 0.7019\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5089 - accuracy: 0.7568 - val_loss: 0.5762 - val_accuracy: 0.7115\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5134 - accuracy: 0.7579 - val_loss: 0.5919 - val_accuracy: 0.7276\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5184 - accuracy: 0.7443 - val_loss: 0.5694 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5199 - accuracy: 0.7562 - val_loss: 0.5834 - val_accuracy: 0.7019\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5168 - accuracy: 0.7551 - val_loss: 0.5891 - val_accuracy: 0.6827\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7173076923076923\n",
            "Accuracy: 0.7173076923076923\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6377 - accuracy: 0.6627 - val_loss: 0.6145 - val_accuracy: 0.6795\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6274 - accuracy: 0.6638 - val_loss: 0.5959 - val_accuracy: 0.6795\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6218 - accuracy: 0.6650 - val_loss: 0.5821 - val_accuracy: 0.6763\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6032 - accuracy: 0.6706 - val_loss: 0.5940 - val_accuracy: 0.7083\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5906 - accuracy: 0.6956 - val_loss: 0.5657 - val_accuracy: 0.6859\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5900 - accuracy: 0.6990 - val_loss: 0.5654 - val_accuracy: 0.7083\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5756 - accuracy: 0.7092 - val_loss: 0.5590 - val_accuracy: 0.7051\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5630 - accuracy: 0.7313 - val_loss: 0.5467 - val_accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5805 - accuracy: 0.7024 - val_loss: 0.5716 - val_accuracy: 0.6987\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5642 - accuracy: 0.7336 - val_loss: 0.5492 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5651 - accuracy: 0.7262 - val_loss: 0.5683 - val_accuracy: 0.7179\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5649 - accuracy: 0.7245 - val_loss: 0.5784 - val_accuracy: 0.7115\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5606 - accuracy: 0.7205 - val_loss: 0.5463 - val_accuracy: 0.7372\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5640 - accuracy: 0.7251 - val_loss: 0.5499 - val_accuracy: 0.7308\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5528 - accuracy: 0.7296 - val_loss: 0.5429 - val_accuracy: 0.7308\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5537 - accuracy: 0.7336 - val_loss: 0.5505 - val_accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5518 - accuracy: 0.7324 - val_loss: 0.5354 - val_accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5626 - accuracy: 0.7217 - val_loss: 0.5560 - val_accuracy: 0.6987\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5579 - accuracy: 0.7341 - val_loss: 0.5500 - val_accuracy: 0.7340\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5485 - accuracy: 0.7256 - val_loss: 0.5596 - val_accuracy: 0.7051\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5471 - accuracy: 0.7370 - val_loss: 0.5619 - val_accuracy: 0.7147\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7341 - val_loss: 0.5762 - val_accuracy: 0.6955\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5457 - accuracy: 0.7347 - val_loss: 0.5427 - val_accuracy: 0.7276\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5451 - accuracy: 0.7415 - val_loss: 0.5552 - val_accuracy: 0.7083\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5415 - accuracy: 0.7364 - val_loss: 0.5580 - val_accuracy: 0.7115\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5426 - accuracy: 0.7330 - val_loss: 0.5606 - val_accuracy: 0.6923\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5485 - accuracy: 0.7404 - val_loss: 0.5778 - val_accuracy: 0.7019\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5541 - accuracy: 0.7205 - val_loss: 0.5467 - val_accuracy: 0.7212\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5353 - accuracy: 0.7415 - val_loss: 0.5887 - val_accuracy: 0.7212\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7375 - val_loss: 0.5363 - val_accuracy: 0.7308\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5346 - accuracy: 0.7387 - val_loss: 0.5403 - val_accuracy: 0.7276\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5390 - accuracy: 0.7330 - val_loss: 0.5378 - val_accuracy: 0.7340\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5401 - accuracy: 0.7432 - val_loss: 0.5380 - val_accuracy: 0.7212\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5378 - accuracy: 0.7387 - val_loss: 0.5386 - val_accuracy: 0.7404\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5392 - accuracy: 0.7347 - val_loss: 0.5389 - val_accuracy: 0.7179\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5290 - accuracy: 0.7432 - val_loss: 0.5516 - val_accuracy: 0.7212\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5363 - accuracy: 0.7313 - val_loss: 0.5365 - val_accuracy: 0.7468\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.7415 - val_loss: 0.5679 - val_accuracy: 0.7147\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.7489 - val_loss: 0.5488 - val_accuracy: 0.7244\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.7409 - val_loss: 0.5736 - val_accuracy: 0.6955\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5331 - accuracy: 0.7387 - val_loss: 0.5407 - val_accuracy: 0.7340\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5302 - accuracy: 0.7460 - val_loss: 0.5339 - val_accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5241 - accuracy: 0.7534 - val_loss: 0.5321 - val_accuracy: 0.7468\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5289 - accuracy: 0.7409 - val_loss: 0.5436 - val_accuracy: 0.7468\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.7534 - val_loss: 0.5321 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5274 - accuracy: 0.7494 - val_loss: 0.5419 - val_accuracy: 0.7276\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5226 - accuracy: 0.7540 - val_loss: 0.5484 - val_accuracy: 0.7308\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5273 - accuracy: 0.7466 - val_loss: 0.5395 - val_accuracy: 0.7212\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5238 - accuracy: 0.7415 - val_loss: 0.5443 - val_accuracy: 0.7179\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.7517 - val_loss: 0.5401 - val_accuracy: 0.7436\n",
            "17/17 [==============================] - 0s 3ms/step\n",
            "0.7211538461538461\n",
            "Accuracy: 0.7211538461538461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 7ms/step - loss: 0.6339 - accuracy: 0.6610 - val_loss: 0.6209 - val_accuracy: 0.6538\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6183 - accuracy: 0.6706 - val_loss: 0.6124 - val_accuracy: 0.6506\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6082 - accuracy: 0.6854 - val_loss: 0.6101 - val_accuracy: 0.7019\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5889 - accuracy: 0.6831 - val_loss: 0.5967 - val_accuracy: 0.7019\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5788 - accuracy: 0.7024 - val_loss: 0.5907 - val_accuracy: 0.6795\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5816 - accuracy: 0.7120 - val_loss: 0.5938 - val_accuracy: 0.6763\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5683 - accuracy: 0.7143 - val_loss: 0.5981 - val_accuracy: 0.6859\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5565 - accuracy: 0.7268 - val_loss: 0.5991 - val_accuracy: 0.6731\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5704 - accuracy: 0.7075 - val_loss: 0.6012 - val_accuracy: 0.6827\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5595 - accuracy: 0.7194 - val_loss: 0.5868 - val_accuracy: 0.6923\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5577 - accuracy: 0.7200 - val_loss: 0.5952 - val_accuracy: 0.6923\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5529 - accuracy: 0.7341 - val_loss: 0.6095 - val_accuracy: 0.6795\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5679 - accuracy: 0.7205 - val_loss: 0.6258 - val_accuracy: 0.6667\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5445 - accuracy: 0.7188 - val_loss: 0.5866 - val_accuracy: 0.6923\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5476 - accuracy: 0.7324 - val_loss: 0.6039 - val_accuracy: 0.6955\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5422 - accuracy: 0.7347 - val_loss: 0.5868 - val_accuracy: 0.6955\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.7426 - val_loss: 0.6077 - val_accuracy: 0.6859\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5426 - accuracy: 0.7443 - val_loss: 0.5942 - val_accuracy: 0.6795\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5454 - accuracy: 0.7211 - val_loss: 0.5798 - val_accuracy: 0.7051\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.7460 - val_loss: 0.5876 - val_accuracy: 0.6955\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5493 - accuracy: 0.7336 - val_loss: 0.5837 - val_accuracy: 0.7019\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5342 - accuracy: 0.7387 - val_loss: 0.6259 - val_accuracy: 0.6827\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5428 - accuracy: 0.7404 - val_loss: 0.5874 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5396 - accuracy: 0.7353 - val_loss: 0.5882 - val_accuracy: 0.6987\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5269 - accuracy: 0.7506 - val_loss: 0.6007 - val_accuracy: 0.6923\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5340 - accuracy: 0.7500 - val_loss: 0.5830 - val_accuracy: 0.6987\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7591 - val_loss: 0.5988 - val_accuracy: 0.6987\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5265 - accuracy: 0.7443 - val_loss: 0.6448 - val_accuracy: 0.6795\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7409 - val_loss: 0.5847 - val_accuracy: 0.7115\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7449 - val_loss: 0.5946 - val_accuracy: 0.6987\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5203 - accuracy: 0.7511 - val_loss: 0.6347 - val_accuracy: 0.6827\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5263 - accuracy: 0.7472 - val_loss: 0.5961 - val_accuracy: 0.6859\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5276 - accuracy: 0.7387 - val_loss: 0.6026 - val_accuracy: 0.6923\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5274 - accuracy: 0.7477 - val_loss: 0.6174 - val_accuracy: 0.6827\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5200 - accuracy: 0.7438 - val_loss: 0.6117 - val_accuracy: 0.6923\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5214 - accuracy: 0.7551 - val_loss: 0.6219 - val_accuracy: 0.6987\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5252 - accuracy: 0.7528 - val_loss: 0.5947 - val_accuracy: 0.7083\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5167 - accuracy: 0.7506 - val_loss: 0.6132 - val_accuracy: 0.6987\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5155 - accuracy: 0.7551 - val_loss: 0.6442 - val_accuracy: 0.6923\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5207 - accuracy: 0.7511 - val_loss: 0.6271 - val_accuracy: 0.7083\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5187 - accuracy: 0.7511 - val_loss: 0.6282 - val_accuracy: 0.6923\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5118 - accuracy: 0.7585 - val_loss: 0.6117 - val_accuracy: 0.6891\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5130 - accuracy: 0.7625 - val_loss: 0.6166 - val_accuracy: 0.6955\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5231 - accuracy: 0.7523 - val_loss: 0.5891 - val_accuracy: 0.7051\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5175 - accuracy: 0.7506 - val_loss: 0.6087 - val_accuracy: 0.7019\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5241 - accuracy: 0.7483 - val_loss: 0.6119 - val_accuracy: 0.7179\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5149 - accuracy: 0.7443 - val_loss: 0.6037 - val_accuracy: 0.7019\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5053 - accuracy: 0.7630 - val_loss: 0.6418 - val_accuracy: 0.6955\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5047 - accuracy: 0.7664 - val_loss: 0.6269 - val_accuracy: 0.7051\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5223 - accuracy: 0.7528 - val_loss: 0.6254 - val_accuracy: 0.7019\n",
            "17/17 [==============================] - 0s 3ms/step\n",
            "0.7288461538461538\n",
            "Accuracy: 0.7288461538461538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6410 - accuracy: 0.6548 - val_loss: 0.6336 - val_accuracy: 0.6731\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6219 - accuracy: 0.6542 - val_loss: 0.6204 - val_accuracy: 0.6923\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6712 - val_loss: 0.5817 - val_accuracy: 0.7051\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6009 - accuracy: 0.7001 - val_loss: 0.5850 - val_accuracy: 0.7147\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5865 - accuracy: 0.7098 - val_loss: 0.5808 - val_accuracy: 0.6923\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5764 - accuracy: 0.7234 - val_loss: 0.6218 - val_accuracy: 0.6314\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5844 - accuracy: 0.6967 - val_loss: 0.5764 - val_accuracy: 0.7019\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5690 - accuracy: 0.7222 - val_loss: 0.5744 - val_accuracy: 0.6923\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5740 - accuracy: 0.7154 - val_loss: 0.6023 - val_accuracy: 0.6859\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5619 - accuracy: 0.7188 - val_loss: 0.5611 - val_accuracy: 0.7019\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5538 - accuracy: 0.7324 - val_loss: 0.5551 - val_accuracy: 0.7276\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5609 - accuracy: 0.7290 - val_loss: 0.5783 - val_accuracy: 0.6923\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5650 - accuracy: 0.7234 - val_loss: 0.5599 - val_accuracy: 0.7340\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5563 - accuracy: 0.7245 - val_loss: 0.5560 - val_accuracy: 0.7212\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5592 - accuracy: 0.7245 - val_loss: 0.5653 - val_accuracy: 0.7019\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5526 - accuracy: 0.7228 - val_loss: 0.5740 - val_accuracy: 0.6859\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5579 - accuracy: 0.7302 - val_loss: 0.5666 - val_accuracy: 0.7083\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5536 - accuracy: 0.7290 - val_loss: 0.5549 - val_accuracy: 0.7404\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5574 - accuracy: 0.7160 - val_loss: 0.6371 - val_accuracy: 0.6058\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5612 - accuracy: 0.7143 - val_loss: 0.5599 - val_accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5581 - accuracy: 0.7234 - val_loss: 0.5636 - val_accuracy: 0.7051\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5485 - accuracy: 0.7268 - val_loss: 0.5766 - val_accuracy: 0.6859\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5493 - accuracy: 0.7313 - val_loss: 0.5856 - val_accuracy: 0.6763\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7392 - val_loss: 0.5715 - val_accuracy: 0.7019\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5489 - accuracy: 0.7330 - val_loss: 0.5780 - val_accuracy: 0.7083\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5536 - accuracy: 0.7137 - val_loss: 0.5625 - val_accuracy: 0.7340\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5518 - accuracy: 0.7307 - val_loss: 0.5547 - val_accuracy: 0.7340\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5340 - accuracy: 0.7432 - val_loss: 0.5616 - val_accuracy: 0.7212\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5427 - accuracy: 0.7432 - val_loss: 0.5569 - val_accuracy: 0.7212\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.7421 - val_loss: 0.5611 - val_accuracy: 0.7147\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5391 - accuracy: 0.7409 - val_loss: 0.5641 - val_accuracy: 0.7115\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5414 - accuracy: 0.7449 - val_loss: 0.5583 - val_accuracy: 0.7212\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5396 - accuracy: 0.7353 - val_loss: 0.5535 - val_accuracy: 0.7212\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.7387 - val_loss: 0.5591 - val_accuracy: 0.7276\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5398 - accuracy: 0.7324 - val_loss: 0.5561 - val_accuracy: 0.7372\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7483 - val_loss: 0.5605 - val_accuracy: 0.7115\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5379 - accuracy: 0.7375 - val_loss: 0.5464 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5298 - accuracy: 0.7426 - val_loss: 0.5513 - val_accuracy: 0.7564\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5226 - accuracy: 0.7477 - val_loss: 0.5896 - val_accuracy: 0.6859\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5300 - accuracy: 0.7398 - val_loss: 0.5621 - val_accuracy: 0.7276\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5386 - accuracy: 0.7404 - val_loss: 0.5593 - val_accuracy: 0.7179\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7477 - val_loss: 0.5553 - val_accuracy: 0.7372\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5349 - accuracy: 0.7364 - val_loss: 0.5554 - val_accuracy: 0.7244\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.7500 - val_loss: 0.5449 - val_accuracy: 0.7404\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5188 - accuracy: 0.7455 - val_loss: 0.5558 - val_accuracy: 0.7276\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5225 - accuracy: 0.7455 - val_loss: 0.5547 - val_accuracy: 0.7372\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5299 - accuracy: 0.7460 - val_loss: 0.5431 - val_accuracy: 0.7564\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7506 - val_loss: 0.5469 - val_accuracy: 0.7372\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5193 - accuracy: 0.7540 - val_loss: 0.5653 - val_accuracy: 0.7115\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5190 - accuracy: 0.7551 - val_loss: 0.5625 - val_accuracy: 0.7436\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7365384615384616\n",
            "Accuracy: 0.7365384615384616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6361 - accuracy: 0.6616 - val_loss: 0.6182 - val_accuracy: 0.6571\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6256 - accuracy: 0.6672 - val_loss: 0.6131 - val_accuracy: 0.6571\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.6132 - accuracy: 0.6695 - val_loss: 0.6008 - val_accuracy: 0.6571\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5904 - accuracy: 0.6837 - val_loss: 0.5925 - val_accuracy: 0.6635\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5870 - accuracy: 0.7046 - val_loss: 0.5814 - val_accuracy: 0.7083\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.7205 - val_loss: 0.5739 - val_accuracy: 0.7019\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5725 - accuracy: 0.7109 - val_loss: 0.5765 - val_accuracy: 0.7051\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5826 - accuracy: 0.7012 - val_loss: 0.5917 - val_accuracy: 0.6987\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5738 - accuracy: 0.7222 - val_loss: 0.5745 - val_accuracy: 0.7115\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5582 - accuracy: 0.7222 - val_loss: 0.5782 - val_accuracy: 0.7051\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5587 - accuracy: 0.7336 - val_loss: 0.5672 - val_accuracy: 0.7051\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5600 - accuracy: 0.7234 - val_loss: 0.5815 - val_accuracy: 0.6891\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5609 - accuracy: 0.7262 - val_loss: 0.5866 - val_accuracy: 0.6795\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5489 - accuracy: 0.7200 - val_loss: 0.5718 - val_accuracy: 0.6987\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5549 - accuracy: 0.7296 - val_loss: 0.5729 - val_accuracy: 0.6955\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5522 - accuracy: 0.7273 - val_loss: 0.5831 - val_accuracy: 0.7051\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5512 - accuracy: 0.7319 - val_loss: 0.6102 - val_accuracy: 0.6987\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7313 - val_loss: 0.5749 - val_accuracy: 0.7115\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5611 - accuracy: 0.7126 - val_loss: 0.5813 - val_accuracy: 0.6827\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5443 - accuracy: 0.7256 - val_loss: 0.5740 - val_accuracy: 0.7083\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5498 - accuracy: 0.7234 - val_loss: 0.5776 - val_accuracy: 0.7083\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5406 - accuracy: 0.7415 - val_loss: 0.5710 - val_accuracy: 0.6987\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5516 - accuracy: 0.7330 - val_loss: 0.5707 - val_accuracy: 0.7115\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5430 - accuracy: 0.7302 - val_loss: 0.5786 - val_accuracy: 0.7212\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5488 - accuracy: 0.7279 - val_loss: 0.5738 - val_accuracy: 0.7083\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7273 - val_loss: 0.5724 - val_accuracy: 0.6859\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5332 - accuracy: 0.7375 - val_loss: 0.5718 - val_accuracy: 0.7051\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5345 - accuracy: 0.7341 - val_loss: 0.5753 - val_accuracy: 0.6763\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5319 - accuracy: 0.7455 - val_loss: 0.5784 - val_accuracy: 0.7019\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5315 - accuracy: 0.7477 - val_loss: 0.5928 - val_accuracy: 0.7051\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5287 - accuracy: 0.7557 - val_loss: 0.5763 - val_accuracy: 0.6923\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5304 - accuracy: 0.7455 - val_loss: 0.5761 - val_accuracy: 0.7051\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5327 - accuracy: 0.7483 - val_loss: 0.5739 - val_accuracy: 0.7051\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5274 - accuracy: 0.7364 - val_loss: 0.5802 - val_accuracy: 0.7019\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.7432 - val_loss: 0.5845 - val_accuracy: 0.7051\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7353 - val_loss: 0.5795 - val_accuracy: 0.7019\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5311 - accuracy: 0.7409 - val_loss: 0.5823 - val_accuracy: 0.7083\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.7483 - val_loss: 0.5860 - val_accuracy: 0.7019\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5304 - accuracy: 0.7523 - val_loss: 0.5934 - val_accuracy: 0.6731\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5297 - accuracy: 0.7426 - val_loss: 0.5762 - val_accuracy: 0.7051\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5181 - accuracy: 0.7511 - val_loss: 0.5921 - val_accuracy: 0.6987\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5235 - accuracy: 0.7574 - val_loss: 0.5871 - val_accuracy: 0.7115\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5217 - accuracy: 0.7562 - val_loss: 0.5971 - val_accuracy: 0.7051\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.7562 - val_loss: 0.5996 - val_accuracy: 0.7115\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5313 - accuracy: 0.7523 - val_loss: 0.5824 - val_accuracy: 0.7051\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5304 - accuracy: 0.7302 - val_loss: 0.5931 - val_accuracy: 0.7115\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5205 - accuracy: 0.7489 - val_loss: 0.5883 - val_accuracy: 0.7115\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5183 - accuracy: 0.7443 - val_loss: 0.5980 - val_accuracy: 0.7340\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5257 - accuracy: 0.7432 - val_loss: 0.5965 - val_accuracy: 0.7083\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5175 - accuracy: 0.7489 - val_loss: 0.6035 - val_accuracy: 0.7019\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7461538461538462\n",
            "Accuracy: 0.7461538461538462\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 7ms/step - loss: 0.6337 - accuracy: 0.6667 - val_loss: 0.6534 - val_accuracy: 0.6186\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6729 - val_loss: 0.6375 - val_accuracy: 0.6186\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6043 - accuracy: 0.6735 - val_loss: 0.6327 - val_accuracy: 0.6186\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6000 - accuracy: 0.6859 - val_loss: 0.5993 - val_accuracy: 0.6795\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5863 - accuracy: 0.6893 - val_loss: 0.5931 - val_accuracy: 0.6955\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5821 - accuracy: 0.6978 - val_loss: 0.6300 - val_accuracy: 0.6538\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5681 - accuracy: 0.7137 - val_loss: 0.5902 - val_accuracy: 0.7051\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5681 - accuracy: 0.7109 - val_loss: 0.5819 - val_accuracy: 0.6923\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5647 - accuracy: 0.7188 - val_loss: 0.5850 - val_accuracy: 0.7051\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5593 - accuracy: 0.7279 - val_loss: 0.6366 - val_accuracy: 0.6314\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5520 - accuracy: 0.7228 - val_loss: 0.5860 - val_accuracy: 0.7051\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5541 - accuracy: 0.7251 - val_loss: 0.5847 - val_accuracy: 0.6955\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5471 - accuracy: 0.7364 - val_loss: 0.5799 - val_accuracy: 0.6923\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5487 - accuracy: 0.7324 - val_loss: 0.5843 - val_accuracy: 0.6923\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5565 - accuracy: 0.7188 - val_loss: 0.5827 - val_accuracy: 0.7083\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5379 - accuracy: 0.7347 - val_loss: 0.5854 - val_accuracy: 0.6827\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5406 - accuracy: 0.7392 - val_loss: 0.5806 - val_accuracy: 0.7019\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5435 - accuracy: 0.7443 - val_loss: 0.5876 - val_accuracy: 0.6955\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5449 - accuracy: 0.7353 - val_loss: 0.5886 - val_accuracy: 0.6923\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5407 - accuracy: 0.7455 - val_loss: 0.5903 - val_accuracy: 0.7051\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5284 - accuracy: 0.7472 - val_loss: 0.6085 - val_accuracy: 0.7051\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5345 - accuracy: 0.7438 - val_loss: 0.5771 - val_accuracy: 0.7115\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5462 - accuracy: 0.7228 - val_loss: 0.5917 - val_accuracy: 0.7051\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5367 - accuracy: 0.7392 - val_loss: 0.5912 - val_accuracy: 0.7019\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5250 - accuracy: 0.7557 - val_loss: 0.5907 - val_accuracy: 0.6955\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5372 - accuracy: 0.7432 - val_loss: 0.5992 - val_accuracy: 0.7019\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7415 - val_loss: 0.5860 - val_accuracy: 0.7115\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5266 - accuracy: 0.7483 - val_loss: 0.6431 - val_accuracy: 0.7019\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5291 - accuracy: 0.7404 - val_loss: 0.5893 - val_accuracy: 0.6891\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5299 - accuracy: 0.7477 - val_loss: 0.5850 - val_accuracy: 0.6987\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5257 - accuracy: 0.7409 - val_loss: 0.6192 - val_accuracy: 0.6859\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5193 - accuracy: 0.7506 - val_loss: 0.6089 - val_accuracy: 0.6763\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7398 - val_loss: 0.5939 - val_accuracy: 0.7051\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5183 - accuracy: 0.7562 - val_loss: 0.6165 - val_accuracy: 0.6699\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5191 - accuracy: 0.7545 - val_loss: 0.6044 - val_accuracy: 0.6987\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5218 - accuracy: 0.7438 - val_loss: 0.6188 - val_accuracy: 0.6795\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5199 - accuracy: 0.7540 - val_loss: 0.6155 - val_accuracy: 0.6763\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5188 - accuracy: 0.7523 - val_loss: 0.5944 - val_accuracy: 0.6955\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5247 - accuracy: 0.7477 - val_loss: 0.5918 - val_accuracy: 0.6987\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5103 - accuracy: 0.7585 - val_loss: 0.5848 - val_accuracy: 0.7179\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5189 - accuracy: 0.7449 - val_loss: 0.6192 - val_accuracy: 0.6987\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5118 - accuracy: 0.7528 - val_loss: 0.6215 - val_accuracy: 0.6859\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5172 - accuracy: 0.7540 - val_loss: 0.6234 - val_accuracy: 0.6891\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5034 - accuracy: 0.7653 - val_loss: 0.5977 - val_accuracy: 0.7083\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5130 - accuracy: 0.7506 - val_loss: 0.6383 - val_accuracy: 0.6923\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5055 - accuracy: 0.7540 - val_loss: 0.6562 - val_accuracy: 0.6763\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5095 - accuracy: 0.7534 - val_loss: 0.6002 - val_accuracy: 0.7051\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5080 - accuracy: 0.7574 - val_loss: 0.5993 - val_accuracy: 0.7212\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5165 - accuracy: 0.7625 - val_loss: 0.6273 - val_accuracy: 0.7115\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5084 - accuracy: 0.7704 - val_loss: 0.6326 - val_accuracy: 0.6987\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7288461538461538\n",
            "Accuracy: 0.7288461538461538\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6330 - accuracy: 0.6638 - val_loss: 0.6445 - val_accuracy: 0.6250\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6216 - accuracy: 0.6689 - val_loss: 0.6345 - val_accuracy: 0.6250\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6085 - accuracy: 0.6672 - val_loss: 0.6132 - val_accuracy: 0.6603\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5948 - accuracy: 0.6814 - val_loss: 0.5946 - val_accuracy: 0.6923\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5803 - accuracy: 0.6950 - val_loss: 0.5657 - val_accuracy: 0.7147\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5808 - accuracy: 0.7046 - val_loss: 0.5608 - val_accuracy: 0.7436\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5831 - accuracy: 0.7092 - val_loss: 0.5667 - val_accuracy: 0.7340\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5702 - accuracy: 0.7154 - val_loss: 0.5639 - val_accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5787 - accuracy: 0.7137 - val_loss: 0.5590 - val_accuracy: 0.7468\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5603 - accuracy: 0.7177 - val_loss: 0.5698 - val_accuracy: 0.7308\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5590 - accuracy: 0.7239 - val_loss: 0.5839 - val_accuracy: 0.7083\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5591 - accuracy: 0.7126 - val_loss: 0.5722 - val_accuracy: 0.7340\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5662 - accuracy: 0.7183 - val_loss: 0.5790 - val_accuracy: 0.7372\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5611 - accuracy: 0.7205 - val_loss: 0.5752 - val_accuracy: 0.7436\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5568 - accuracy: 0.7217 - val_loss: 0.5652 - val_accuracy: 0.7308\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5487 - accuracy: 0.7336 - val_loss: 0.5627 - val_accuracy: 0.7019\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5550 - accuracy: 0.7234 - val_loss: 0.5563 - val_accuracy: 0.7276\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5609 - accuracy: 0.7211 - val_loss: 0.5689 - val_accuracy: 0.7019\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5442 - accuracy: 0.7358 - val_loss: 0.5462 - val_accuracy: 0.7372\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5487 - accuracy: 0.7358 - val_loss: 0.5511 - val_accuracy: 0.7404\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5523 - accuracy: 0.7132 - val_loss: 0.5599 - val_accuracy: 0.7372\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5422 - accuracy: 0.7358 - val_loss: 0.5715 - val_accuracy: 0.7372\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5428 - accuracy: 0.7330 - val_loss: 0.5588 - val_accuracy: 0.7308\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5430 - accuracy: 0.7330 - val_loss: 0.5411 - val_accuracy: 0.7340\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5423 - accuracy: 0.7341 - val_loss: 0.5539 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5394 - accuracy: 0.7421 - val_loss: 0.5742 - val_accuracy: 0.7083\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5440 - accuracy: 0.7268 - val_loss: 0.5646 - val_accuracy: 0.7340\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5406 - accuracy: 0.7330 - val_loss: 0.5739 - val_accuracy: 0.7244\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5292 - accuracy: 0.7460 - val_loss: 0.5633 - val_accuracy: 0.7244\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.7387 - val_loss: 0.5417 - val_accuracy: 0.7276\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5372 - accuracy: 0.7319 - val_loss: 0.5621 - val_accuracy: 0.7083\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5368 - accuracy: 0.7336 - val_loss: 0.5681 - val_accuracy: 0.7115\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5305 - accuracy: 0.7494 - val_loss: 0.5538 - val_accuracy: 0.7147\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5321 - accuracy: 0.7426 - val_loss: 0.5497 - val_accuracy: 0.7276\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5297 - accuracy: 0.7415 - val_loss: 0.5607 - val_accuracy: 0.7212\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5404 - accuracy: 0.7392 - val_loss: 0.5584 - val_accuracy: 0.7436\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5266 - accuracy: 0.7506 - val_loss: 0.5610 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7472 - val_loss: 0.5534 - val_accuracy: 0.7276\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5245 - accuracy: 0.7579 - val_loss: 0.5560 - val_accuracy: 0.7179\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.7438 - val_loss: 0.5519 - val_accuracy: 0.7372\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5287 - accuracy: 0.7534 - val_loss: 0.5645 - val_accuracy: 0.7083\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.7494 - val_loss: 0.5703 - val_accuracy: 0.7212\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5186 - accuracy: 0.7528 - val_loss: 0.5912 - val_accuracy: 0.7244\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5368 - accuracy: 0.7449 - val_loss: 0.5660 - val_accuracy: 0.7308\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.7574 - val_loss: 0.5585 - val_accuracy: 0.7372\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5253 - accuracy: 0.7438 - val_loss: 0.5547 - val_accuracy: 0.7308\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5201 - accuracy: 0.7455 - val_loss: 0.5641 - val_accuracy: 0.7468\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5210 - accuracy: 0.7500 - val_loss: 0.5875 - val_accuracy: 0.7051\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5108 - accuracy: 0.7687 - val_loss: 0.5863 - val_accuracy: 0.6891\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5180 - accuracy: 0.7608 - val_loss: 0.5744 - val_accuracy: 0.7083\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7307692307692307\n",
            "Accuracy: 0.7307692307692307\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6436 - accuracy: 0.6548 - val_loss: 0.6430 - val_accuracy: 0.6474\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6264 - accuracy: 0.6599 - val_loss: 0.6242 - val_accuracy: 0.6474\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6179 - accuracy: 0.6604 - val_loss: 0.5972 - val_accuracy: 0.6474\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6110 - accuracy: 0.6633 - val_loss: 0.6488 - val_accuracy: 0.7179\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5949 - accuracy: 0.6752 - val_loss: 0.5610 - val_accuracy: 0.7115\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5931 - accuracy: 0.6780 - val_loss: 0.5690 - val_accuracy: 0.6859\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5836 - accuracy: 0.7092 - val_loss: 0.5672 - val_accuracy: 0.7083\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5806 - accuracy: 0.7098 - val_loss: 0.5516 - val_accuracy: 0.7404\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5835 - accuracy: 0.7109 - val_loss: 0.5761 - val_accuracy: 0.6827\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5749 - accuracy: 0.7160 - val_loss: 0.5535 - val_accuracy: 0.7115\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5808 - accuracy: 0.7035 - val_loss: 0.5625 - val_accuracy: 0.7083\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5685 - accuracy: 0.7166 - val_loss: 0.5524 - val_accuracy: 0.7051\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5736 - accuracy: 0.7052 - val_loss: 0.5739 - val_accuracy: 0.7372\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5611 - accuracy: 0.7194 - val_loss: 0.5676 - val_accuracy: 0.7115\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5622 - accuracy: 0.7222 - val_loss: 0.5520 - val_accuracy: 0.7372\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5571 - accuracy: 0.7205 - val_loss: 0.5395 - val_accuracy: 0.7308\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5640 - accuracy: 0.7296 - val_loss: 0.5556 - val_accuracy: 0.7147\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5646 - accuracy: 0.7194 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5481 - accuracy: 0.7222 - val_loss: 0.5533 - val_accuracy: 0.7083\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5609 - accuracy: 0.7273 - val_loss: 0.5739 - val_accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5567 - accuracy: 0.7222 - val_loss: 0.5511 - val_accuracy: 0.7115\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5629 - accuracy: 0.7080 - val_loss: 0.5538 - val_accuracy: 0.6987\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5480 - accuracy: 0.7347 - val_loss: 0.5571 - val_accuracy: 0.7212\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5574 - accuracy: 0.7245 - val_loss: 0.5453 - val_accuracy: 0.7436\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5534 - accuracy: 0.7273 - val_loss: 0.5424 - val_accuracy: 0.7308\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7319 - val_loss: 0.5494 - val_accuracy: 0.7404\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5422 - accuracy: 0.7285 - val_loss: 0.5587 - val_accuracy: 0.7308\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5502 - accuracy: 0.7319 - val_loss: 0.5559 - val_accuracy: 0.7372\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5335 - accuracy: 0.7415 - val_loss: 0.5485 - val_accuracy: 0.7372\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5482 - accuracy: 0.7347 - val_loss: 0.5889 - val_accuracy: 0.6923\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5467 - accuracy: 0.7239 - val_loss: 0.5384 - val_accuracy: 0.7340\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5424 - accuracy: 0.7273 - val_loss: 0.5498 - val_accuracy: 0.7340\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5372 - accuracy: 0.7341 - val_loss: 0.5662 - val_accuracy: 0.7115\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5420 - accuracy: 0.7279 - val_loss: 0.5621 - val_accuracy: 0.7147\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5423 - accuracy: 0.7426 - val_loss: 0.5644 - val_accuracy: 0.7083\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7387 - val_loss: 0.5531 - val_accuracy: 0.7308\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5321 - accuracy: 0.7358 - val_loss: 0.5792 - val_accuracy: 0.7147\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5332 - accuracy: 0.7404 - val_loss: 0.5742 - val_accuracy: 0.7115\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5334 - accuracy: 0.7370 - val_loss: 0.5735 - val_accuracy: 0.7372\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5400 - accuracy: 0.7268 - val_loss: 0.5545 - val_accuracy: 0.7404\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5391 - accuracy: 0.7324 - val_loss: 0.5563 - val_accuracy: 0.7372\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5292 - accuracy: 0.7477 - val_loss: 0.5730 - val_accuracy: 0.7340\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5358 - accuracy: 0.7307 - val_loss: 0.5730 - val_accuracy: 0.7019\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5259 - accuracy: 0.7398 - val_loss: 0.5714 - val_accuracy: 0.7276\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5342 - accuracy: 0.7375 - val_loss: 0.5621 - val_accuracy: 0.7244\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5294 - accuracy: 0.7341 - val_loss: 0.5797 - val_accuracy: 0.7276\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.7409 - val_loss: 0.5669 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7506 - val_loss: 0.5595 - val_accuracy: 0.7404\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5251 - accuracy: 0.7398 - val_loss: 0.5623 - val_accuracy: 0.7276\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5238 - accuracy: 0.7540 - val_loss: 0.5565 - val_accuracy: 0.7404\n",
            "17/17 [==============================] - 0s 3ms/step\n",
            "0.7307692307692307\n",
            "Accuracy: 0.7307692307692307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 7ms/step - loss: 0.6409 - accuracy: 0.6565 - val_loss: 0.6451 - val_accuracy: 0.6667\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6234 - accuracy: 0.6616 - val_loss: 0.6157 - val_accuracy: 0.7051\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.6650 - val_loss: 0.5888 - val_accuracy: 0.6987\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5974 - accuracy: 0.6899 - val_loss: 0.5851 - val_accuracy: 0.6891\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5944 - accuracy: 0.6961 - val_loss: 0.6184 - val_accuracy: 0.6186\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5819 - accuracy: 0.6973 - val_loss: 0.5602 - val_accuracy: 0.7083\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5745 - accuracy: 0.6995 - val_loss: 0.5877 - val_accuracy: 0.7212\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5825 - accuracy: 0.7115 - val_loss: 0.5708 - val_accuracy: 0.7147\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5648 - accuracy: 0.7137 - val_loss: 0.5799 - val_accuracy: 0.6506\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5618 - accuracy: 0.7222 - val_loss: 0.5453 - val_accuracy: 0.7468\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5621 - accuracy: 0.7211 - val_loss: 0.5561 - val_accuracy: 0.7340\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5620 - accuracy: 0.7205 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5639 - accuracy: 0.7143 - val_loss: 0.5563 - val_accuracy: 0.7404\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5550 - accuracy: 0.7387 - val_loss: 0.5454 - val_accuracy: 0.7372\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5573 - accuracy: 0.7222 - val_loss: 0.5409 - val_accuracy: 0.7468\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5519 - accuracy: 0.7262 - val_loss: 0.5386 - val_accuracy: 0.7468\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5442 - accuracy: 0.7375 - val_loss: 0.5654 - val_accuracy: 0.7436\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5539 - accuracy: 0.7296 - val_loss: 0.5475 - val_accuracy: 0.7436\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5528 - accuracy: 0.7341 - val_loss: 0.5402 - val_accuracy: 0.7596\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5535 - accuracy: 0.7256 - val_loss: 0.5464 - val_accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5501 - accuracy: 0.7268 - val_loss: 0.5378 - val_accuracy: 0.7404\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5463 - accuracy: 0.7307 - val_loss: 0.5401 - val_accuracy: 0.7340\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7398 - val_loss: 0.5357 - val_accuracy: 0.7340\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5441 - accuracy: 0.7324 - val_loss: 0.5404 - val_accuracy: 0.7212\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5452 - accuracy: 0.7358 - val_loss: 0.5339 - val_accuracy: 0.7436\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7358 - val_loss: 0.5327 - val_accuracy: 0.7404\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5510 - accuracy: 0.7251 - val_loss: 0.5349 - val_accuracy: 0.7308\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5348 - accuracy: 0.7370 - val_loss: 0.5409 - val_accuracy: 0.7404\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5392 - accuracy: 0.7370 - val_loss: 0.5380 - val_accuracy: 0.7436\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5360 - accuracy: 0.7353 - val_loss: 0.5386 - val_accuracy: 0.7404\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5385 - accuracy: 0.7381 - val_loss: 0.5332 - val_accuracy: 0.7436\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5334 - accuracy: 0.7449 - val_loss: 0.5571 - val_accuracy: 0.7244\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7234 - val_loss: 0.5428 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5382 - accuracy: 0.7392 - val_loss: 0.5389 - val_accuracy: 0.7564\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.7285 - val_loss: 0.5483 - val_accuracy: 0.7372\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5393 - accuracy: 0.7443 - val_loss: 0.5408 - val_accuracy: 0.7468\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5359 - accuracy: 0.7358 - val_loss: 0.5491 - val_accuracy: 0.7468\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5317 - accuracy: 0.7432 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5352 - accuracy: 0.7285 - val_loss: 0.5311 - val_accuracy: 0.7340\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5256 - accuracy: 0.7500 - val_loss: 0.5347 - val_accuracy: 0.7372\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5469 - accuracy: 0.7239 - val_loss: 0.5388 - val_accuracy: 0.7308\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5297 - accuracy: 0.7370 - val_loss: 0.5319 - val_accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5341 - accuracy: 0.7381 - val_loss: 0.5407 - val_accuracy: 0.7404\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5331 - accuracy: 0.7228 - val_loss: 0.5324 - val_accuracy: 0.7532\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5250 - accuracy: 0.7443 - val_loss: 0.5316 - val_accuracy: 0.7564\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5275 - accuracy: 0.7455 - val_loss: 0.5497 - val_accuracy: 0.7372\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5222 - accuracy: 0.7483 - val_loss: 0.5319 - val_accuracy: 0.7532\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5231 - accuracy: 0.7472 - val_loss: 0.5364 - val_accuracy: 0.7276\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5256 - accuracy: 0.7381 - val_loss: 0.5377 - val_accuracy: 0.7308\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5166 - accuracy: 0.7426 - val_loss: 0.5564 - val_accuracy: 0.7212\n",
            "17/17 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7365384615384616\n",
            "Accuracy: 0.7365384615384616\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 7ms/step - loss: 0.6409 - accuracy: 0.6610 - val_loss: 0.6374 - val_accuracy: 0.6378\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6251 - accuracy: 0.6627 - val_loss: 0.6247 - val_accuracy: 0.6378\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6087 - accuracy: 0.6689 - val_loss: 0.6326 - val_accuracy: 0.6282\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5978 - accuracy: 0.6933 - val_loss: 0.6160 - val_accuracy: 0.6442\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5877 - accuracy: 0.7115 - val_loss: 0.5929 - val_accuracy: 0.7019\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5758 - accuracy: 0.7069 - val_loss: 0.5886 - val_accuracy: 0.6827\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5755 - accuracy: 0.7035 - val_loss: 0.5882 - val_accuracy: 0.6795\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5649 - accuracy: 0.7149 - val_loss: 0.6090 - val_accuracy: 0.6667\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5723 - accuracy: 0.7143 - val_loss: 0.5868 - val_accuracy: 0.6923\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5675 - accuracy: 0.7092 - val_loss: 0.5799 - val_accuracy: 0.6955\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5570 - accuracy: 0.7137 - val_loss: 0.5933 - val_accuracy: 0.6891\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5583 - accuracy: 0.7211 - val_loss: 0.5804 - val_accuracy: 0.6827\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5543 - accuracy: 0.7296 - val_loss: 0.5858 - val_accuracy: 0.6987\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5519 - accuracy: 0.7381 - val_loss: 0.5788 - val_accuracy: 0.6987\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 9ms/step - loss: 0.5501 - accuracy: 0.7268 - val_loss: 0.5804 - val_accuracy: 0.6795\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5542 - accuracy: 0.7262 - val_loss: 0.5753 - val_accuracy: 0.7179\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.7307 - val_loss: 0.5810 - val_accuracy: 0.6763\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5478 - accuracy: 0.7234 - val_loss: 0.5710 - val_accuracy: 0.7051\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5492 - accuracy: 0.7302 - val_loss: 0.5806 - val_accuracy: 0.7179\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5492 - accuracy: 0.7313 - val_loss: 0.5726 - val_accuracy: 0.7115\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5388 - accuracy: 0.7347 - val_loss: 0.5691 - val_accuracy: 0.7051\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5520 - accuracy: 0.7251 - val_loss: 0.5752 - val_accuracy: 0.7244\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5414 - accuracy: 0.7421 - val_loss: 0.5694 - val_accuracy: 0.7019\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5404 - accuracy: 0.7347 - val_loss: 0.5749 - val_accuracy: 0.7276\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5316 - accuracy: 0.7375 - val_loss: 0.5754 - val_accuracy: 0.6955\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5417 - accuracy: 0.7353 - val_loss: 0.5794 - val_accuracy: 0.6795\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5401 - accuracy: 0.7421 - val_loss: 0.5829 - val_accuracy: 0.6923\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5347 - accuracy: 0.7341 - val_loss: 0.5701 - val_accuracy: 0.6891\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7398 - val_loss: 0.5816 - val_accuracy: 0.6795\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5363 - accuracy: 0.7302 - val_loss: 0.5808 - val_accuracy: 0.7019\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5450 - accuracy: 0.7483 - val_loss: 0.6007 - val_accuracy: 0.7083\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5275 - accuracy: 0.7432 - val_loss: 0.5688 - val_accuracy: 0.7051\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5309 - accuracy: 0.7404 - val_loss: 0.5735 - val_accuracy: 0.7212\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5281 - accuracy: 0.7438 - val_loss: 0.5785 - val_accuracy: 0.7115\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5335 - accuracy: 0.7466 - val_loss: 0.5784 - val_accuracy: 0.7115\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5300 - accuracy: 0.7398 - val_loss: 0.5703 - val_accuracy: 0.7308\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5214 - accuracy: 0.7574 - val_loss: 0.5709 - val_accuracy: 0.7179\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5368 - accuracy: 0.7392 - val_loss: 0.5714 - val_accuracy: 0.7083\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5204 - accuracy: 0.7489 - val_loss: 0.5778 - val_accuracy: 0.7083\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5274 - accuracy: 0.7347 - val_loss: 0.5763 - val_accuracy: 0.7019\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5209 - accuracy: 0.7358 - val_loss: 0.5774 - val_accuracy: 0.6987\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5153 - accuracy: 0.7596 - val_loss: 0.6181 - val_accuracy: 0.6763\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5253 - accuracy: 0.7432 - val_loss: 0.5715 - val_accuracy: 0.6923\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.7415 - val_loss: 0.5738 - val_accuracy: 0.7147\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5301 - accuracy: 0.7347 - val_loss: 0.5732 - val_accuracy: 0.7147\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5159 - accuracy: 0.7460 - val_loss: 0.5923 - val_accuracy: 0.6891\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5203 - accuracy: 0.7483 - val_loss: 0.5830 - val_accuracy: 0.6923\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5149 - accuracy: 0.7483 - val_loss: 0.5901 - val_accuracy: 0.6987\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5276 - accuracy: 0.7500 - val_loss: 0.5885 - val_accuracy: 0.7179\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5136 - accuracy: 0.7483 - val_loss: 0.5826 - val_accuracy: 0.7179\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7442307692307693\n",
            "Accuracy: 0.7442307692307693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6373 - accuracy: 0.6678 - val_loss: 0.6190 - val_accuracy: 0.6891\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6166 - accuracy: 0.6746 - val_loss: 0.6002 - val_accuracy: 0.7212\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5940 - accuracy: 0.6927 - val_loss: 0.5747 - val_accuracy: 0.6923\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5892 - accuracy: 0.6763 - val_loss: 0.5876 - val_accuracy: 0.6891\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5831 - accuracy: 0.6842 - val_loss: 0.5633 - val_accuracy: 0.7276\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5704 - accuracy: 0.7154 - val_loss: 0.6220 - val_accuracy: 0.6635\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5710 - accuracy: 0.7086 - val_loss: 0.5834 - val_accuracy: 0.6923\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5662 - accuracy: 0.7228 - val_loss: 0.5681 - val_accuracy: 0.7083\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5513 - accuracy: 0.7239 - val_loss: 0.5639 - val_accuracy: 0.7436\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5603 - accuracy: 0.7273 - val_loss: 0.5662 - val_accuracy: 0.7019\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5461 - accuracy: 0.7273 - val_loss: 0.6327 - val_accuracy: 0.6250\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5645 - accuracy: 0.7211 - val_loss: 0.5659 - val_accuracy: 0.7308\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5443 - accuracy: 0.7256 - val_loss: 0.5802 - val_accuracy: 0.6955\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5507 - accuracy: 0.7358 - val_loss: 0.5736 - val_accuracy: 0.7083\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5453 - accuracy: 0.7307 - val_loss: 0.5821 - val_accuracy: 0.7019\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5376 - accuracy: 0.7273 - val_loss: 0.5724 - val_accuracy: 0.7212\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5361 - accuracy: 0.7398 - val_loss: 0.5759 - val_accuracy: 0.7436\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5330 - accuracy: 0.7455 - val_loss: 0.5551 - val_accuracy: 0.7500\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5442 - accuracy: 0.7364 - val_loss: 0.5660 - val_accuracy: 0.7404\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5336 - accuracy: 0.7398 - val_loss: 0.5876 - val_accuracy: 0.6955\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5300 - accuracy: 0.7415 - val_loss: 0.5759 - val_accuracy: 0.7051\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5277 - accuracy: 0.7545 - val_loss: 0.5935 - val_accuracy: 0.6987\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5399 - accuracy: 0.7273 - val_loss: 0.5967 - val_accuracy: 0.6795\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5298 - accuracy: 0.7460 - val_loss: 0.6116 - val_accuracy: 0.6795\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5301 - accuracy: 0.7443 - val_loss: 0.5733 - val_accuracy: 0.7468\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5276 - accuracy: 0.7449 - val_loss: 0.5724 - val_accuracy: 0.7468\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5237 - accuracy: 0.7494 - val_loss: 0.5787 - val_accuracy: 0.7051\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5283 - accuracy: 0.7409 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5245 - accuracy: 0.7489 - val_loss: 0.5733 - val_accuracy: 0.7276\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5210 - accuracy: 0.7517 - val_loss: 0.5814 - val_accuracy: 0.7147\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5259 - accuracy: 0.7506 - val_loss: 0.6088 - val_accuracy: 0.6795\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5217 - accuracy: 0.7534 - val_loss: 0.5912 - val_accuracy: 0.6859\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.7511 - val_loss: 0.5733 - val_accuracy: 0.7404\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5229 - accuracy: 0.7557 - val_loss: 0.5770 - val_accuracy: 0.6987\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5230 - accuracy: 0.7528 - val_loss: 0.5998 - val_accuracy: 0.6827\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5255 - accuracy: 0.7545 - val_loss: 0.5915 - val_accuracy: 0.7340\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5198 - accuracy: 0.7500 - val_loss: 0.5803 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5208 - accuracy: 0.7562 - val_loss: 0.6017 - val_accuracy: 0.6859\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5154 - accuracy: 0.7608 - val_loss: 0.6065 - val_accuracy: 0.6859\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5114 - accuracy: 0.7642 - val_loss: 0.5937 - val_accuracy: 0.7340\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7579 - val_loss: 0.6011 - val_accuracy: 0.6987\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5119 - accuracy: 0.7579 - val_loss: 0.6145 - val_accuracy: 0.6731\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5190 - accuracy: 0.7585 - val_loss: 0.5962 - val_accuracy: 0.7019\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5086 - accuracy: 0.7579 - val_loss: 0.6168 - val_accuracy: 0.6827\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5057 - accuracy: 0.7574 - val_loss: 0.5894 - val_accuracy: 0.7051\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5140 - accuracy: 0.7545 - val_loss: 0.5829 - val_accuracy: 0.7532\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5190 - accuracy: 0.7500 - val_loss: 0.5923 - val_accuracy: 0.7179\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5119 - accuracy: 0.7585 - val_loss: 0.6030 - val_accuracy: 0.7468\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5129 - accuracy: 0.7506 - val_loss: 0.5996 - val_accuracy: 0.6955\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5095 - accuracy: 0.7625 - val_loss: 0.5946 - val_accuracy: 0.7372\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7057692307692308\n",
            "Accuracy: 0.7057692307692308\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6294 - accuracy: 0.6718 - val_loss: 0.6588 - val_accuracy: 0.6186\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6250 - accuracy: 0.6729 - val_loss: 0.6464 - val_accuracy: 0.6186\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6048 - accuracy: 0.6723 - val_loss: 0.6462 - val_accuracy: 0.6186\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5965 - accuracy: 0.6746 - val_loss: 0.6111 - val_accuracy: 0.6859\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5906 - accuracy: 0.6831 - val_loss: 0.6149 - val_accuracy: 0.7051\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5904 - accuracy: 0.6882 - val_loss: 0.6081 - val_accuracy: 0.7019\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5830 - accuracy: 0.7007 - val_loss: 0.6096 - val_accuracy: 0.6699\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5811 - accuracy: 0.7052 - val_loss: 0.5820 - val_accuracy: 0.7019\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5715 - accuracy: 0.7132 - val_loss: 0.5872 - val_accuracy: 0.7019\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5598 - accuracy: 0.7126 - val_loss: 0.5835 - val_accuracy: 0.6891\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5578 - accuracy: 0.7268 - val_loss: 0.5902 - val_accuracy: 0.6891\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5543 - accuracy: 0.7341 - val_loss: 0.5739 - val_accuracy: 0.7051\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5562 - accuracy: 0.7177 - val_loss: 0.5765 - val_accuracy: 0.7019\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5531 - accuracy: 0.7353 - val_loss: 0.5715 - val_accuracy: 0.6891\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5695 - accuracy: 0.7188 - val_loss: 0.5773 - val_accuracy: 0.6923\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5491 - accuracy: 0.7228 - val_loss: 0.6039 - val_accuracy: 0.6410\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5560 - accuracy: 0.7302 - val_loss: 0.5988 - val_accuracy: 0.6442\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5486 - accuracy: 0.7387 - val_loss: 0.5888 - val_accuracy: 0.6987\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5498 - accuracy: 0.7268 - val_loss: 0.5702 - val_accuracy: 0.7147\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5552 - accuracy: 0.7324 - val_loss: 0.5916 - val_accuracy: 0.7019\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5397 - accuracy: 0.7381 - val_loss: 0.5753 - val_accuracy: 0.6763\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5534 - accuracy: 0.7307 - val_loss: 0.5906 - val_accuracy: 0.6987\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5455 - accuracy: 0.7387 - val_loss: 0.5835 - val_accuracy: 0.6923\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5489 - accuracy: 0.7285 - val_loss: 0.5893 - val_accuracy: 0.6795\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5376 - accuracy: 0.7426 - val_loss: 0.5764 - val_accuracy: 0.6859\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5442 - accuracy: 0.7347 - val_loss: 0.6006 - val_accuracy: 0.6603\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5373 - accuracy: 0.7455 - val_loss: 0.5648 - val_accuracy: 0.7019\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5373 - accuracy: 0.7455 - val_loss: 0.5728 - val_accuracy: 0.7115\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5376 - accuracy: 0.7460 - val_loss: 0.5796 - val_accuracy: 0.7019\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5402 - accuracy: 0.7364 - val_loss: 0.5726 - val_accuracy: 0.7115\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5410 - accuracy: 0.7426 - val_loss: 0.5738 - val_accuracy: 0.6955\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5401 - accuracy: 0.7415 - val_loss: 0.5768 - val_accuracy: 0.6795\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5376 - accuracy: 0.7409 - val_loss: 0.5781 - val_accuracy: 0.6923\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7432 - val_loss: 0.5637 - val_accuracy: 0.7083\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5358 - accuracy: 0.7426 - val_loss: 0.5693 - val_accuracy: 0.6987\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5339 - accuracy: 0.7472 - val_loss: 0.5691 - val_accuracy: 0.7083\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5289 - accuracy: 0.7432 - val_loss: 0.5671 - val_accuracy: 0.7019\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5375 - accuracy: 0.7438 - val_loss: 0.5641 - val_accuracy: 0.6987\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.7500 - val_loss: 0.5624 - val_accuracy: 0.7019\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5399 - accuracy: 0.7404 - val_loss: 0.5769 - val_accuracy: 0.7115\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5296 - accuracy: 0.7455 - val_loss: 0.5898 - val_accuracy: 0.6955\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5239 - accuracy: 0.7528 - val_loss: 0.5638 - val_accuracy: 0.7147\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5262 - accuracy: 0.7494 - val_loss: 0.5661 - val_accuracy: 0.6987\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5232 - accuracy: 0.7517 - val_loss: 0.5720 - val_accuracy: 0.7115\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5327 - accuracy: 0.7421 - val_loss: 0.5718 - val_accuracy: 0.6955\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5249 - accuracy: 0.7438 - val_loss: 0.5812 - val_accuracy: 0.6859\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5279 - accuracy: 0.7517 - val_loss: 0.5717 - val_accuracy: 0.7019\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5229 - accuracy: 0.7506 - val_loss: 0.5804 - val_accuracy: 0.6987\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5331 - accuracy: 0.7330 - val_loss: 0.5737 - val_accuracy: 0.7019\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5295 - accuracy: 0.7477 - val_loss: 0.5721 - val_accuracy: 0.7115\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7403846153846154\n",
            "Accuracy: 0.7403846153846154\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6415 - accuracy: 0.6491 - val_loss: 0.6138 - val_accuracy: 0.6571\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6339 - accuracy: 0.6599 - val_loss: 0.6073 - val_accuracy: 0.6571\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6138 - accuracy: 0.6667 - val_loss: 0.5845 - val_accuracy: 0.6955\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5993 - accuracy: 0.6837 - val_loss: 0.5949 - val_accuracy: 0.6538\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5860 - accuracy: 0.6916 - val_loss: 0.5816 - val_accuracy: 0.6923\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5777 - accuracy: 0.7058 - val_loss: 0.5843 - val_accuracy: 0.6699\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5859 - accuracy: 0.7086 - val_loss: 0.5871 - val_accuracy: 0.7051\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5711 - accuracy: 0.7217 - val_loss: 0.5914 - val_accuracy: 0.6827\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5653 - accuracy: 0.7143 - val_loss: 0.5855 - val_accuracy: 0.6827\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5652 - accuracy: 0.7188 - val_loss: 0.5930 - val_accuracy: 0.6891\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5660 - accuracy: 0.7160 - val_loss: 0.5810 - val_accuracy: 0.6859\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5637 - accuracy: 0.7324 - val_loss: 0.5925 - val_accuracy: 0.6987\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5573 - accuracy: 0.7296 - val_loss: 0.6033 - val_accuracy: 0.6859\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5600 - accuracy: 0.7285 - val_loss: 0.5876 - val_accuracy: 0.7083\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5663 - accuracy: 0.7222 - val_loss: 0.5821 - val_accuracy: 0.7083\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5540 - accuracy: 0.7381 - val_loss: 0.5819 - val_accuracy: 0.6891\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5566 - accuracy: 0.7290 - val_loss: 0.6080 - val_accuracy: 0.6955\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5576 - accuracy: 0.7262 - val_loss: 0.5852 - val_accuracy: 0.7019\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5472 - accuracy: 0.7307 - val_loss: 0.5811 - val_accuracy: 0.6923\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7262 - val_loss: 0.5802 - val_accuracy: 0.6603\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5548 - accuracy: 0.7228 - val_loss: 0.6388 - val_accuracy: 0.6923\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5541 - accuracy: 0.7268 - val_loss: 0.5734 - val_accuracy: 0.7019\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7336 - val_loss: 0.5860 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5477 - accuracy: 0.7234 - val_loss: 0.5802 - val_accuracy: 0.7019\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5475 - accuracy: 0.7154 - val_loss: 0.5792 - val_accuracy: 0.6923\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5413 - accuracy: 0.7262 - val_loss: 0.5631 - val_accuracy: 0.6859\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5537 - accuracy: 0.7341 - val_loss: 0.5553 - val_accuracy: 0.7051\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5407 - accuracy: 0.7302 - val_loss: 0.5821 - val_accuracy: 0.7019\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5420 - accuracy: 0.7375 - val_loss: 0.5660 - val_accuracy: 0.7115\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5426 - accuracy: 0.7307 - val_loss: 0.5821 - val_accuracy: 0.7019\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5341 - accuracy: 0.7353 - val_loss: 0.5910 - val_accuracy: 0.7083\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5356 - accuracy: 0.7358 - val_loss: 0.5687 - val_accuracy: 0.6987\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5371 - accuracy: 0.7353 - val_loss: 0.5731 - val_accuracy: 0.7083\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5313 - accuracy: 0.7489 - val_loss: 0.5654 - val_accuracy: 0.6987\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5305 - accuracy: 0.7438 - val_loss: 0.5959 - val_accuracy: 0.7051\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5344 - accuracy: 0.7341 - val_loss: 0.5740 - val_accuracy: 0.6987\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5277 - accuracy: 0.7443 - val_loss: 0.5791 - val_accuracy: 0.7147\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5288 - accuracy: 0.7460 - val_loss: 0.5741 - val_accuracy: 0.6795\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5434 - accuracy: 0.7262 - val_loss: 0.5695 - val_accuracy: 0.6923\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.7449 - val_loss: 0.5879 - val_accuracy: 0.7179\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5298 - accuracy: 0.7443 - val_loss: 0.5662 - val_accuracy: 0.6795\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7415 - val_loss: 0.5728 - val_accuracy: 0.6987\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.7347 - val_loss: 0.5741 - val_accuracy: 0.7308\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7540 - val_loss: 0.5940 - val_accuracy: 0.7244\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5223 - accuracy: 0.7449 - val_loss: 0.5644 - val_accuracy: 0.7083\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.7443 - val_loss: 0.6078 - val_accuracy: 0.7212\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7353 - val_loss: 0.5705 - val_accuracy: 0.7212\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5218 - accuracy: 0.7455 - val_loss: 0.5825 - val_accuracy: 0.7212\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5176 - accuracy: 0.7443 - val_loss: 0.5903 - val_accuracy: 0.7147\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5204 - accuracy: 0.7511 - val_loss: 0.5713 - val_accuracy: 0.6731\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7211538461538461\n",
            "Accuracy: 0.7211538461538461\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6253 - accuracy: 0.6769 - val_loss: 0.6477 - val_accuracy: 0.6763\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6155 - accuracy: 0.6814 - val_loss: 0.6097 - val_accuracy: 0.6442\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6084 - accuracy: 0.6808 - val_loss: 0.6208 - val_accuracy: 0.6442\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5995 - accuracy: 0.6786 - val_loss: 0.5858 - val_accuracy: 0.7404\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5783 - accuracy: 0.7063 - val_loss: 0.5642 - val_accuracy: 0.7468\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5830 - accuracy: 0.6944 - val_loss: 0.5618 - val_accuracy: 0.6955\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5757 - accuracy: 0.7143 - val_loss: 0.5732 - val_accuracy: 0.7244\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5655 - accuracy: 0.7194 - val_loss: 0.5696 - val_accuracy: 0.6731\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5669 - accuracy: 0.7126 - val_loss: 0.5457 - val_accuracy: 0.7788\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5601 - accuracy: 0.7080 - val_loss: 0.5269 - val_accuracy: 0.7564\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5623 - accuracy: 0.7296 - val_loss: 0.5562 - val_accuracy: 0.7724\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7262 - val_loss: 0.5328 - val_accuracy: 0.7628\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5545 - accuracy: 0.7188 - val_loss: 0.5254 - val_accuracy: 0.7788\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5498 - accuracy: 0.7200 - val_loss: 0.5623 - val_accuracy: 0.7756\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7279 - val_loss: 0.5381 - val_accuracy: 0.7660\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5539 - accuracy: 0.7302 - val_loss: 0.5543 - val_accuracy: 0.7372\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5402 - accuracy: 0.7324 - val_loss: 0.5436 - val_accuracy: 0.7051\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5529 - accuracy: 0.7222 - val_loss: 0.5225 - val_accuracy: 0.7468\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5497 - accuracy: 0.7364 - val_loss: 0.5311 - val_accuracy: 0.7564\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5457 - accuracy: 0.7290 - val_loss: 0.5464 - val_accuracy: 0.7276\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5378 - accuracy: 0.7347 - val_loss: 0.5465 - val_accuracy: 0.7244\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5428 - accuracy: 0.7319 - val_loss: 0.5187 - val_accuracy: 0.7564\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5426 - accuracy: 0.7324 - val_loss: 0.5506 - val_accuracy: 0.6987\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5389 - accuracy: 0.7336 - val_loss: 0.5274 - val_accuracy: 0.7468\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5525 - accuracy: 0.7341 - val_loss: 0.5374 - val_accuracy: 0.7276\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5447 - accuracy: 0.7324 - val_loss: 0.5367 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7268 - val_loss: 0.5333 - val_accuracy: 0.7244\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5441 - accuracy: 0.7256 - val_loss: 0.5461 - val_accuracy: 0.7051\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5305 - accuracy: 0.7358 - val_loss: 0.5264 - val_accuracy: 0.7404\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 9ms/step - loss: 0.5253 - accuracy: 0.7387 - val_loss: 0.5429 - val_accuracy: 0.7051\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5392 - accuracy: 0.7398 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5278 - accuracy: 0.7460 - val_loss: 0.5421 - val_accuracy: 0.7212\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5328 - accuracy: 0.7432 - val_loss: 0.5390 - val_accuracy: 0.7179\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.7426 - val_loss: 0.5301 - val_accuracy: 0.7276\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5249 - accuracy: 0.7500 - val_loss: 0.5308 - val_accuracy: 0.7308\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7460 - val_loss: 0.5330 - val_accuracy: 0.7340\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5220 - accuracy: 0.7455 - val_loss: 0.5411 - val_accuracy: 0.7532\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5265 - accuracy: 0.7421 - val_loss: 0.5379 - val_accuracy: 0.7372\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5203 - accuracy: 0.7494 - val_loss: 0.5494 - val_accuracy: 0.7596\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5214 - accuracy: 0.7432 - val_loss: 0.5625 - val_accuracy: 0.7051\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5211 - accuracy: 0.7472 - val_loss: 0.5646 - val_accuracy: 0.6955\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5220 - accuracy: 0.7449 - val_loss: 0.5463 - val_accuracy: 0.7532\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.7347 - val_loss: 0.5334 - val_accuracy: 0.7115\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5141 - accuracy: 0.7534 - val_loss: 0.5573 - val_accuracy: 0.7500\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.7307 - val_loss: 0.5592 - val_accuracy: 0.7115\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7528 - val_loss: 0.5745 - val_accuracy: 0.6891\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5282 - accuracy: 0.7466 - val_loss: 0.5845 - val_accuracy: 0.6795\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5197 - accuracy: 0.7483 - val_loss: 0.5480 - val_accuracy: 0.7051\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5112 - accuracy: 0.7557 - val_loss: 0.5518 - val_accuracy: 0.7212\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5199 - accuracy: 0.7534 - val_loss: 0.5557 - val_accuracy: 0.7212\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7076923076923077\n",
            "Accuracy: 0.7076923076923077\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 13ms/step - loss: 0.6382 - accuracy: 0.6570 - val_loss: 0.6306 - val_accuracy: 0.6987\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6174 - accuracy: 0.6644 - val_loss: 0.5767 - val_accuracy: 0.6987\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6229 - accuracy: 0.6576 - val_loss: 0.5918 - val_accuracy: 0.6987\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5977 - accuracy: 0.6910 - val_loss: 0.6443 - val_accuracy: 0.5833\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5920 - accuracy: 0.6933 - val_loss: 0.5822 - val_accuracy: 0.6635\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5940 - accuracy: 0.6791 - val_loss: 0.5549 - val_accuracy: 0.7276\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5703 - accuracy: 0.7132 - val_loss: 0.5454 - val_accuracy: 0.7372\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5670 - accuracy: 0.7177 - val_loss: 0.5219 - val_accuracy: 0.7436\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5687 - accuracy: 0.7256 - val_loss: 0.5292 - val_accuracy: 0.7564\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5681 - accuracy: 0.7171 - val_loss: 0.5309 - val_accuracy: 0.7692\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5728 - accuracy: 0.7052 - val_loss: 0.5283 - val_accuracy: 0.7436\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5701 - accuracy: 0.6961 - val_loss: 0.5259 - val_accuracy: 0.7692\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5667 - accuracy: 0.7171 - val_loss: 0.5495 - val_accuracy: 0.7276\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5607 - accuracy: 0.7188 - val_loss: 0.5665 - val_accuracy: 0.7147\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5692 - accuracy: 0.7069 - val_loss: 0.5192 - val_accuracy: 0.7596\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5540 - accuracy: 0.7256 - val_loss: 0.5390 - val_accuracy: 0.7212\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5529 - accuracy: 0.7239 - val_loss: 0.5267 - val_accuracy: 0.7724\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5543 - accuracy: 0.7228 - val_loss: 0.5465 - val_accuracy: 0.6955\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5491 - accuracy: 0.7324 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5439 - accuracy: 0.7319 - val_loss: 0.5731 - val_accuracy: 0.6699\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5471 - accuracy: 0.7353 - val_loss: 0.5620 - val_accuracy: 0.6859\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5482 - accuracy: 0.7449 - val_loss: 0.5322 - val_accuracy: 0.7372\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5578 - accuracy: 0.7251 - val_loss: 0.5852 - val_accuracy: 0.6603\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5528 - accuracy: 0.7262 - val_loss: 0.5385 - val_accuracy: 0.7436\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5415 - accuracy: 0.7370 - val_loss: 0.5134 - val_accuracy: 0.7756\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7296 - val_loss: 0.5430 - val_accuracy: 0.7244\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5405 - accuracy: 0.7409 - val_loss: 0.5224 - val_accuracy: 0.7628\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5383 - accuracy: 0.7432 - val_loss: 0.5369 - val_accuracy: 0.7115\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7358 - val_loss: 0.5518 - val_accuracy: 0.6763\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5426 - accuracy: 0.7279 - val_loss: 0.5554 - val_accuracy: 0.6955\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5371 - accuracy: 0.7273 - val_loss: 0.5233 - val_accuracy: 0.7372\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5403 - accuracy: 0.7398 - val_loss: 0.5494 - val_accuracy: 0.7212\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5427 - accuracy: 0.7364 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5331 - accuracy: 0.7494 - val_loss: 0.5361 - val_accuracy: 0.7276\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5322 - accuracy: 0.7466 - val_loss: 0.5717 - val_accuracy: 0.6795\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5389 - accuracy: 0.7313 - val_loss: 0.5232 - val_accuracy: 0.7532\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5333 - accuracy: 0.7443 - val_loss: 0.5277 - val_accuracy: 0.7308\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5334 - accuracy: 0.7375 - val_loss: 0.6280 - val_accuracy: 0.6186\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5308 - accuracy: 0.7353 - val_loss: 0.5530 - val_accuracy: 0.7019\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5301 - accuracy: 0.7370 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5272 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.6795\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5263 - accuracy: 0.7494 - val_loss: 0.5488 - val_accuracy: 0.6923\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5300 - accuracy: 0.7387 - val_loss: 0.5337 - val_accuracy: 0.7532\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5224 - accuracy: 0.7506 - val_loss: 0.5399 - val_accuracy: 0.7244\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5248 - accuracy: 0.7472 - val_loss: 0.5405 - val_accuracy: 0.7147\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5201 - accuracy: 0.7557 - val_loss: 0.5373 - val_accuracy: 0.7212\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5230 - accuracy: 0.7517 - val_loss: 0.5308 - val_accuracy: 0.7404\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5299 - accuracy: 0.7290 - val_loss: 0.5619 - val_accuracy: 0.6859\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5194 - accuracy: 0.7523 - val_loss: 0.5353 - val_accuracy: 0.7340\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5192 - accuracy: 0.7545 - val_loss: 0.5432 - val_accuracy: 0.7308\n",
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7211538461538461\n",
            "Accuracy: 0.7211538461538461\n",
            "Epoch 1/50\n",
            "111/111 [==============================] - 3s 7ms/step - loss: 0.6290 - accuracy: 0.6701 - val_loss: 0.6493 - val_accuracy: 0.6987\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6194 - accuracy: 0.6655 - val_loss: 0.6310 - val_accuracy: 0.6314\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5974 - accuracy: 0.6633 - val_loss: 0.6221 - val_accuracy: 0.6314\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5846 - accuracy: 0.6876 - val_loss: 0.6130 - val_accuracy: 0.6827\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5761 - accuracy: 0.7120 - val_loss: 0.6016 - val_accuracy: 0.6987\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5652 - accuracy: 0.7120 - val_loss: 0.5939 - val_accuracy: 0.6955\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5703 - accuracy: 0.7188 - val_loss: 0.5914 - val_accuracy: 0.7179\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5549 - accuracy: 0.7341 - val_loss: 0.5916 - val_accuracy: 0.7019\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5610 - accuracy: 0.7302 - val_loss: 0.5870 - val_accuracy: 0.7179\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5492 - accuracy: 0.7217 - val_loss: 0.5908 - val_accuracy: 0.7051\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5533 - accuracy: 0.7296 - val_loss: 0.6058 - val_accuracy: 0.6955\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5485 - accuracy: 0.7217 - val_loss: 0.6383 - val_accuracy: 0.7212\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5471 - accuracy: 0.7375 - val_loss: 0.5990 - val_accuracy: 0.6955\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5455 - accuracy: 0.7347 - val_loss: 0.5989 - val_accuracy: 0.6891\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5413 - accuracy: 0.7421 - val_loss: 0.5846 - val_accuracy: 0.7115\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5432 - accuracy: 0.7296 - val_loss: 0.5921 - val_accuracy: 0.6827\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5364 - accuracy: 0.7381 - val_loss: 0.5867 - val_accuracy: 0.7083\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5429 - accuracy: 0.7415 - val_loss: 0.5846 - val_accuracy: 0.7083\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7472 - val_loss: 0.6204 - val_accuracy: 0.6442\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5434 - accuracy: 0.7387 - val_loss: 0.6250 - val_accuracy: 0.6667\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5449 - accuracy: 0.7341 - val_loss: 0.5807 - val_accuracy: 0.7083\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5345 - accuracy: 0.7415 - val_loss: 0.5910 - val_accuracy: 0.7051\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5380 - accuracy: 0.7432 - val_loss: 0.5920 - val_accuracy: 0.7115\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5300 - accuracy: 0.7426 - val_loss: 0.5981 - val_accuracy: 0.6923\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5324 - accuracy: 0.7398 - val_loss: 0.5818 - val_accuracy: 0.7179\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5246 - accuracy: 0.7528 - val_loss: 0.6205 - val_accuracy: 0.6571\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5344 - accuracy: 0.7336 - val_loss: 0.5857 - val_accuracy: 0.7147\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5309 - accuracy: 0.7506 - val_loss: 0.5941 - val_accuracy: 0.7115\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5307 - accuracy: 0.7421 - val_loss: 0.5759 - val_accuracy: 0.7276\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5218 - accuracy: 0.7500 - val_loss: 0.5857 - val_accuracy: 0.7147\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5281 - accuracy: 0.7421 - val_loss: 0.5918 - val_accuracy: 0.7083\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5308 - accuracy: 0.7443 - val_loss: 0.5737 - val_accuracy: 0.7147\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5226 - accuracy: 0.7409 - val_loss: 0.6040 - val_accuracy: 0.7083\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5127 - accuracy: 0.7489 - val_loss: 0.6036 - val_accuracy: 0.7019\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5285 - accuracy: 0.7443 - val_loss: 0.5771 - val_accuracy: 0.7019\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5178 - accuracy: 0.7500 - val_loss: 0.5837 - val_accuracy: 0.7147\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5148 - accuracy: 0.7489 - val_loss: 0.5728 - val_accuracy: 0.7212\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5170 - accuracy: 0.7557 - val_loss: 0.5774 - val_accuracy: 0.7083\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5152 - accuracy: 0.7489 - val_loss: 0.5846 - val_accuracy: 0.7276\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5196 - accuracy: 0.7483 - val_loss: 0.5721 - val_accuracy: 0.7147\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5136 - accuracy: 0.7562 - val_loss: 0.5780 - val_accuracy: 0.7083\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5153 - accuracy: 0.7500 - val_loss: 0.5704 - val_accuracy: 0.7276\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5123 - accuracy: 0.7557 - val_loss: 0.6070 - val_accuracy: 0.7083\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5112 - accuracy: 0.7477 - val_loss: 0.5813 - val_accuracy: 0.7212\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5225 - accuracy: 0.7506 - val_loss: 0.5734 - val_accuracy: 0.7212\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.7596 - val_loss: 0.5776 - val_accuracy: 0.7276\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5109 - accuracy: 0.7540 - val_loss: 0.5760 - val_accuracy: 0.6827\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5229 - accuracy: 0.7466 - val_loss: 0.5767 - val_accuracy: 0.7051\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5088 - accuracy: 0.7534 - val_loss: 0.5720 - val_accuracy: 0.7051\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5007 - accuracy: 0.7613 - val_loss: 0.5738 - val_accuracy: 0.7147\n",
            "17/17 [==============================] - 0s 3ms/step\n",
            "0.698076923076923\n",
            "Accuracy: 0.698076923076923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "111/111 [==============================] - 4s 7ms/step - loss: 0.6426 - accuracy: 0.6559 - val_loss: 0.5982 - val_accuracy: 0.6891\n",
            "Epoch 2/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6301 - accuracy: 0.6548 - val_loss: 0.5808 - val_accuracy: 0.6891\n",
            "Epoch 3/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6226 - accuracy: 0.6559 - val_loss: 0.5621 - val_accuracy: 0.6891\n",
            "Epoch 4/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6047 - accuracy: 0.6559 - val_loss: 0.5459 - val_accuracy: 0.7244\n",
            "Epoch 5/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.6027 - accuracy: 0.6922 - val_loss: 0.5362 - val_accuracy: 0.7147\n",
            "Epoch 6/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5903 - accuracy: 0.7075 - val_loss: 0.5478 - val_accuracy: 0.7051\n",
            "Epoch 7/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5864 - accuracy: 0.7086 - val_loss: 0.5786 - val_accuracy: 0.7083\n",
            "Epoch 8/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5790 - accuracy: 0.7052 - val_loss: 0.5492 - val_accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5762 - accuracy: 0.7024 - val_loss: 0.5551 - val_accuracy: 0.7212\n",
            "Epoch 10/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5723 - accuracy: 0.7200 - val_loss: 0.5472 - val_accuracy: 0.7179\n",
            "Epoch 11/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5723 - accuracy: 0.7098 - val_loss: 0.5644 - val_accuracy: 0.7019\n",
            "Epoch 12/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5624 - accuracy: 0.7228 - val_loss: 0.5613 - val_accuracy: 0.7115\n",
            "Epoch 13/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5687 - accuracy: 0.7018 - val_loss: 0.5539 - val_accuracy: 0.7083\n",
            "Epoch 14/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5677 - accuracy: 0.7109 - val_loss: 0.5630 - val_accuracy: 0.7179\n",
            "Epoch 15/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5583 - accuracy: 0.7302 - val_loss: 0.5482 - val_accuracy: 0.7244\n",
            "Epoch 16/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5616 - accuracy: 0.7205 - val_loss: 0.5402 - val_accuracy: 0.7276\n",
            "Epoch 17/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5580 - accuracy: 0.7296 - val_loss: 0.5434 - val_accuracy: 0.7308\n",
            "Epoch 18/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5621 - accuracy: 0.7217 - val_loss: 0.5494 - val_accuracy: 0.7115\n",
            "Epoch 19/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5626 - accuracy: 0.7234 - val_loss: 0.5590 - val_accuracy: 0.7179\n",
            "Epoch 20/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5534 - accuracy: 0.7353 - val_loss: 0.5367 - val_accuracy: 0.7404\n",
            "Epoch 21/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5633 - accuracy: 0.7154 - val_loss: 0.5615 - val_accuracy: 0.7051\n",
            "Epoch 22/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5565 - accuracy: 0.7149 - val_loss: 0.5586 - val_accuracy: 0.6859\n",
            "Epoch 23/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5545 - accuracy: 0.7251 - val_loss: 0.5575 - val_accuracy: 0.7083\n",
            "Epoch 24/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5517 - accuracy: 0.7421 - val_loss: 0.5504 - val_accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5534 - accuracy: 0.7279 - val_loss: 0.5448 - val_accuracy: 0.7019\n",
            "Epoch 26/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5417 - accuracy: 0.7421 - val_loss: 0.5666 - val_accuracy: 0.7051\n",
            "Epoch 27/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5427 - accuracy: 0.7302 - val_loss: 0.5454 - val_accuracy: 0.7212\n",
            "Epoch 28/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5522 - accuracy: 0.7279 - val_loss: 0.5574 - val_accuracy: 0.7276\n",
            "Epoch 29/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5409 - accuracy: 0.7302 - val_loss: 0.5856 - val_accuracy: 0.6763\n",
            "Epoch 30/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5403 - accuracy: 0.7205 - val_loss: 0.5446 - val_accuracy: 0.7276\n",
            "Epoch 31/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5452 - accuracy: 0.7319 - val_loss: 0.5446 - val_accuracy: 0.7436\n",
            "Epoch 32/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5325 - accuracy: 0.7353 - val_loss: 0.5676 - val_accuracy: 0.6987\n",
            "Epoch 33/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5336 - accuracy: 0.7409 - val_loss: 0.5515 - val_accuracy: 0.7244\n",
            "Epoch 34/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5346 - accuracy: 0.7455 - val_loss: 0.5428 - val_accuracy: 0.7212\n",
            "Epoch 35/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5372 - accuracy: 0.7381 - val_loss: 0.5525 - val_accuracy: 0.6987\n",
            "Epoch 36/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7381 - val_loss: 0.5515 - val_accuracy: 0.7115\n",
            "Epoch 37/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5276 - accuracy: 0.7483 - val_loss: 0.5452 - val_accuracy: 0.7244\n",
            "Epoch 38/50\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.5265 - accuracy: 0.7523 - val_loss: 0.5682 - val_accuracy: 0.7083\n",
            "Epoch 39/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5272 - accuracy: 0.7404 - val_loss: 0.5498 - val_accuracy: 0.7468\n",
            "Epoch 40/50\n",
            "111/111 [==============================] - 1s 8ms/step - loss: 0.5266 - accuracy: 0.7438 - val_loss: 0.5753 - val_accuracy: 0.7019\n",
            "Epoch 41/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5347 - accuracy: 0.7426 - val_loss: 0.5517 - val_accuracy: 0.7340\n",
            "Epoch 42/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5297 - accuracy: 0.7398 - val_loss: 0.5579 - val_accuracy: 0.7340\n",
            "Epoch 43/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5250 - accuracy: 0.7443 - val_loss: 0.5419 - val_accuracy: 0.7340\n",
            "Epoch 44/50\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5251 - accuracy: 0.7404 - val_loss: 0.5836 - val_accuracy: 0.6923\n",
            "Epoch 45/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5309 - accuracy: 0.7455 - val_loss: 0.5626 - val_accuracy: 0.7147\n",
            "Epoch 46/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5216 - accuracy: 0.7489 - val_loss: 0.5688 - val_accuracy: 0.7147\n",
            "Epoch 47/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5232 - accuracy: 0.7489 - val_loss: 0.5639 - val_accuracy: 0.7276\n",
            "Epoch 48/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5213 - accuracy: 0.7438 - val_loss: 0.5576 - val_accuracy: 0.7212\n",
            "Epoch 49/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5204 - accuracy: 0.7540 - val_loss: 0.5594 - val_accuracy: 0.7308\n",
            "Epoch 50/50\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.5191 - accuracy: 0.7443 - val_loss: 0.5477 - val_accuracy: 0.7500\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7557692307692307\n",
            "Accuracy: 0.7557692307692307\n"
          ]
        }
      ],
      "source": [
        "input_data = np.array(input_data)\n",
        "\n",
        "scores= []\n",
        "for i in range(0, 100):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(input_data, encoded_labels, test_size=0.2)\n",
        "  # Init classifier\n",
        "  test_model = create_model()\n",
        "\n",
        "  # Fit\n",
        "  history = test_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=.15)\n",
        "\n",
        "  y_pred = test_model.predict(X_test)\n",
        "\n",
        "  count = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    if np.argmax(y_pred[i]) == np.argmax(y_test[i]):\n",
        "      count+=1\n",
        "\n",
        "  print(count/len(y_pred))\n",
        "  accuracy = count/len(y_pred)\n",
        "  scores.append(accuracy)\n",
        "  print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "NRg60rwjSmDk",
        "outputId": "d372049b-e2ab-4d49-fbaf-2d80eb8763fd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.hist(scores, 15)\n",
        "plt.xlabel(\"Model Accuracy\")\n",
        "plt.ylabel(\"Models in Accuracy Range\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thp46X3YdDIa",
        "outputId": "d53b8475-a5f1-4e78-c543-4bfce159fff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-f4a047684325>:3: DeprecationWarning: Use of keyword argument 'alpha' for method 'interval' is deprecated and wil be removed in SciPy 1.11.0. Use first positional argument or keyword argument 'confidence' instead.\n",
            "  st.t.interval(alpha=0.95, df=len(scores)-1, loc=np.mean(scores), scale=st.sem(scores))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7154112649331862, 0.721896427374506)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import scipy.stats as st\n",
        "\n",
        "st.t.interval(alpha=0.95, df=len(scores)-1, loc=np.mean(scores), scale=st.sem(scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD4qU5r0SP5o"
      },
      "source": [
        "# Data Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4GECXc0p69H",
        "outputId": "a30aa923-dbd4-435a-db78-7fba550c607e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65/65 [==============================] - 0s 2ms/step\n",
            "0.7557803468208093\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_pred = model.predict(X_train)\n",
        "count = 0\n",
        "for i in range(len(y_pred)):\n",
        "  if np.argmax(y_pred[i]) == np.argmax(y_train[i]):\n",
        "    count+=1\n",
        "\n",
        "print(count/len(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "VGGY6mCQBnxD",
        "outputId": "ffc69ce0-af03-4cda-97d6-43d65e657130"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGwCAYAAAA0bWYRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3UUlEQVR4nO3deXhU5dnH8d9km4SsBCQhEDZZgywKSuNOjQbwVRBaSxttRIQqRFlEhCqbbBUVMYjgjrSo0KpU0VIpFhCJKMFQxICssiagIQkJZJs57x+RwSlMTTKTTDLn+7muc9U553nO3EMDc+e+n3OOxTAMQwAAwLT8vB0AAADwLpIBAABMjmQAAACTIxkAAMDkSAYAADA5kgEAAEyOZAAAAJML8HYA7rDb7Tp27JjCw8NlsVi8HQ4AoJoMw9Dp06cVFxcnP7/a+/20pKREZWVlbp8nKChIwcHBHoiofmnQycCxY8cUHx/v7TAAAG46fPiwWrZsWSvnLikpUdvWYco5YXP7XLGxsTpw4IDPJQQNOhkIDw+XJH23rY0iwuh4wDfd0bGbt0MAak2FyrVJHzn+Pa8NZWVlyjlh03eZbRQRXvPvisLTdrXudVBlZWUkA/XJudZARJifW/8HA/VZgCXQ2yEAtefHG+LXRas3LNyisPCav49dvtuObtDJAAAAVWUz7LK58TQem2H3XDD1DMkAAMAU7DJkV82zAXfm1nfU1gEAMDkqAwAAU7DLLncK/e7Nrt9IBgAApmAzDNmMmpf63Zlb39EmAADA5KgMAABMgQWErpEMAABMwS5DNpKBi6JNAACAyVEZAACYAm0C10gGAACmwNUErtEmAADA5KgMAABMwf7j5s58X0UyAAAwBZubVxO4M7e+IxkAAJiCzZCbTy30XCz1DWsGAAAwOSoDAABTYM2AayQDAABTsMsimyxuzfdVtAkAADA5KgMAAFOwG5WbO/N9FckAAMAUbG62CdyZW9/RJgAAwOSoDAAATIHKgGskAwAAU7AbFtkNN64mcGNufUebAAAAk6MyAAAwBdoErpEMAABMwSY/2dwoiNs8GEt9QzIAADAFw801AwZrBgAAgK+iMgAAMAXWDLhGMgAAMAWb4Seb4caaAR++HTFtAgAATI7KAADAFOyyyO7G78B2+W5pgGQAAGAKrBlwjTYBAAAmR2UAAGAK7i8gpE0AAECDVrlmwI0HFdEmAAAAvorKAADAFOxuPpuAqwkAAGjgWDPgGskAAMAU7PLjPgMusGYAAACTozIAADAFm2GRzY3HELszt74jGQAAmILNzQWENtoEAADAV1EZAACYgt3wk92NqwnsXE0AAEDDRpvANdoEAACYHJUBAIAp2OXeFQF2z4VS75AMAABMwf2bDvluMd13PxkAAKgSKgMAAFNw/9kEvvv7M8kAAMAU7LLILnfWDHAHQgAAGjQqA6757icDAABVQmUAAGAK7t90yHd/fyYZAACYgt2wyO7OfQZ8+KmFvpvmAADgRRs3btRtt92muLg4WSwWrVq1yum4YRiaOnWqmjdvrpCQECUlJWnPnj1OY/Ly8pSSkqKIiAhFRUVp+PDhKioqchrzn//8R9ddd52Cg4MVHx+vefPmVTtWkgEAgCnYf2wT1HSr7k2HiouL1aNHDy1atOiix+fNm6f09HQtWbJEW7ZsUWhoqJKTk1VSUuIYk5KSop07d2rt2rVavXq1Nm7cqJEjRzqOFxYW6pZbblHr1q2VmZmpp556StOnT9dLL71UrVhpEwAATMH9pxZWb27//v3Vv3//ix4zDEMLFizQ448/roEDB0qSli1bppiYGK1atUpDhw5Vdna21qxZoy+//FK9e/eWJC1cuFADBgzQ008/rbi4OC1fvlxlZWV67bXXFBQUpK5duyorK0vz5893Shp+DpUBAACqobCw0GkrLS2t9jkOHDignJwcJSUlOfZFRkaqT58+ysjIkCRlZGQoKirKkQhIUlJSkvz8/LRlyxbHmOuvv15BQUGOMcnJydq9e7dOnTpV5XhIBgAApmCTxe1NkuLj4xUZGenY5s6dW+1YcnJyJEkxMTFO+2NiYhzHcnJy1KxZM6fjAQEBio6OdhpzsXP89D2qgjYBAMAUPNUmOHz4sCIiIhz7rVar27F5G5UBAACqISIiwmmrSTIQGxsrScrNzXXan5ub6zgWGxurEydOOB2vqKhQXl6e05iLneOn71EVJAMAAFOwyd1Wgee0bdtWsbGxWrdunWNfYWGhtmzZosTERElSYmKi8vPzlZmZ6RjzySefyG63q0+fPo4xGzduVHl5uWPM2rVr1alTJzVu3LjK8ZAMAABM4VybwJ2tOoqKipSVlaWsrCxJlYsGs7KydOjQIVksFo0dO1azZs3S+++/rx07duj3v/+94uLiNGjQIElSly5d1K9fP40YMUJffPGFPvvsM6WlpWno0KGKi4uTJP3ud79TUFCQhg8frp07d2rFihV67rnnNH78+GrFypoBAIAp1PWDirZu3aq+ffs6Xp/7gk5NTdXSpUs1ceJEFRcXa+TIkcrPz9e1116rNWvWKDg42DFn+fLlSktL00033SQ/Pz8NGTJE6enpjuORkZH6+OOPNXr0aPXq1UtNmzbV1KlTq3VZoSRZDMMwqjWjHiksLFRkZKROfdtOEeEUOeCbkuN6ejsEoNZUGOVar7+roKDAaVGeJ537rpic0U/BYYE1Pk9JUbnmJq6p1Vi9hcoAAMAUDFlkV82fL2C4Mbe+IxkAAJhCXbcJGhLf/WQAAKBKqAwAAEyBRxi7RjIAADCFc08fdGe+r/LdTwYAAKqEygAAwBRoE7hGMgAAMAW7/GR3oyDuztz6znc/GQAAqBIqAwAAU7AZFtncKPW7M7e+IxkAAJgCawZcIxkAAJiCUYMnD/73fF/lu58MAABUCZUBAIAp2GSRzY2HDbkzt74jGQAAmILdcK/vbzc8GEw9Q5sAAACTozJgMjs+D9VfX2imPTsaKS83UNNePaCr+xc4jm/6KFIfLmuiPTsa6fSpAL3w8W5detnZC87zzdZGWvpkc+3a1kj+/lK7rmc15819soZUps6/vypBuUeCnObcO/mYfvPgidr9gMB/+U1arq4ZUKD49qUqK/HTN1sb6dXZzXVkX7BjTKDVrpHTjunG2/MVaDWUuT5cCye3UP73gY4xHXuc0b1/PK4O3c/IMCzanRWiV2fFaf83Id74WKgBu5sLCN2ZW9/57ifDRZWc8VO7rmeVNueIy+NdryrW8D8ec3mOb7Y20mMpl6rX9aeV/tEepX/0rW4f9r0s//XT9PtHjuutrK8d28Dh33vyowBV0j2xWB8sbaqx/9dBk4e2k3+AoTlv7Zc1xOYYc//0Y/rFzYWa9YfWmjD4UkXHlGvqqwcdx4Mb2TR7+X6dPBaoMf/XQQ8Paq+zRf6a/eZ++Qf4cO3Yx9hlcXvzVfWiMrBo0SI99dRTysnJUY8ePbRw4UJdddVV3g7LJ135y9O68penXR5P+tUpSVLO4SCXY16c3kKDhp90+i0/vn3pBeNCwuyKblbhRrSA+x5Laef0+pmxrbTy653q0P2svt4SpkbhNiX/Nk9/Gt1K2z8LlyTNHx+vVzbuVucrirVrW6ji25cqItqmZU/F6uSxyr8bf5kfoxc/+VYxLct07KC1zj8X4ElerwysWLFC48eP17Rp07Rt2zb16NFDycnJOnGCcnJ9lP99gHZtC1VUkwqNva2DftO9qyYMbq+vt4ReMHbl8830q66XadTNHfXXFy6RjbwA9UBoRGVF4HS+vySpQ/czCgwy9NWn4Y4xh/cGK/dIoLr0OiNJOrLPqoI8fyX/Nk8BgXYFBdvV77d5+u5b6/9MnFG/nLsDoTubr/J6MjB//nyNGDFCw4YNU0JCgpYsWaJGjRrptdde83ZouIjj31X+w/fn+bHqn/KDZi/fr/bdzmjSby7V0f3n/1EcOPykJi/+TvP+ulcD7v5Bby+M0Suz4rwVNiBJslgM3T/jqL7+opG+213Z649uVqGyUouKC/2dxuafDFB0s3JJ0tlifz0y5FLdNPiU3t+/Q6v27FDvvqf1eEo72W2++wXha86tGXBn81VebROUlZUpMzNTkydPduzz8/NTUlKSMjIyLhhfWlqq0tLz5ejCwsI6iRPn2e2V/zvgrh+UPDRPktS+21llbQrXP99uonv/eFySNOQPJx1z2iWUKDDQ0HOPxmvY5OMKstJjhXekzTmq1p1L9PCg9tWaFxRs1/hnjmjnl6GaO6q1/PwN/er+k5r55wN6cEAHlZX47pcEzMGrP8Hff/+9bDabYmJinPbHxMQoJyfngvFz585VZGSkY4uPj6+rUPGjJjGVtf7WHUuc9se3L9GJo4EXmyJJ6nTFGdkqLMqlpAovGT37iPrcXKiJv7pU3x8//3OYdyJAQVbD0T44J+qSCuWdqPyZ7nvHKcXEl+mZcfH6dnsj7doWqj+NbqXYVmVKTC4QGga7LI7nE9Ro8+EFhA0qnZ08ebIKCgoc2+HDh70dkunExJepSWyZjuxzXjB1dL9VzVqWu5y3f2eI/PwMRTVl4QDqmqHRs4/o6n4FmvjrS5V72Plnd89/Gqm8zKLLrz2/sLblpSWKaVmu7MxGkiRriF12u2T8pKhlt1tkGJJfg/pX1NwMN68kMHw4GfBqm6Bp06by9/dXbm6u0/7c3FzFxsZeMN5qtcpqZdWuO84W++nYgfN/hjmHg7Tv6xCFR1WoWctyFZ7y18mjQfoht/JH4/CPX/qNm5UrulmFLBbpVw+c1J+fjlW7hLNq1/Ws/vXXaB3eF6zHXz4oqfLSw11fharH1afVKMyu7MxQLZkWp18OOaXwKNsFMQG1KW3OUfW945SmD2urs0V+anxJZdJafNpfZSV+OnPaX/98K1ojpx/T6fwAFZ/20+jZRyt/jrdVLoz9amO4Rjx+XGlzjurvrzWVn590Z9oJ2Sqk7Z+FefPjoRp4aqFrXk0GgoKC1KtXL61bt06DBg2SJNntdq1bt05paWneDM1nfbu9kSb+6ny/9MXpLSRJN9+ZpwkLDunzjyP1zLhWjuNzH2gjSbprfI7unlDZuhk84qTKSyxaMq2FTuf7q11Ciea+tU9xbcokSYFBhjb8PUp/eSZW5WUWxcaXafDIkxo88vw6AqCu3HbPD5Kkp9/d57T/6bHxWrsyWpK0ZHqc7IY05eWDCrQa2ro+XM9PbuEYe3hvsKbd01Yp43O04IM9MuwW7f06RI+ltHO0EoCGzGIYhldXc61YsUKpqal68cUXddVVV2nBggVauXKldu3adcFagv9WWFioyMhInfq2nSLCqdXBNyXH9fR2CECtqTDKtV5/V0FBgSIiImrlPc59V9yxdpgCQ2u+bqm8uEzv3fx6rcbqLV6/6dBvfvMbnTx5UlOnTlVOTo569uypNWvW/GwiAABAddAmcM3ryYAkpaWl0RYAAMBL6kUyAABAbXP3+QK+fGkhyQAAwBRoE7jGqjsAAEyOygAAwBSoDLhGMgAAMAWSAddoEwAAYHJUBgAApkBlwDWSAQCAKRhy7/JAX374OskAAMAUqAy4xpoBAABMjsoAAMAUqAy4RjIAADAFkgHXaBMAAGByVAYAAKZAZcA1kgEAgCkYhkWGG1/o7syt72gTAABgclQGAACmYJfFrZsOuTO3viMZAACYAmsGXKNNAACAyVEZAACYAgsIXSMZAACYAm0C10gGAACmQGXANdYMAABgclQGAACmYLjZJvDlygDJAADAFAxJhuHefF9FmwAAAJOjMgAAMAW7LLJwB8KLIhkAAJgCVxO4RpsAAACTozIAADAFu2GRhZsOXRTJAADAFAzDzasJfPhyAtoEAACYHJUBAIApsIDQNZIBAIApkAy4RjIAADAFFhC6xpoBAABMjsoAAMAUuJrANSoDAABTqEwGLG5s1Xs/m82mKVOmqG3btgoJCdGll16qmTNnyvjJiQzD0NSpU9W8eXOFhIQoKSlJe/bscTpPXl6eUlJSFBERoaioKA0fPlxFRUWe+CNxIBkAAKAWPPnkk1q8eLGef/55ZWdn68knn9S8efO0cOFCx5h58+YpPT1dS5Ys0ZYtWxQaGqrk5GSVlJQ4xqSkpGjnzp1au3atVq9erY0bN2rkyJEejZU2AQDAFOr6aoLNmzdr4MCBuvXWWyVJbdq00VtvvaUvvvjix/MZWrBggR5//HENHDhQkrRs2TLFxMRo1apVGjp0qLKzs7VmzRp9+eWX6t27tyRp4cKFGjBggJ5++mnFxcXV+PP8FJUBAIApGB7YJKmwsNBpKy0tvej7XX311Vq3bp2+/fZbSdL27du1adMm9e/fX5J04MAB5eTkKCkpyTEnMjJSffr0UUZGhiQpIyNDUVFRjkRAkpKSkuTn56ctW7Z44E+lEpUBAACqIT4+3un1tGnTNH369AvGTZo0SYWFhercubP8/f1ls9k0e/ZspaSkSJJycnIkSTExMU7zYmJiHMdycnLUrFkzp+MBAQGKjo52jPEEkgEAgCl4qk1w+PBhRUREOPZbrdaLjl+5cqWWL1+uN998U127dlVWVpbGjh2ruLg4paam1jiO2kAyAAAwh5/W+ms6X1JERIRTMuDKI488okmTJmno0KGSpG7duum7777T3LlzlZqaqtjYWElSbm6umjdv7piXm5urnj17SpJiY2N14sQJp/NWVFQoLy/PMd8TWDMAADAHty4rtEjVrCqcOXNGfn7OX7P+/v6y2+2SpLZt2yo2Nlbr1q1zHC8sLNSWLVuUmJgoSUpMTFR+fr4yMzMdYz755BPZ7Xb16dOnpn8SF6AyAABALbjttts0e/ZstWrVSl27dtVXX32l+fPn695775UkWSwWjR07VrNmzVKHDh3Utm1bTZkyRXFxcRo0aJAkqUuXLurXr59GjBihJUuWqLy8XGlpaRo6dKjHriSQSAYAACZR13cgXLhwoaZMmaJRo0bpxIkTiouL0x/+8AdNnTrVMWbixIkqLi7WyJEjlZ+fr2uvvVZr1qxRcHCwY8zy5cuVlpamm266SX5+fhoyZIjS09Nr/kEuwmIYDfcGi4WFhYqMjNSpb9spIpyOB3xTclxPb4cA1JoKo1zr9XcVFBRUqQ9fE+e+K9q89rj8GgX//AQX7GdKdPDeWbUaq7fwDQoAgMnRJgAAmEMNFgFeMN9HkQwAAEyBpxa6RpsAAACTozIAADAHD910yBeRDAAATKGun1rYkFQpGXj//ferfMLbb7+9xsEAAIC6V6Vk4NydkH6OxWKRzWZzJx4AAGqPD5f63VGlZODcfZQBAGioaBO45tbVBCUlJZ6KAwCA2mV4YPNR1U4GbDabZs6cqRYtWigsLEz79++XJE2ZMkWvvvqqxwMEAAC1q9rJwOzZs7V06VLNmzdPQUFBjv2XXXaZXnnlFY8GBwCA51g8sPmmaicDy5Yt00svvaSUlBT5+/s79vfo0UO7du3yaHAAAHgMbQKXqp0MHD16VO3bt79gv91uV3l5uUeCAgAAdafayUBCQoI+/fTTC/b/7W9/0+WXX+6RoAAA8DgqAy5V+w6EU6dOVWpqqo4ePSq73a53331Xu3fv1rJly7R69eraiBEAAPfx1EKXql0ZGDhwoD744AP961//UmhoqKZOnars7Gx98MEHuvnmm2sjRgAAUItq9GyC6667TmvXrvV0LAAA1BoeYexajR9UtHXrVmVnZ0uqXEfQq1cvjwUFAIDH8dRCl6qdDBw5ckS//e1v9dlnnykqKkqSlJ+fr6uvvlpvv/22WrZs6ekYAQBALar2moH77rtP5eXlys7OVl5envLy8pSdnS273a777ruvNmIEAMB95xYQurP5qGpXBjZs2KDNmzerU6dOjn2dOnXSwoULdd1113k0OAAAPMViVG7uzPdV1U4G4uPjL3pzIZvNpri4OI8EBQCAx7FmwKVqtwmeeuopPfjgg9q6datj39atWzVmzBg9/fTTHg0OAADUvipVBho3biyL5XyvpLi4WH369FFAQOX0iooKBQQE6N5779WgQYNqJVAAANzCTYdcqlIysGDBgloOAwCAWkabwKUqJQOpqam1HQcAAPCSGt90SJJKSkpUVlbmtC8iIsKtgAAAqBVUBlyq9gLC4uJipaWlqVmzZgoNDVXjxo2dNgAA6iWeWuhStZOBiRMn6pNPPtHixYtltVr1yiuvaMaMGYqLi9OyZctqI0YAAFCLqt0m+OCDD7Rs2TLdeOONGjZsmK677jq1b99erVu31vLly5WSklIbcQIA4B6uJnCp2pWBvLw8tWvXTlLl+oC8vDxJ0rXXXquNGzd6NjoAADzk3B0I3dl8VbWTgXbt2unAgQOSpM6dO2vlypWSKisG5x5cBAAAGo5qJwPDhg3T9u3bJUmTJk3SokWLFBwcrHHjxumRRx7xeIAAAHgECwhdqvaagXHjxjn+OykpSbt27VJmZqbat2+v7t27ezQ4AABQ+9y6z4AktW7dWq1bt/ZELAAA1BqL3HxqocciqX+qlAykp6dX+YQPPfRQjYMBAAB1r0rJwLPPPlulk1ksFq8kA7++ZYAC/Kx1/r5AXai4qam3QwBqTUVFibT+73XzZlxa6FKVkoFzVw8AANBgcTtil6p9NQEAAPAtbi8gBACgQaAy4BLJAADAFNy9iyB3IAQAAD6LygAAwBxoE7hUo8rAp59+qrvuukuJiYk6evSoJOnPf/6zNm3a5NHgAADwGG5H7FK1k4F33nlHycnJCgkJ0VdffaXS0lJJUkFBgebMmePxAAEAQO2qdjIwa9YsLVmyRC+//LICAwMd+6+55hpt27bNo8EBAOApPMLYtWqvGdi9e7euv/76C/ZHRkYqPz/fEzEBAOB53IHQpWpXBmJjY7V3794L9m/atEnt2rXzSFAAAHgcawZcqnYyMGLECI0ZM0ZbtmyRxWLRsWPHtHz5ck2YMEEPPPBAbcQIAABqUbXbBJMmTZLdbtdNN92kM2fO6Prrr5fVatWECRP04IMP1kaMAAC4jZsOuVbtZMBiseixxx7TI488or1796qoqEgJCQkKCwurjfgAAPAM7jPgUo1vOhQUFKSEhARPxgIAALyg2slA3759ZbG4XlH5ySefuBUQAAC1wt3LA6kMnNezZ0+n1+Xl5crKytLXX3+t1NRUT8UFAIBn0SZwqdrJwLPPPnvR/dOnT1dRUZHbAQEAgLrlsacW3nXXXXrttdc8dToAADyL+wy45LGnFmZkZCg4ONhTpwMAwKO4tNC1aicDgwcPdnptGIaOHz+urVu3asqUKR4LDAAA1I1qJwORkZFOr/38/NSpUyc98cQTuuWWWzwWGAAAqBvVSgZsNpuGDRumbt26qXHjxrUVEwAAnsfVBC5VawGhv7+/brnlFp5OCABocHiEsWvVvprgsssu0/79+2sjFgAA4AXVTgZmzZqlCRMmaPXq1Tp+/LgKCwudNgAA6i0uK7yoKq8ZeOKJJ/Twww9rwIABkqTbb7/d6bbEhmHIYrHIZrN5PkoAANzFmgGXqpwMzJgxQ/fff7/+/e9/12Y8AACgjlU5GTCMypTohhtuqLVgAACoLdx0yLVqrRn4X08rBACgXvPC7YiPHj2qu+66S02aNFFISIi6deumrVu3ng/JMDR16lQ1b95cISEhSkpK0p49e5zOkZeXp5SUFEVERCgqKkrDhw/3+LOAqnWfgY4dO/5sQpCXl+dWQAAA+IJTp07pmmuuUd++ffWPf/xDl1xyifbs2eN0n5558+YpPT1db7zxhtq2baspU6YoOTlZ33zzjeMW/ykpKTp+/LjWrl2r8vJyDRs2TCNHjtSbb77psVirlQzMmDHjgjsQAgDQEHiqTfDfV85ZrVZZrdYLxj/55JOKj4/X66+/7tjXtm1bx38bhqEFCxbo8ccf18CBAyVJy5YtU0xMjFatWqWhQ4cqOztba9as0ZdffqnevXtLkhYuXKgBAwbo6aefVlxcXM0/0E9UKxkYOnSomjVr5pE3BgCgTnnoaoL4+Hin3dOmTdP06dMvGP7+++8rOTlZv/71r7Vhwwa1aNFCo0aN0ogRIyRJBw4cUE5OjpKSkhxzIiMj1adPH2VkZGjo0KHKyMhQVFSUIxGQpKSkJPn5+WnLli2644473PhA51U5GWC9AAAA0uHDhxUREeF4fbGqgCTt379fixcv1vjx4/XHP/5RX375pR566CEFBQUpNTVVOTk5kqSYmBineTExMY5jOTk5F/wSHhAQoOjoaMcYT6j21QQAADRIHqoMREREOCUDrtjtdvXu3Vtz5syRJF1++eX6+uuvtWTJEqWmproRiOdV+WoCu91OiwAA0GDV9bMJmjdvroSEBKd9Xbp00aFDhyRJsbGxkqTc3FynMbm5uY5jsbGxOnHihNPxiooK5eXlOcZ4QrVvRwwAQINUx5cWXnPNNdq9e7fTvm+//VatW7eWVLmYMDY2VuvWrXMcLyws1JYtW5SYmChJSkxMVH5+vjIzMx1jPvnkE9ntdvXp06d6Af0P1VpACAAAqmbcuHG6+uqrNWfOHN1555364osv9NJLL+mll16SVLkWb+zYsZo1a5Y6dOjguLQwLi5OgwYNklRZSejXr59GjBihJUuWqLy8XGlpaRo6dKjHriSQSAYAAGZRx88muPLKK/Xee+9p8uTJeuKJJ9S2bVstWLBAKSkpjjETJ05UcXGxRo4cqfz8fF177bVas2aN4x4DkrR8+XKlpaXppptukp+fn4YMGaL09HQ3PsiFLEYDXhlYWFioyMhIJbVJU4DfxVdzAg1dSbum3g4BqDUVFSXatH6GCgoKqrQorybOfVd0fmiO/K3BPz/BBVtpiXal/7FWY/UW1gwAAGBytAkAAObAI4xdIhkAAJgCTy10jTYBAAAmR2UAAGAOtAlcIhkAAJgDyYBLtAkAADA5KgMAAFOw/Li5M99XkQwAAMyBNoFLJAMAAFPg0kLXWDMAAIDJURkAAJgDbQKXSAYAAObhw1/o7qBNAACAyVEZAACYAgsIXSMZAACYA2sGXKJNAACAyVEZAACYAm0C10gGAADmQJvAJdoEAACYHJUBAIAp0CZwjWQAAGAOtAlcIhkAAJgDyYBLrBkAAMDkqAwAAEyBNQOukQwAAMyBNoFLtAkAADA5KgMAAFOwGIYsRs1/vXdnbn1HMgAAMAfaBC7RJgAAwOSoDAAATIGrCVwjGQAAmANtApdoEwAAYHJUBgAApkCbwDWSAQCAOdAmcIlkAABgClQGXGPNAAAAJkdlAABgDrQJXCIZAACYhi+X+t1BmwAAAJOjMgAAMAfDqNzcme+jSAYAAKbA1QSu0SYAAMDkqAwAAMyBqwlcIhkAAJiCxV65uTPfV9EmAADA5KgMmNyv796jq284rpatT6us1F/ZO6L1+uIEHT0U5hgT26JYw0fvVNfueQoMsivz82Za8uxlyj8V7Bhzacd8DRv1jTp0zpfdbtHm9XF6eWFXlZzlRwz1y9D/264Rv8nUO2sS9MLyX0iSAgMr9MDvvlDfPgcUGGjTlztaKH3p1TpVGHLB/IiwEr00e5UuiT6j2/+QouIz1rr+CKgp2gQuURkwuW49v9eH77bRwyOv0+NjExUQYNesZzNkDa6QJFmDKzTr2QxJ0uSHrtaE+69VQKBdU+d9IcuPS2ujm5Zo9nMZOnYkVONHXq+p43+hVm0LNe6xr7z2uYCL6dT2pP7vl7u171Bjp/2jUr7QL3oe1ozn+2rc7AFqGnVG08esu+g5Jty3SfsPR9dFuPCwc1cTuLP5Kq8mAxs3btRtt92muLg4WSwWrVq1ypvhmNLUhxP1r49a6dCBCB3YG6n5sy9Xs9izat+pQJKU0D1PzWLPaP6sy/Xd/gh9tz9C82ddrg6d89Wj1/eSpKuuzlFFhUWLn+muo4fCtGdXYz3/VA9d2/e4mrco8ubHAxyCreX64wMbNP/Va3S6+Pxv86EhZep/w7da8uZVyvomTnsONtW8l6/TZR1PqMulJ5zOcdtN2QptVKaVH11W1+HDE87dZ8CdzUd5NRkoLi5Wjx49tGjRIm+GgZ8IDS2XJBUVBkqSAgPtkmFRefn5H5WyMj8ZdosSuv9QOSbIropyPxmG5fyY0srxXXvk1VXowP80JjVDn2+P17adLZz2d2j7vQID7MrcGefYd/h4lHK/D1VCh/PJQOu4U7p7UJaefPF6GXaLAF/i1WSgf//+mjVrlu64444qjS8tLVVhYaHTBs+xWAyNHLNTO7dH67sDEZKkXTsbq6TEX8NGZctqrZA1uEL3pX0j/wBD0U1KJUnbM5uqcZNSDf7dXgUE2BUWXqZ7HsiWJDX+cQzgTX1/sV/t2/ygV1b2uuBYdORZlZX7XdD7P1UQoujIs5KkwACbHhu9Xi+9daVO/BB2wTnQMNAmcK1BrRmYO3euIiMjHVt8fLy3Q/IpDzz8H7VuV6gnp53/B7Mw36q5U3qrzzU5+tu/PtJf//kPhYaVa++uSNl//Itx6EBl62Dw0H16d92H+sv7Hyv3eCOd+sEqw4cvxUHDcEl0kUbf9bnmLr5B5eU1W9B6351bdehYlP61ub2Ho0OdMjyw+agGtdR78uTJGj9+vON1YWEhCYGH3D/+P7rq6lw9Ovoa/XDSeQX1V1800313JikislQ2m5+KiwL1l/f/qZx1oY4xG9a21Ia1LRXVuEQlJQEyDGnQb/Yp51jof78VUKc6tv1BjSNLtGTm3x37/P0Nde+Uo0E3Z+vReckKCrQrtFGpU3WgceRZ5RVU/l3omXBcbeNP6eMrX688+GOX4L0X3tTy93vojXevqLPPA9SGBpUMWK1WWa1cxuNZhu4fv0OJ1+doctrVyj3u+su7sKDyz777FScV2bhUWzbFXjDm3OWGN996SOVl/vrqy0tqJ2ygirbtjNPwyc6tyEdGfKrDxyL19ofddfKHUJVX+OmKhOP6dGsbSVLL2ALFNC3WN3uaSZKmp/9S1iCbY36ntic1ceQmjZ11q46dCK+zzwL38GwC1xpUMgDPG/XwDt1w8xHNnHSVzp4JUOPoEklScVGgysr8JUlJAw7p8HdhKsi3qkvXPI0c+7VWrWjndC+C/xtyQNk7Guvs2QBdfuVJ3Tv6Gy1d3EXFRYFe+VzAOWdLAnXwiPOlhCWlASossjr2/2NDRz2QskWni60qPhuoB3//uXbuaabsfZXJwPETEU7zI8Mq/558dyyS+ww0JDy10CWSAZO7dfBBSdKTizY77X92dk/966NWkqSWrYp0z/3ZCoso04njjbTijY5ataKd0/iOXU4pZfguhYTYdPi7MD0/r7v+/U9aOGgYXlh+lQxDmvbQOgUG2rX1Py303BuJ3g4LqDMWw/BeqlNUVKS9e/dKki6//HLNnz9fffv2VXR0tFq1avWz8wsLCxUZGamkNmkK8CM7h28qadfU2yEAtaaiokSb1s9QQUGBIiIifn5CDZz7rkjs/4QCAoN/foILFeUlyvjH1FqN1Vu8WhnYunWr+vbt63h9bnFgamqqli5d6qWoAAA+idsRu+TVZODGG2+UFwsTAABArBkAAJgEVxO4RjIAADAHuyHH3dJqOt9HkQwAAMyBNQMuNajbEQMAAM+jMgAAMAWL3Fwz4LFI6h+SAQCAOXAHQpdoEwAAYHIkAwAAUzh3aaE7W0396U9/ksVi0dixYx37SkpKNHr0aDVp0kRhYWEaMmSIcnNzneYdOnRIt956qxo1aqRmzZrpkUceUUVFRc0DcYFkAABgDoYHthr48ssv9eKLL6p79+5O+8eNG6cPPvhAf/3rX7VhwwYdO3ZMgwcPdhy32Wy69dZbVVZWps2bN+uNN97Q0qVLNXXq1JoF8j+QDAAAUEuKioqUkpKil19+WY0bn396ZkFBgV599VXNnz9fv/zlL9WrVy+9/vrr2rx5sz7//HNJ0scff6xvvvlGf/nLX9SzZ0/1799fM2fO1KJFi1RWVubROEkGAACmYDEMtzep8sFHP91KS0tdvufo0aN16623KikpyWl/ZmamysvLnfZ37txZrVq1UkZGhiQpIyND3bp1U0xMjGNMcnKyCgsLtXPnTk/+0ZAMAABMwu6BTVJ8fLwiIyMd29y5cy/6dm+//ba2bdt20eM5OTkKCgpSVFSU0/6YmBjl5OQ4xvw0ETh3/NwxT+LSQgAAquHw4cNOjzC2Wq0XHTNmzBitXbtWwcE1f2xyXaEyAAAwBU+1CSIiIpy2iyUDmZmZOnHihK644goFBAQoICBAGzZsUHp6ugICAhQTE6OysjLl5+c7zcvNzVVsbKwkKTY29oKrC869PjfGU0gGAADmUIdXE9x0003asWOHsrKyHFvv3r2VkpLi+O/AwECtW7fOMWf37t06dOiQEhMTJUmJiYnasWOHTpw44Rizdu1aRUREKCEhocZ/DBdDmwAAYA51eAfC8PBwXXbZZU77QkND1aRJE8f+4cOHa/z48YqOjlZERIQefPBBJSYm6he/+IUk6ZZbblFCQoLuvvtuzZs3Tzk5OXr88cc1evToi1Yj3EEyAACAFzz77LPy8/PTkCFDVFpaquTkZL3wwguO4/7+/lq9erUeeOABJSYmKjQ0VKmpqXriiSc8HgvJAADAFNy9i6A7cyVp/fr1Tq+Dg4O1aNEiLVq0yOWc1q1b66OPPnLvjauAZAAAYA48qMglFhACAGByVAYAAKZgsVdu7sz3VSQDAABzoE3gEm0CAABMjsoAAMAc3HgMsWO+jyIZAACYwk9vKVzT+b6KNgEAACZHZQAAYA4sIHSJZAAAYA6GJHcuD/TdXIBkAABgDqwZcI01AwAAmByVAQCAORhyc82AxyKpd0gGAADmwAJCl2gTAABgclQGAADmYJdkcXO+jyIZAACYAlcTuEabAAAAk6MyAAAwBxYQukQyAAAwB5IBl2gTAABgclQGAADmQGXAJZIBAIA5cGmhSyQDAABT4NJC11gzAACAyVEZAACYA2sGXCIZAACYg92QLG58odt9NxmgTQAAgMlRGQAAmANtApdIBgAAJuFmMiDfTQZoEwAAYHJUBgAA5kCbwCWSAQCAOdgNuVXq52oCAADgq6gMAADMwbBXbu7M91EkAwAAc2DNgEskAwAAc2DNgEusGQAAwOSoDAAAzIE2gUskAwAAczDkZjLgsUjqHdoEAACYHJUBAIA50CZwiWQAAGAOdrskN+4VYPfd+wzQJgAAwOSoDAAAzIE2gUskAwAAcyAZcIk2AQAAJkdlAABgDtyO2CWSAQCAKRiGXYYbTx50Z259RzIAADAHw3Dvt3vWDAAAAF9FZQAAYA6Gm2sGfLgyQDIAADAHu12yuNH39+E1A7QJAAAwOSoDAABzoE3gEskAAMAUDLtdhhttAl++tJA2AQAAJkdlAABgDrQJXCIZAACYg92QLCQDF0ObAAAAk6MyAAAwB8OQ5M59Bny3MkAyAAAwBcNuyHCjTWCQDAAA0MAZdrlXGeDSQgAA4KOoDAAATIE2gWskAwAAc6BN4FKDTgbOZWkV9jIvRwLUnoqKEm+HANSaiopSSXXzW3eFyt2651CFyj0XTD3ToJOB06dPS5LWH3rJy5EAteigtwMAat/p06cVGRlZK+cOCgpSbGysNuV85Pa5YmNjFRQU5IGo6heL0YCbIHa7XceOHVN4eLgsFou3wzGFwsJCxcfH6/Dhw4qIiPB2OIBH8fNd9wzD0OnTpxUXFyc/v9pb015SUqKyMveryEFBQQoODvZARPVLg64M+Pn5qWXLlt4Ow5QiIiL4xxI+i5/vulVbFYGfCg4O9skvcU/h0kIAAEyOZAAAAJMjGUC1WK1WTZs2TVar1duhAB7HzzfMqkEvIAQAAO6jMgAAgMmRDAAAYHIkAwAAmBzJAAAAJkcygCpbtGiR2rRpo+DgYPXp00dffPGFt0MCPGLjxo267bbbFBcXJ4vFolWrVnk7JKBOkQygSlasWKHx48dr2rRp2rZtm3r06KHk5GSdOHHC26EBbisuLlaPHj20aNEib4cCeAWXFqJK+vTpoyuvvFLPP/+8pMrnQsTHx+vBBx/UpEmTvBwd4DkWi0XvvfeeBg0a5O1QgDpDZQA/q6ysTJmZmUpKSnLs8/PzU1JSkjIyMrwYGQDAE0gG8LO+//572Ww2xcTEOO2PiYlRTk6Ol6ICAHgKyQAAACZHMoCf1bRpU/n7+ys3N9dpf25urmJjY70UFQDAU0gG8LOCgoLUq1cvrVu3zrHPbrdr3bp1SkxM9GJkAABPCPB2AGgYxo8fr9TUVPXu3VtXXXWVFixYoOLiYg0bNszboQFuKyoq0t69ex2vDxw4oKysLEVHR6tVq1ZejAyoG1xaiCp7/vnn9dRTTyknJ0c9e/ZUenq6+vTp4+2wALetX79effv2vWB/amqqli5dWvcBAXWMZAAAAJNjzQAAACZHMgAAgMmRDAAAYHIkAwAAmBzJAAAAJkcyAACAyZEMAABgciQDAACYHMkA4KZ77rlHgwYNcry+8cYbNXbs2DqPY/369bJYLMrPz3c5xmKxaNWqVVU+5/Tp09WzZ0+34jp48KAsFouysrLcOg+A2kMyAJ90zz33yGKxyGKxKCgoSO3bt9cTTzyhioqKWn/vd999VzNnzqzS2Kp8gQNAbeNBRfBZ/fr10+uvv67S0lJ99NFHGj16tAIDAzV58uQLxpaVlSkoKMgj7xsdHe2R8wBAXaEyAJ9ltVoVGxur1q1b64EHHlBSUpLef/99SedL+7Nnz1ZcXJw6deokSTp8+LDuvPNORUVFKTo6WgMHDtTBgwcd57TZbBo/fryioqLUpEkTTZw4Uf/9eI//bhOUlpbq0UcfVXx8vKxWq9q3b69XX31VBw8edDwcp3HjxrJYLLrnnnskVT4ieu7cuWrbtq1CQkLUo0cP/e1vf3N6n48++kgdO3ZUSEiI+vbt6xRnVT366KPq2LGjGjVqpHbt2mnKlCkqLy+/YNyLL76o+Ph4NWrUSHfeeacKCgqcjr/yyivq0qWLgoOD1blzZ73wwgvVjgWA95AMwDRCQkJUVlbmeL1u3Trt3r1ba9eu1erVq1VeXq7k5GSFh4fr008/1WeffaawsDD169fPMe+ZZ57R0qVL9dprr2nTpk3Ky8vTe++99z/f9/e//73eeustpaenKzs7Wy+++KLCwsIUHx+vd955R5K0e/duHT9+XM8995wkae7cuVq2bJmWLFminTt3aty4cbrrrru0YcMGSZVJy+DBg3XbbbcpKytL9913nyZNmlTtP5Pw8HAtXbpU33zzjZ577jm9/PLLevbZZ53G7N27VytXrtQHH3ygNWvW6KuvvtKoUaMcx5cvX66pU6dq9uzZys7O1pw5czRlyhS98cYb1Y4HgJcYgA9KTU01Bg4caBiGYdjtdmPt2rWG1Wo1JkyY4DgeExNjlJaWOub8+c9/Njp16mTY7XbHvtLSUiMkJMT45z//aRiGYTRv3tyYN2+e43h5ebnRsmVLx3sZhmHccMMNxpgxYwzDMIzdu3cbkoy1a9deNM5///vfhiTj1KlTjn0lJSVGo0aNjM2bNzuNHT58uPHb3/7WMAzDmDx5spGQkOB0/NFHH73gXP9NkvHee++5PP7UU08ZvXr1cryeNm2a4e/vbxw5csSx7x//+Ifh5+dnHD9+3DAMw7j00kuNN9980+k8M2fONBITEw3DMIwDBw4YkoyvvvrK5fsC8C7WDMBnrV69WmFhYSovL5fdbtfvfvc7TZ8+3XG8W7duTusEtm/frr179yo8PNzpPCUlJdq3b58KCgp0/Phx9enTx3EsICBAvXv3vqBVcE5WVpb8/f11ww03VDnuvXv36syZM7r55pud9peVlenyyy+XJGVnZzvFIUmJiYlVfo9zVqxYofT0dO3bt09FRUWqqKhQRESE05hWrVqpRYsWTu9jt9u1e/duhYeHa9++fRo+fLhGjBjhGFNRUaHIyMhqxwPAO0gG4LP69u2rxYsXKygoSHFxcQoIcP5xDw0NdXpdVFSkXr16afny5Rec65JLLqlRDCEhIdWeU1RUJEn68MMPnb6Epcp1EJ6SkZGhlJQUzZgxQ8nJyYqMjNTbb7+tZ555ptqxvvzyyxckJ/7+/h6LFUDtIhmAzwoNDVX79u2rPP6KK67QihUr1KxZswt+Oz6nefPm2rJli66//npJlb8BZ2Zm6oorrrjo+G7duslut2vDhg1KSkq64Pi5yoTNZnPsS0hIkNVq1aFDh1xWFLp06eJYDHnO559//vMf8ic2b96s1q1b67HHHnPs++677y4Yd+jQIR07dkxxcXGO9/Hz81OnTp0UExOjuLg47d+/XykpKdV6fwD1BwsIgR+lpKSoadOmGjhwoD799FMdOHBA69ev10MPPaQjR45IksaMGaM//elPWrVqlXbt2qVRo0b9z3sEtGnTRqmpqbr33nu1atUqxzlXrlwpSWrdurUsFotWr16tkydPqqioSOHh4ZowYYLGjRunN954Q/v27dO2bdu0cOFCx6K8+++/X3v27NEjjzyi3bt3680339TSpUur9Xk7dOigQ4cO6e2339a+ffuUnp5+0cWQwcHBSk1N1fbt2/Xpp5/qoYce0p133qnY2FhJ0owZMzR37lylp6fr22+/1Y4dO/T6669r/vz51YoHgPeQDAA/atSokTZu3KhWrVpp8ODB6tKli4YPH66SkhJHpeDhhx/W3XffrdTUVCUmJio8PFx33HHH/zzv4sWL9atf/UqjRo1S586dNWLECBUXF0uSWrRooRkzZmjSpEmKiYlRWlqaJGnmzJmaMmWK5s6dqy5duqhfv3768MMP1bZtW0mVffx33nlHq1atUo8ePbRkyRLNmTOnWp/39ttv17hx45SWlqaePXtq8+bNmjJlygXj2rdvr8GDB2vAgAG65ZZb1L17d6dLB++77z698sorev3119WtWzfdcMMNWrp0qSNWAPWfxXC18gkAAJgClQEAAEyOZAAAAJMjGQAAwORIBgAAMDmSAQAATI5kAAAAkyMZAADA5EgGAAAwOZIBAABMjmQAAACTIxkAAMDk/h8OTJHewTzE7gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_pred=np.argmax(y_pred, axis=1), y_true=np.argmax(y_train, axis=1))\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMQiw3Y6Bqj6",
        "outputId": "70faf106-c842-4c38-a8be-28591e587b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 2ms/step\n",
            "0.7653846153846153\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_pred = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(y_pred)):\n",
        "  if np.argmax(y_pred[i]) == np.argmax(y_test[i]):\n",
        "    count+=1\n",
        "\n",
        "print(count/len(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "HjebddC3-Evl",
        "outputId": "c53ae46f-ec6b-4b2b-a3bf-fd3c857bd09f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_pred=np.argmax(y_pred, axis=1), y_true=np.argmax(y_test, axis=1))\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE70rfLp5Mcf"
      },
      "source": [
        "Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rokTLycR5NZb"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/Group 3 Inventors Program Project/Data Sets/rodpump_failure.csv')\n",
        "test_data['FAILURETYPE'] = test_data['FAILURETYPE'].replace(np.nan, 'Not Failure')\n",
        "test_data['FAILURETYPE'] = test_data['FAILURETYPE'].replace('Tubing', 'Failure')\n",
        "test_data['FAILURETYPE'] = test_data['FAILURETYPE'].replace('Sucker Rod Pump', 'Failure')\n",
        "test_data['FAILURETYPE'] = test_data['FAILURETYPE'].replace('Rods', 'Failure')\n",
        "test_data = test_data.replace(np.nan, 0)\n",
        "test_data = test_data[filters]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp6bNMOU5qdR",
        "outputId": "32eae7da-5add-4ce8-c029-606b099aaf7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "\n",
        "input_data = []\n",
        "for i in range(len(test_data)):\n",
        "  input_data.append(test_data.values[i][1:])\n",
        "\n",
        "labels = []\n",
        "for i in range(len(test_data)):\n",
        "  labels.append(test_data.values[i][0])\n",
        "\n",
        "\n",
        "labels = np.reshape(np.array(labels), (-1, 1))\n",
        "oneHotEncoder = OneHotEncoder(sparse=False )\n",
        "encoded_labels = oneHotEncoder.fit_transform(labels)\n",
        "encoded_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "4UtGCL0F6bFF",
        "outputId": "b941cadd-aa6c-40f7-d607-12a2f319b104"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f97b52820bf3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mencoded_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Other'"
          ]
        }
      ],
      "source": [
        "input_data = np.array(input_data)\n",
        "input_data = scaler.transform(input_data)\n",
        "encoded_labels = np.array(encoded_labels)\n",
        "\n",
        "X_test, y_test = input_data, encoded_labels\n",
        "\n",
        "print(X_test.shape,  y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cas5zt5j6vl9"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(y_pred)):\n",
        "  if np.argmax(y_pred[i]) == np.argmax(y_test[i]):\n",
        "    count+=1\n",
        "\n",
        "print(count/len(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUZQ67r42HaM"
      },
      "outputs": [],
      "source": [
        "\n",
        "confusion_matrix = metrics.confusion_matrix(y_pred=np.argmax(y_pred, axis=1), y_true=np.argmax(y_test, axis=1))\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
        "cm_display.plot()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}